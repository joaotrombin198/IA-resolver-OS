{"file_contents":{"COMO_USAR_VSCODE.md":{"content":"# 🎯 Como Usar no VSCode - Guia Completo\n\n## 📥 DOWNLOAD E CONFIGURAÇÃO\n\n### 1. Baixar o Projeto\n1. **Baixe TODOS os arquivos** desta pasta para seu computador\n2. **Crie uma pasta** (ex: `C:\\OS-Assistant` ou `~/OS-Assistant`)\n3. **Copie todos os arquivos** para essa pasta\n\n### 2. Estrutura Necessária\nSua pasta deve ter exatamente estes arquivos:\n\n```\nOS-Assistant/\n├── 📋 DOCUMENTAÇÃO\n│   ├── README.md                    ← Leia primeiro\n│   ├── INSTALACAO_VSCODE.md        ← Guia passo a passo\n│   ├── setup_local.md              ← Instalação detalhada\n│   └── DOCUMENTACAO_SISTEMA.md     ← Manual técnico\n│\n├── 🚀 EXECUÇÃO\n│   ├── run_local.py                ← PRINCIPAL - Execute este arquivo\n│   ├── main.py                     ← Alternativo\n│   └── requirements_local.txt      ← Lista de dependências\n│\n├── 🔧 CORE DO SISTEMA\n│   ├── app.py                      ← Configuração Flask\n│   ├── routes.py                   ← Todas as páginas/rotas\n│   ├── models.py                   ← Estrutura do banco\n│   ├── case_service.py             ← Gerenciamento de casos\n│   ├── ml_service.py               ← Inteligência artificial\n│   └── file_processor.py           ← Importação Excel\n│\n├── 🎨 INTERFACE\n│   ├── static/\n│   │   ├── style.css               ← Estilos visuais\n│   │   └── script.js               ← Interações\n│   └── templates/                  ← Páginas HTML\n│       ├── base.html\n│       ├── index.html\n│       ├── dashboard.html\n│       └── ... (outras páginas)\n│\n├── ⚙️ VSCODE (Configurações)\n│   └── .vscode/\n│       ├── settings.json           ← Configurações do editor\n│       ├── launch.json             ← Debug do sistema\n│       └── tasks.json              ← Comandos rápidos\n│\n└── 🤖 ML MODELS (Criados automaticamente)\n    └── ml_models/                  ← Modelos de IA (vazio no início)\n```\n\n---\n\n## ⚡ INSTALAÇÃO SUPER RÁPIDA\n\n### Passo 1: Instalar Python\n- **Windows:** https://python.org/downloads (marque \"Add to PATH\")\n- **Mac:** `brew install python3`\n- **Linux:** `sudo apt install python3 python3-pip`\n\n### Passo 2: Instalar VSCode\n- Baixe em: https://code.visualstudio.com/\n\n### Passo 3: Configurar Projeto\n1. **Abra VSCode**\n2. **File → Open Folder** → Selecione pasta `OS-Assistant`\n3. **Abra Terminal** (Ctrl+` ou Terminal → New Terminal)\n4. **Execute:**\n\n```bash\n# Instalar dependências\npip install -r requirements_local.txt\n\n# OU instalar manualmente:\npip install flask flask-sqlalchemy pandas openpyxl scikit-learn werkzeug numpy PyPDF2 email-validator\n\n# Executar sistema\npython run_local.py\n```\n\n### Passo 4: Acessar Sistema\n- **URL:** http://localhost:5000\n- **Deve aparecer:** Tela inicial do OS Assistant\n\n---\n\n## 🎮 COMANDOS DO VSCODE\n\n### Executar Sistema\n- **Desenvolvimento (1 usuário):** `python run_local.py`\n- **Produção (multi-usuário):** `python run_production.py`\n- **Via VSCode Tasks:** Ctrl+Shift+P → \"Tasks: Run Task\" → \"Executar OS Assistant\"\n- **Debug mode:** F5\n\n### Comandos Úteis via Terminal\n```bash\n# Executar sistema\npython run_local.py\n\n# Instalar dependências\npip install -r requirements_local.txt\n\n# Verificar casos no banco\npython -c \"from app import *; with app.app_context(): print(f'Casos: {Case.query.count()}')\"\n\n# Backup do banco\ncp os_assistant.db backup_$(date +%Y%m%d).db\n```\n\n### Tasks Automáticas (Ctrl+Shift+P → Tasks)\n- **\"Executar OS Assistant\"** - Inicia o sistema\n- **\"Instalar Dependências\"** - Instala todas as bibliotecas\n- **\"Verificar Status do Banco\"** - Mostra estatísticas\n\n---\n\n## 🔧 CONFIGURAÇÕES DO VSCODE\n\n### Extensões Recomendadas\n1. **Python** (Microsoft) - Essencial\n2. **Python Debugger** - Para debug\n3. **Pylance** - IntelliSense avançado\n\n### Configurações Incluídas\n- **Auto-complete** para Python ativado\n- **Debug** configurado para Flask\n- **Formatação** automática\n- **Syntax highlighting** para templates\n\n---\n\n## 📊 USANDO O SISTEMA\n\n### 1. Primeira Execução\n1. Execute `python run_local.py`\n2. Aguarde mensagem \"Banco de dados SQLite inicializado\"\n3. Acesse http://localhost:5000\n4. Você verá: \"0 casos existentes\"\n\n### 2. Importar Seus Dados\n1. **Prepare planilha Excel** com colunas:\n   - **Problema**: Descrição do problema\n   - **Solução**: Como foi resolvido  \n   - **Sistema**: Tipo de sistema (Tasy, SGU, etc)\n\n2. **No sistema:**\n   - Menu → \"Upload de Casos\"\n   - Selecione sua planilha .xlsx\n   - Clique \"Importar\"\n   - Aguarde confirmação\n\n### 3. Funcionalidades Principais\n- **📊 Dashboard**: Estatísticas e casos recentes\n- **➕ Adicionar Caso**: Inserir problema manualmente\n- **🔍 Analisar Problema**: IA sugere soluções\n- **📋 Gerenciar Casos**: Ver, editar, deletar casos\n- **📁 Upload de Casos**: Importação em massa\n\n---\n\n## 🚨 SOLUÇÃO DE PROBLEMAS\n\n### Erro: \"python: command not found\"\n```bash\n# Windows - use:\npy run_local.py\n\n# Mac/Linux - use:\npython3 run_local.py\n```\n\n### Erro: \"ModuleNotFoundError\"\n```bash\npip install --upgrade pip\npip install -r requirements_local.txt\n```\n\n### Erro: \"Port 5000 in use\"\n**Edite `run_local.py`** linha final:\n```python\napp.run(port=8080)  # Mude de 5000 para 8080\n```\n\n### Sistema Lento\n- **Feche outros programas** pesados\n- **Use SSD** se possível\n- **Máximo 10.000 casos** recomendado\n\n### Importação Falha\n- **Verifique colunas:** Exatamente \"Problema\", \"Solução\", \"Sistema\"\n- **Formato:** Arquivo .xlsx (Excel), não .xls\n- **Tamanho:** Máximo 5MB por arquivo\n\n---\n\n## 💾 BACKUP E MANUTENÇÃO\n\n### Backup Simples\n```bash\n# Copiar banco de dados\ncp os_assistant.db backup/\n\n# Copiar modelos treinados\ncp -r ml_models/ backup/\n```\n\n### Limpeza\n```bash\n# Resetar banco (CUIDADO!)\nrm os_assistant.db\n\n# Limpar modelos (sistema vai retreinar)\nrm -rf ml_models/\n```\n\n### Atualização\n1. **Baixe nova versão** dos arquivos\n2. **Mantenha** seu `os_assistant.db`\n3. **Mantenha** pasta `ml_models/`\n4. **Substitua** outros arquivos\n\n---\n\n## 📈 PERFORMANCE\n\n### Configuração Mínima\n- **Python 3.8+**\n- **2GB RAM**\n- **100MB espaço livre**\n- **Windows 10/Mac 10.15/Ubuntu 18.04+**\n\n### Configuração Recomendada\n- **Python 3.11+**\n- **4GB RAM**\n- **1GB espaço livre**\n- **SSD**\n\n### Limites Sugeridos\n- **Casos:** Até 10.000 funcionam bem\n- **Importação:** Até 1.000 casos por vez\n- **Arquivo:** Máximo 5MB por planilha\n\n---\n\n## 📞 SUPORTE\n\n### Documentação\n- **README.md** - Visão geral e comandos\n- **INSTALACAO_VSCODE.md** - Passo a passo detalhado\n- **DOCUMENTACAO_SISTEMA.md** - Manual técnico completo\n\n### Debug\n- **Logs:** Aparecem no terminal do VSCode\n- **Erros:** Copie mensagem completa para análise\n- **SQL Debug:** Edite `app.py`, mude `echo: False` para `True`\n\n### Arquivos Importantes\n- **Dados:** `os_assistant.db`\n- **Config:** `.vscode/` (configurações VSCode)\n- **Modelos:** `ml_models/` (IA treinada)\n\n---\n\n## 🌐 ACESSO MULTI-USUÁRIO\n\n### Compartilhar na Rede Local\n1. **Execute:** `python run_production.py` (para múltiplos usuários)\n2. **Descubra seu IP:**\n   ```bash\n   # Windows\n   ipconfig\n   \n   # Mac/Linux  \n   ifconfig\n   ```\n3. **Compartilhe o link:** `http://SEU_IP:5000`\n4. **Exemplo:** `http://192.168.1.100:5000`\n\n### Sincronização Automática\n- ✅ **Todos acessam o mesmo banco** SQLite\n- ✅ **Casos adicionados aparecem para todos** instantaneamente\n- ✅ **Importações Excel** ficam disponíveis para toda equipe\n- ✅ **Modelos ML** retreinam automaticamente\n\n### Backup Centralizado\n```bash\n# Fazer backup do banco compartilhado\ncp os_assistant.db backup_$(date +%Y%m%d_%H%M).db\n\n# Restaurar backup\ncp backup_20250814_1030.db os_assistant.db\n```\n\n---\n\n## ✅ CHECKLIST FINAL\n\n**Antes de começar:**\n- [ ] Python instalado e funcionando\n- [ ] VSCode instalado\n- [ ] Pasta do projeto criada\n- [ ] Todos os arquivos copiados\n\n**Configuração:**\n- [ ] VSCode aberto na pasta correta\n- [ ] Terminal integrado funcionando\n- [ ] Dependências instaladas sem erro\n\n**Teste:**\n- [ ] `python run_local.py` executa\n- [ ] http://localhost:5000 carrega\n- [ ] Dashboard mostra \"0 casos\"\n- [ ] Upload de teste funciona\n\n**🎉 PRONTO! Seu OS Assistant está rodando perfeitamente no VSCode!**","size_bytes":8448},"DOCUMENTACAO_SISTEMA.md":{"content":"# OS Assistant - Documentação Completa do Sistema\n\n## Visão Geral\n\nO OS Assistant é um sistema de suporte técnico baseado em machine learning, projetado para diagnosticar e resolver problemas em múltiplos sistemas (especialmente sistemas hospitalares brasileiros como Tasy, SGU, SGU Card e Autorizador). O sistema funciona como um \"mentor digital\" que analisa descrições de problemas e sugere soluções baseadas em casos históricos.\n\n## Arquitetura do Sistema\n\n### Estrutura de Diretórios\n\n```\nOS-Assistant/\n├── app.py                 # Configuração principal do Flask\n├── main.py                # Ponto de entrada da aplicação\n├── models.py              # Modelos de dados (SQLAlchemy)\n├── routes.py              # Rotas e endpoints da aplicação\n├── case_service.py        # Serviço para gerenciamento de casos\n├── ml_service.py          # Serviço de machine learning\n├── file_processor.py      # Processamento de arquivos de importação\n├── static/                # Arquivos estáticos (CSS, JS)\n│   ├── style.css\n│   └── script.js\n├── templates/             # Templates HTML (Jinja2)\n│   ├── base.html\n│   ├── index.html\n│   ├── dashboard.html\n│   ├── add_case.html\n│   └── ...\n├── ml_models/             # Modelos de ML treinados (pickle)\n│   ├── system_classifier.pkl\n│   ├── label_encoder.pkl\n│   └── metadata.pkl\n└── attached_assets/       # Arquivos anexados pelos usuários\n```\n\n### Tecnologias Utilizadas\n\n**Backend:**\n- **Flask**: Framework web principal\n- **PostgreSQL**: Banco de dados principal para persistência\n- **SQLAlchemy**: ORM para interação com banco de dados\n- **Scikit-learn**: Machine learning e processamento de texto\n- **Pandas**: Manipulação de dados e importação de planilhas\n- **Gunicorn**: Servidor WSGI para produção\n\n**Frontend:**\n- **Bootstrap**: Framework CSS responsivo com tema escuro\n- **Feather Icons**: Biblioteca de ícones\n- **JavaScript**: Funcionalidades interativas (validação, busca, confirmações)\n\n**Machine Learning:**\n- **TF-IDF Vectorization**: Análise de similaridade de texto\n- **Support Vector Machine (SVM)**: Classificação de tipos de sistema\n- **Naive Bayes**: Classificação complementar\n- **Cosine Similarity**: Busca de casos similares\n\n## Banco de Dados\n\n### Localização e Configuração\n\nO sistema utiliza **PostgreSQL** como banco de dados principal, configurado automaticamente no ambiente Replit:\n\n**Variáveis de Ambiente:**\n- `DATABASE_URL`: URL completa de conexão\n- `PGHOST`: Host do banco de dados\n- `PGPORT`: Porta (padrão: 5432)\n- `PGUSER`: Usuário do banco\n- `PGPASSWORD`: Senha do banco\n- `PGDATABASE`: Nome do banco de dados\n\n### Estrutura das Tabelas\n\n#### Tabela `cases`\n```sql\nCREATE TABLE cases (\n    id SERIAL PRIMARY KEY,\n    problem_description TEXT NOT NULL,\n    solution TEXT NOT NULL,\n    system_type VARCHAR(100) DEFAULT 'Unknown',\n    created_at TIMESTAMP DEFAULT NOW(),\n    effectiveness_score FLOAT,\n    feedback_count INTEGER DEFAULT 0,\n    tags VARCHAR(500) DEFAULT ''\n);\n```\n\n#### Tabela `case_feedbacks`\n```sql\nCREATE TABLE case_feedbacks (\n    id SERIAL PRIMARY KEY,\n    case_id INTEGER REFERENCES cases(id),\n    effectiveness_score INTEGER NOT NULL,\n    resolution_method VARCHAR(50) DEFAULT '',\n    custom_solution TEXT DEFAULT '',\n    created_at TIMESTAMP DEFAULT NOW()\n);\n```\n\n### Backup de Dados\n\nO sistema mantém dois níveis de armazenamento:\n1. **Principal**: PostgreSQL para persistência completa\n2. **Fallback**: Armazenamento em memória (temporário) em caso de falha do banco\n\n## Funcionalidades Principais\n\n### 1. Análise de Problemas\n- Entrada de descrição de problema via interface web\n- Análise automática usando ML para detectar tipo de sistema\n- Geração de sugestões de solução baseadas em padrões históricos\n- Busca de casos similares usando TF-IDF e similaridade coseno\n\n### 2. Gerenciamento de Casos (CRUD Completo)\n- **Criar**: Adição de novos casos via formulário ou importação\n- **Ler**: Visualização de casos individuais e listagem completa\n- **Atualizar**: Edição de casos existentes\n- **Deletar**: Remoção de casos com confirmação\n\n### 3. Importação de Dados\nSuporte para múltiplos formatos:\n- **Excel (.xlsx, .xls)**: Formato preferido\n- **CSV**: Dados tabulares\n- **TXT**: Texto estruturado\n- **PDF**: Extração de texto (quando PyPDF2 disponível)\n\n#### Formato de Importação Esperado\nPara arquivos Excel/CSV, as colunas devem ser nomeadas (case-insensitive):\n- **Problema/Problem**: Descrição detalhada do problema\n- **Solução/Solution**: Solução aplicada\n- **Sistema/System**: Tipo de sistema afetado\n\n### 4. Machine Learning Interno\n- **100% Offline**: Sem dependências de APIs externas\n- **Classificação Automática**: Detecção de tipo de sistema\n- **Aprendizado Contínuo**: Modelos se adaptam com novos casos\n- **Feedback Loop**: Melhoria baseada em efetividade reportada\n\n### 5. Dashboard e Estatísticas\n- Total de casos por sistema\n- Efetividade média das soluções\n- Casos recentes e tendências\n- Estatísticas de feedback dos usuários\n\n## Como Usar o Sistema\n\n### 1. Análise de Problema\n1. Acesse a página principal\n2. Digite a descrição detalhada do problema\n3. Clique em \"Analisar Problema\"\n4. Revise as sugestões e casos similares\n5. Aplique a solução e forneça feedback\n\n### 2. Adicionar Novo Caso\n1. Navegue para \"Adicionar Caso\"\n2. Preencha problema, solução e tipo de sistema\n3. Adicione tags relevantes (opcional)\n4. Salve o caso\n\n### 3. Importar Casos em Lote\n1. Prepare arquivo Excel com colunas: Problema, Solução, Sistema\n2. Acesse \"Upload de Casos\"\n3. Selecione o arquivo\n4. Escolha \"Formato Estruturado\"\n5. Confirme a importação\n\n### 4. Gerenciar Casos Existentes\n1. Acesse \"Dashboard\" para visão geral\n2. Use \"Casos\" para listar todos\n3. Clique em qualquer caso para visualizar/editar\n4. Use a busca integrada para encontrar casos específicos\n\n## Segurança e Privacidade\n\n### Características de Segurança\n- **Sem Conexões Externas**: Sistema 100% interno, sem envio de dados para APIs externas\n- **Validação de Entrada**: Sanitização de todos os inputs do usuário\n- **Sessões Seguras**: Gerenciamento de sessão com chaves secretas\n- **Separação Cliente/Servidor**: Arquitetura segura com validação no backend\n\n### Dados Sensíveis\n- Todos os casos permanecem no banco de dados local\n- Nenhuma informação é enviada para serviços externos de IA\n- Machine learning executado completamente on-premises\n\n## Manutenção e Troubleshooting\n\n### Logs do Sistema\n- Logs disponíveis no console da aplicação\n- Nível DEBUG ativado para desenvolvimento\n- Erros de banco de dados logados com detalhes\n\n### Comandos Úteis\n```bash\n# Verificar status do banco\npsql $DATABASE_URL -c \"SELECT COUNT(*) FROM cases;\"\n\n# Backup de casos\npsql $DATABASE_URL -c \"COPY cases TO STDOUT WITH CSV HEADER;\" > backup_casos.csv\n\n# Verificar modelos ML\nls -la ml_models/\n```\n\n### Problemas Comuns\n\n#### 1. Erro de Conexão com Banco\n- Verifique as variáveis de ambiente DATABASE_URL\n- Reinicie o workflow se necessário\n- Sistema faz fallback para armazenamento em memória\n\n#### 2. Importação Falha\n- Verifique se as colunas estão nomeadas corretamente\n- Confirme que o arquivo não está corrompido\n- Use template fornecido como referência\n\n#### 3. ML Models Não Carregam\n- Verifique diretório ml_models/\n- Modelos são retreinados automaticamente com novos dados\n- Mínimo de 5 casos necessário para treinamento\n\n## Escalabilidade e Performance\n\n### Otimizações Implementadas\n- **Connection Pooling**: Reutilização de conexões do banco\n- **TF-IDF Caching**: Vetorização armazenada para reuso\n- **Lazy Loading**: Modelos ML carregados sob demanda\n- **Batch Processing**: Importação otimizada para múltiplos casos\n\n### Limites Recomendados\n- **Casos**: Até 10.000 casos mantém performance ótima\n- **Importação**: Arquivos até 5MB recomendados\n- **Busca**: Resultados limitados a 50 casos similares\n\n## Roadmap e Extensões Futuras\n\n### Funcionalidades Planejadas\n- Export de dados em múltiplos formatos\n- Dashboard avançado com gráficos\n- Sistema de notificações para casos críticos\n- API REST para integração externa\n- Workflow de aprovação para casos sensíveis\n\n### Escalabilidade\n- Suporte para múltiplos bancos de dados\n- Cache distribuído para ML models\n- Balanceamento de carga para alta disponibilidade\n\n---\n\n**Versão do Sistema**: 1.0.0  \n**Última Atualização**: 14 de Agosto de 2025  \n**Ambiente**: Replit Production Environment  \n**Suporte**: Sistema interno - documentação completa disponível neste arquivo","size_bytes":8755},"INSTALACAO_VSCODE.md":{"content":"# 🎯 Guia de Instalação VSCode - Passo a Passo\n\n## 📋 O que você vai precisar\n- Windows/Mac/Linux com Python 3.8+\n- VSCode (Visual Studio Code)\n- 10 minutos do seu tempo\n\n---\n\n## 🔧 PASSO 1: Verificar Python\n\nAbra o **Prompt de Comando** (Windows) ou **Terminal** (Mac/Linux):\n\n```bash\npython --version\n```\n\n**Resultado esperado:** `Python 3.8.x` ou superior\n\n**Se não funcionar:**\n- Windows: Baixe em https://python.org/downloads\n- Mac: `brew install python3`\n- Ubuntu: `sudo apt install python3 python3-pip`\n\n---\n\n## 📁 PASSO 2: Preparar Pasta do Projeto\n\n1. **Crie uma pasta** no seu computador (ex: `C:\\OS-Assistant` ou `~/OS-Assistant`)\n2. **Copie TODOS os arquivos** do projeto para essa pasta\n3. **Estrutura deve ficar assim:**\n\n```\nOS-Assistant/\n├── README.md\n├── run_local.py              ← IMPORTANTE\n├── app.py\n├── routes.py\n├── models.py\n├── case_service.py\n├── ml_service.py\n├── file_processor.py\n├── static/\n│   ├── style.css\n│   └── script.js\n├── templates/\n│   ├── base.html\n│   ├── index.html\n│   └── ... (outros arquivos)\n└── ml_models/               ← Pasta pode estar vazia\n```\n\n---\n\n## 🚀 PASSO 3: Abrir no VSCode\n\n1. **Abra o VSCode**\n2. **File → Open Folder** (ou Ctrl+K, Ctrl+O)\n3. **Selecione a pasta** `OS-Assistant`\n4. **Confira**: Você deve ver todos os arquivos na barra lateral\n\n---\n\n## ⚡ PASSO 4: Instalar Dependências\n\n1. **Abra o Terminal integrado** no VSCode:\n   - **Menu:** Terminal → New Terminal\n   - **Atalho:** Ctrl+` (aspas simples)\n\n2. **Execute este comando:**\n```bash\npip install flask flask-sqlalchemy pandas openpyxl scikit-learn werkzeug numpy PyPDF2 email-validator\n```\n\n**Aguarde a instalação** (pode demorar 2-3 minutos)\n\n**Se der erro de permissão:**\n```bash\npip install --user flask flask-sqlalchemy pandas openpyxl scikit-learn werkzeug numpy PyPDF2 email-validator\n```\n\n---\n\n## 🎯 PASSO 5: Executar o Sistema\n\nNo terminal do VSCode, digite:\n\n```bash\npython run_local.py\n```\n\n**Você deve ver:**\n```\n============================================================\nOS ASSISTANT - Sistema de Suporte Técnico Inteligente\n============================================================\nConfiguração: SQLite (Banco Local)\nPorta: 5000\nURL: http://localhost:5000\n============================================================\n✅ Banco de dados SQLite inicializado com sucesso\n📁 Arquivo do banco: C:\\OS-Assistant\\os_assistant.db\n📊 Casos existentes no banco: 0\n\n🚀 Iniciando servidor Flask...\n💡 Pressione Ctrl+C para parar o servidor\n============================================================\n```\n\n---\n\n## 🌐 PASSO 6: Testar no Navegador\n\n1. **Abra seu navegador** (Chrome, Firefox, Edge, Safari)\n2. **Digite:** `http://localhost:5000`\n3. **Deve aparecer** a tela inicial do OS Assistant\n\n**Se não funcionar:**\n- Verifique se não há erro no terminal\n- Tente `http://127.0.0.1:5000`\n- Veja se outra aplicação está usando a porta 5000\n\n---\n\n## 📊 PASSO 7: Testar Importação\n\n1. **Prepare uma planilha Excel** com colunas:\n   - **Problema** (descrição do problema)\n   - **Solução** (como foi resolvido)\n   - **Sistema** (tipo de sistema)\n\n2. **Na aplicação:**\n   - Clique **\"Upload de Casos\"**\n   - Selecione sua planilha\n   - Clique **\"Importar\"**\n\n3. **Verifique no Dashboard** se os casos apareceram\n\n---\n\n## 🔧 Configurações do VSCode (Opcional)\n\n### Extensões Recomendadas\n1. **Python** (Microsoft)\n2. **Python Debugger** (Microsoft)\n3. **Pylance** (Microsoft)\n\n### Configurar Python Interpreter\n1. **Ctrl+Shift+P**\n2. **Digite:** `Python: Select Interpreter`\n3. **Escolha** a versão do Python instalada\n\n---\n\n## 🚨 Soluções de Problemas Comuns\n\n### ❌ \"python: command not found\"\n**Windows:**\n- Reinstale Python marcando \"Add to PATH\"\n- Use `py` em vez de `python`\n\n**Mac/Linux:**\n- Use `python3` em vez de `python`\n- Instale via gerenciador de pacotes\n\n### ❌ \"ModuleNotFoundError: No module named 'flask'\"\n```bash\npip install --upgrade pip\npip install flask flask-sqlalchemy pandas openpyxl scikit-learn\n```\n\n### ❌ \"Port 5000 is already in use\"\n**Edite `run_local.py`** linha 57:\n```python\napp.run(port=8080)  # Mude de 5000 para 8080\n```\n\n### ❌ \"Permission denied\" ao criar banco\n**Windows:**\n- Execute VSCode como Administrador\n- Verifique antivírus\n\n**Mac/Linux:**\n```bash\nchmod 755 .\n```\n\n### ❌ Importação de Excel falha\n- Verifique se colunas estão nomeadas exatamente: \"Problema\", \"Solução\", \"Sistema\"\n- Use arquivo .xlsx (Excel), não .xls\n- Arquivo deve ter menos de 5MB\n\n---\n\n## 📈 Próximos Passos\n\n### 1. Explorar Funcionalidades\n- ✅ Adicionar casos manualmente\n- ✅ Testar análise de problemas\n- ✅ Verificar dashboard\n- ✅ Importar sua planilha de dados\n\n### 2. Customizar Sistema\n- Adicionar seus sistemas específicos\n- Ajustar tipos de problema\n- Configurar tags personalizadas\n\n### 3. Backup dos Dados\n- Copie o arquivo `os_assistant.db` periodicamente\n- Salve a pasta `ml_models/` após treinar\n\n---\n\n## 📞 Suporte\n\n**Documentação Completa:**\n- `DOCUMENTACAO_SISTEMA.md` - Guia técnico completo\n- `setup_local.md` - Guia de instalação detalhado\n\n**Logs de Erro:**\n- Aparecem no terminal do VSCode\n- Copie e cole para debug\n\n**Backup/Restore:**\n- Dados: arquivo `os_assistant.db`\n- Modelos: pasta `ml_models/`\n\n---\n\n## ✅ Checklist Final\n\n- [ ] Python instalado e funcionando\n- [ ] VSCode instalado\n- [ ] Projeto copiado para pasta local\n- [ ] Dependências instaladas sem erro\n- [ ] `python run_local.py` executa sem erro\n- [ ] http://localhost:5000 carrega a aplicação\n- [ ] Teste de importação realizado\n- [ ] Dashboard mostra dados corretamente\n\n**🎉 Parabéns! Seu OS Assistant está funcionando!**","size_bytes":5779},"README.md":{"content":"# OS Assistant - Sistema de Suporte Técnico Inteligente\n\n## 📋 Descrição\nSistema de machine learning para diagnosticar e resolver problemas técnicos baseado em casos históricos. Focado em sistemas hospitalares brasileiros (Tasy, SGU, SGU Card, Autorizador).\n\n## 🚀 Configuração Rápida no VSCode\n\n### 1. Pré-requisitos\n- Python 3.8+ instalado\n- VSCode instalado\n- Terminal/Prompt de comando\n\n### 2. Passos de Instalação\n\n1. **Clone/Baixe o projeto** para uma pasta local\n2. **Abra a pasta no VSCode**\n3. **Abra o terminal integrado** (Ctrl+` ou Terminal → New Terminal)\n4. **Execute os comandos:**\n\n```bash\n# Instalar dependências\npip install flask flask-sqlalchemy pandas openpyxl scikit-learn werkzeug numpy PyPDF2 email-validator\n\n# Executar o sistema\npython run_local.py\n```\n\n5. **Acesse:** http://localhost:5000\n\n## 📁 Estrutura do Projeto\n\n```\nOS-Assistant/\n├── README.md                  # ← Este arquivo\n├── run_local.py              # ← Script principal para executar\n├── setup_local.md            # ← Guia detalhado de instalação\n├── DOCUMENTACAO_SISTEMA.md   # ← Documentação completa técnica\n├── \n├── 🎯 CORE (Arquivos principais)\n├── app.py                    # Configuração Flask e banco\n├── main.py                   # Ponto de entrada alternativo\n├── routes.py                 # Todas as rotas da aplicação\n├── models.py                 # Modelos do banco de dados\n├── \n├── 🧠 SERVICES (Lógica de negócio)\n├── case_service.py           # Gerenciamento de casos\n├── ml_service.py             # Machine learning interno\n├── file_processor.py         # Importação de arquivos Excel\n├── \n├── 🎨 FRONTEND\n├── static/\n│   ├── style.css            # Estilos (Bootstrap + customizações)\n│   └── script.js            # JavaScript (busca, confirmações)\n├── templates/               # Templates HTML (Jinja2)\n│   ├── base.html           # Layout base\n│   ├── index.html          # Página principal\n│   ├── dashboard.html      # Dashboard com estatísticas\n│   ├── add_case.html       # Adicionar caso\n│   ├── upload_cases.html   # Upload de planilhas\n│   └── ... (outros templates)\n├── \n├── 🤖 ML MODELS (Auto-gerados)\n└── ml_models/              # Modelos treinados (pickle)\n    ├── system_classifier.pkl\n    ├── label_encoder.pkl\n    └── metadata.pkl\n```\n\n## ⚡ Funcionalidades Principais\n\n- **🔍 Análise Inteligente**: IA analisa problemas e sugere soluções\n- **📊 Dashboard**: Estatísticas e visualização de casos\n- **📁 Importação Excel**: Carregue centenas de casos via planilha\n- **🔧 CRUD Completo**: Criar, editar, visualizar, deletar casos\n- **🔎 Busca Inteligente**: Encontra casos similares automaticamente\n- **🏥 Sistemas Suportados**: Tasy, SGU, SGU Card, Autorizador\n- **🔒 100% Offline**: Sem dependências de APIs externas\n\n## 💾 Banco de Dados\n\n- **Desenvolvimento Local**: SQLite (arquivo `os_assistant.db`)\n- **Produção**: PostgreSQL (configuração automática)\n- **Backup**: Simplesmente copie o arquivo `os_assistant.db`\n\n## 📤 Importação de Dados\n\n### Formato de Planilha Excel\nSuas planilhas devem ter estas colunas (exato como está):\n\n| Problema | Solução | Sistema |\n|----------|---------|---------|\n| Descrição detalhada do problema | Como foi resolvido | Tasy/SGU/etc |\n\n### Como Importar\n1. Menu → \"Upload de Casos\"\n2. Selecione arquivo Excel (.xlsx)\n3. Clique \"Importar\"\n4. Aguarde confirmação\n\n## 🛠️ Comandos Úteis\n\n```bash\n# Executar em modo desenvolvimento\npython run_local.py\n\n# Executar em modo produção (alternativo)\npython main.py\n\n# Ver casos no banco\npython -c \"from app import *; with app.app_context(): print(f'Casos: {Case.query.count()}')\"\n```\n\n## 📝 Logs e Debug\n\n- **Logs aparecem no terminal** onde executou o comando\n- **Para debug SQL**: Edite `app.py`, linha 49, mude `\"echo\": False` para `True`\n- **Arquivo de log**: Não necessário, tudo aparece no console\n\n## 🔧 Customizações\n\n### Mudar Porta\nEdite `run_local.py`, linha 57:\n```python\napp.run(port=8080)  # Sua porta preferida\n```\n\n### Adicionar Sistemas\nInterface → \"Gerenciar Sistemas\" → Adicionar\n\n### Backup Automático\nCopie periodicamente:\n- `os_assistant.db` (dados)\n- `ml_models/` (modelos treinados)\n\n## 🚨 Solução de Problemas\n\n### Erro: ModuleNotFoundError\n```bash\npip install --upgrade pip\npip install flask flask-sqlalchemy pandas openpyxl scikit-learn\n```\n\n### Erro: \"Port 5000 in use\"\n- Mude a porta em `run_local.py`\n- Ou pare o processo: `pkill -f python`\n\n### Importação Falha\n- Verifique colunas: \"Problema\", \"Solução\", \"Sistema\"\n- Arquivo deve ser .xlsx (Excel)\n- Máximo 5MB recomendado\n\n### Performance Lenta\n- Mais de 10.000 casos? Considere limpeza\n- Feche outros programas pesados\n- Use SSD se possível\n\n## 📚 Documentação Completa\n\n- **setup_local.md**: Guia detalhado de instalação\n- **DOCUMENTACAO_SISTEMA.md**: Documentação técnica completa\n- **Comentários no código**: Cada arquivo é bem documentado\n\n## ✅ Checklist de Instalação\n\n- [ ] Python 3.8+ instalado\n- [ ] VSCode instalado\n- [ ] Projeto baixado em pasta local\n- [ ] Terminal aberto na pasta do projeto\n- [ ] Dependências instaladas (`pip install...`)\n- [ ] `python run_local.py` executado\n- [ ] http://localhost:5000 acessível\n- [ ] Teste de importação realizado\n\n## 🎯 Próximos Passos\n\n1. Execute `python run_local.py`\n2. Acesse http://localhost:5000\n3. Teste as funcionalidades básicas\n4. Importe seus dados Excel\n5. Configure sistemas personalizados\n6. Explore o dashboard e relatórios\n\n---\n\n**Versão:** 1.0.0 | **Suporte:** Sistema 100% interno | **Licença:** Uso interno","size_bytes":5835},"app.py":{"content":"import os\nimport logging\nfrom flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom sqlalchemy.orm import DeclarativeBase\nfrom werkzeug.middleware.proxy_fix import ProxyFix\n\n# Set up logging for debugging\nlogging.basicConfig(level=logging.DEBUG)\n\nclass Base(DeclarativeBase):\n    pass\n\ndb = SQLAlchemy(model_class=Base)\n\n# Create the Flask app\napp = Flask(__name__)\napp.secret_key = os.environ.get(\"SESSION_SECRET\", \"dev-secret-key-change-in-production\")\napp.wsgi_app = ProxyFix(app.wsgi_app, x_proto=1, x_host=1)\n\n# Configure the database with robust fallback strategy\ndatabase_url = os.environ.get(\"DATABASE_URL\")\nif database_url and \"postgres\" in database_url:\n    # PostgreSQL configuration with connection resilience\n    app.config[\"SQLALCHEMY_DATABASE_URI\"] = database_url\n    app.config[\"SQLALCHEMY_ENGINE_OPTIONS\"] = {\n        \"pool_recycle\": 300,\n        \"pool_pre_ping\": True,\n        \"pool_timeout\": 10,\n        \"pool_size\": 5,\n        \"max_overflow\": 10,\n        \"echo\": False,\n        \"connect_args\": {\n            \"connect_timeout\": 10,\n            \"application_name\": \"os_assistant\"\n        }\n    }\nelse:\n    # SQLite fallback for local development and reliability\n    import os\n    db_path = os.path.join(os.getcwd(), \"os_assistant.db\")\n    app.config[\"SQLALCHEMY_DATABASE_URI\"] = f\"sqlite:///{db_path}\"\n    app.config[\"SQLALCHEMY_ENGINE_OPTIONS\"] = {\n        \"echo\": False,\n        \"connect_args\": {\"timeout\": 20}\n    }\n    \napp.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\n\n# Initialize the app with the extension\ndb.init_app(app)\n\n# Initialize in-memory storage for prototyping (will migrate to DB later)\napp.config['CASES_STORAGE'] = []\napp.config['NEXT_CASE_ID'] = 1\n\nwith app.app_context():\n    # Make sure to import the models here\n    import models\n    db.create_all()\n\n# Import routes after app creation to avoid circular imports\nfrom routes import *\n","size_bytes":1890},"case_service.py":{"content":"import logging\nfrom typing import List, Dict, Optional\nfrom datetime import datetime, timedelta\nfrom flask import current_app\nfrom models import Case, CaseFeedback\nfrom app import db\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\nclass CaseService:\n    \"\"\"Service for managing cases and performing similarity searches\"\"\"\n    \n    def __init__(self):\n        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n        self._fitted = False\n    \n    def get_all_cases(self) -> List[Case]:\n        \"\"\"Get all cases from database with fallback\"\"\"\n        try:\n            return Case.query.all()\n        except Exception as e:\n            logging.error(f\"Error getting cases from database: {str(e)}\")\n            # Fallback to in-memory storage\n            return current_app.config.get('CASES_STORAGE', [])\n    \n    def get_case_by_id(self, case_id: int) -> Optional[Case]:\n        \"\"\"Get a specific case by ID from PostgreSQL\"\"\"\n        try:\n            return Case.query.get(case_id)\n        except Exception as e:\n            logging.error(f\"Error getting case {case_id} from database: {str(e)}\")\n            # Fallback to in-memory storage\n            cases = current_app.config.get('CASES_STORAGE', [])\n            for case in cases:\n                if case.id == case_id:\n                    return case\n            return None\n    \n    def add_case(self, problem_description: str, solution: str, system_type: str = \"Unknown\") -> Optional[Case]:\n        \"\"\"Add a new case to the database with robust error handling\"\"\"\n        max_retries = 3\n        retry_count = 0\n        \n        while retry_count < max_retries:\n            try:\n                # Create new case\n                case = Case()\n                case.problem_description = problem_description\n                case.solution = solution\n                case.system_type = system_type\n                \n                # Add to database\n                db.session.add(case)\n                db.session.commit()\n                \n                # Refit vectorizer when new cases are added\n                self._fitted = False\n                \n                logging.info(f\"Added new case #{case.id} to database\")\n                return case\n                \n            except Exception as e:\n                retry_count += 1\n                try:\n                    db.session.rollback()\n                except:\n                    pass\n                    \n                if retry_count < max_retries:\n                    logging.warning(f\"Database error on attempt {retry_count}, retrying: {str(e)}\")\n                    continue\n                else:\n                    logging.error(f\"Failed to add case to database after {max_retries} attempts: {str(e)}\")\n                    return None\n    \n    def update_case(self, case_id: int, problem_description: str, solution: str, system_type: str) -> bool:\n        \"\"\"Update an existing case in PostgreSQL\"\"\"\n        try:\n            case = Case.query.get(case_id)\n            if case:\n                case.problem_description = problem_description\n                case.solution = solution\n                case.system_type = system_type\n                \n                db.session.commit()\n                \n                # Refit vectorizer when cases are updated\n                self._fitted = False\n                \n                logging.info(f\"Updated case #{case_id} in database\")\n                return True\n            \n            return False  # Case not found\n            \n        except Exception as e:\n            db.session.rollback()\n            logging.error(f\"Error updating case {case_id} in database: {str(e)}\")\n            return False\n    \n    def delete_case(self, case_id: int) -> bool:\n        \"\"\"Delete a case from PostgreSQL database\"\"\"\n        try:\n            case = Case.query.get(case_id)\n            if case:\n                db.session.delete(case)\n                db.session.commit()\n                \n                # Refit vectorizer when cases are deleted\n                self._fitted = False\n                \n                logging.info(f\"Deleted case #{case_id} from database\")\n                return True\n            \n            return False  # Case not found\n            \n        except Exception as e:\n            db.session.rollback()\n            logging.error(f\"Error deleting case {case_id} from database: {str(e)}\")\n            return False\n            \n    def add_case_feedback(self, case_id: int, effectiveness_score: int, \n                         resolution_method: str = \"\", custom_solution: str = \"\") -> bool:\n        \"\"\"Add feedback to a case\"\"\"\n        try:\n            case = Case.query.get(case_id)\n            if not case:\n                return False\n                \n            # Add feedback using the model method\n            case.add_feedback(effectiveness_score, resolution_method, custom_solution)\n            db.session.commit()\n            \n            logging.info(f\"Added feedback to case #{case_id}: {resolution_method} (score: {effectiveness_score})\")\n            return True\n            \n        except Exception as e:\n            db.session.rollback()\n            logging.error(f\"Error adding feedback to case {case_id}: {str(e)}\")\n            return False\n    \n    def get_case_feedbacks(self, case_id: int) -> List[CaseFeedback]:\n        \"\"\"Get all feedback for a specific case\"\"\"\n        try:\n            return CaseFeedback.query.filter_by(case_id=case_id).order_by(CaseFeedback.created_at.desc()).all()\n        except Exception as e:\n            logging.error(f\"Error getting feedbacks for case {case_id}: {str(e)}\")\n            return []\n    \n    def find_similar_cases(self, problem_description: str, limit: int = 5) -> List[Case]:\n        \"\"\"Find cases similar to the given problem description using enhanced semantic matching\"\"\"\n        try:\n            cases = self.get_all_cases()\n            \n            if not cases:\n                return []\n            \n            # Use ML service for enhanced semantic similarity\n            from ml_service import MLService\n            ml_service = MLService()\n            \n            # Prepare text corpus with semantic preprocessing\n            case_descriptions = [case.problem_description for case in cases]\n            all_descriptions = case_descriptions + [problem_description]\n            \n            # Use semantic vectorizer for better matching\n            try:\n                semantic_matrix = ml_service.semantic_vectorizer.fit_transform(all_descriptions)\n                self._fitted = True\n            except Exception as e:\n                logging.error(f\"Error with semantic vectorizer: {str(e)}\")\n                # Fallback to standard vectorizer\n                try:\n                    semantic_matrix = self.vectorizer.fit_transform(all_descriptions)\n                    self._fitted = True\n                except Exception as e2:\n                    logging.error(f\"Error fitting fallback vectorizer: {str(e2)}\")\n                    return []\n            \n            # Calculate semantic similarities\n            query_vector = semantic_matrix[-1]  # Last item is the query\n            case_vectors = semantic_matrix[:-1]  # All except the last\n            \n            similarities = cosine_similarity(query_vector, case_vectors).flatten()\n            \n            # Enhanced similarity scoring with semantic boost\n            enhanced_similarities = []\n            query_normalized = ml_service._preprocess_text(problem_description)\n            query_tokens = set(ml_service._semantic_tokenizer(query_normalized))\n            \n            for idx, case in enumerate(cases):\n                base_similarity = similarities[idx]\n                \n                # Calculate semantic boost\n                case_normalized = ml_service._preprocess_text(case.problem_description)\n                case_tokens = set(ml_service._semantic_tokenizer(case_normalized))\n                \n                # Boost for semantic equivalents\n                semantic_boost = 0.0\n                for token in query_tokens:\n                    if token in ml_service.semantic_equivalents:\n                        for equiv in ml_service.semantic_equivalents[token]:\n                            if equiv in case_tokens:\n                                semantic_boost += 0.1\n                \n                # Boost for system type match\n                system_boost = 0.0\n                detected_system = ml_service._detect_system_type(problem_description)\n                if detected_system == case.system_type:\n                    system_boost = 0.2\n                \n                enhanced_similarity = base_similarity + semantic_boost + system_boost\n                enhanced_similarities.append((idx, enhanced_similarity))\n            \n            # Sort by enhanced similarity\n            enhanced_similarities.sort(key=lambda x: x[1], reverse=True)\n            \n            # Get top similar cases with minimum threshold\n            similar_cases = []\n            for idx, similarity in enhanced_similarities[:limit]:\n                if similarity > 0.05:  # Lower threshold due to enhanced scoring\n                    similar_cases.append(cases[idx])\n            \n            return similar_cases\n            \n        except Exception as e:\n            logging.error(f\"Error finding similar cases: {str(e)}\")\n            return []\n    \n    def search_cases(self, query: str, system_filter: str = \"\") -> List[Case]:\n        \"\"\"Enhanced semantic search with aggressive accent normalization and fuzzy matching\"\"\"\n        try:\n            cases = self.get_all_cases()\n            \n            if not query and not system_filter:\n                return cases\n            \n            # Use ML service for enhanced search\n            from ml_service import MLService\n            ml_service = MLService()\n            \n            filtered_cases = []\n            \n            if query:\n                # Advanced query preprocessing\n                query_normalized = ml_service._preprocess_text(query)\n                query_tokens = set(ml_service._semantic_tokenizer(query_normalized))\n                \n                # Create expanded search terms with variations\n                expanded_query_tokens = query_tokens.copy()\n                for token in query_tokens:\n                    if token in ml_service.semantic_equivalents:\n                        expanded_query_tokens.update(ml_service.semantic_equivalents[token][:5])\n                    \n                    # Add common variations for Portuguese\n                    if len(token) > 3:\n                        # Add plural/singular variations\n                        if token.endswith('s'):\n                            expanded_query_tokens.add(token[:-1])  # Remove 's'\n                        else:\n                            expanded_query_tokens.add(token + 's')  # Add 's'\n                        \n                        # Add verb variations\n                        if token.endswith('ar'):\n                            expanded_query_tokens.add(token[:-2] + 'ou')  # -ar to -ou\n                            expanded_query_tokens.add(token[:-2] + 'ando')  # -ar to -ando\n                \n                for case in cases:\n                    # Apply system filter first\n                    if system_filter and case.system_type.lower() != system_filter.lower():\n                        continue\n                    \n                    # Enhanced semantic matching with fuzzy logic\n                    case_description_norm = ml_service._preprocess_text(case.problem_description)\n                    case_solution_norm = ml_service._preprocess_text(case.solution)\n                    \n                    case_desc_tokens = set(ml_service._semantic_tokenizer(case_description_norm))\n                    case_sol_tokens = set(ml_service._semantic_tokenizer(case_solution_norm))\n                    case_all_tokens = case_desc_tokens.union(case_sol_tokens)\n                    \n                    # Calculate enhanced match score\n                    match_score = 0.0\n                    \n                    # Direct token matches (highest weight)\n                    direct_matches = len(query_tokens.intersection(case_all_tokens))\n                    match_score += direct_matches * 5.0\n                    \n                    # Semantic equivalent matches (high weight)\n                    semantic_matches = len(expanded_query_tokens.intersection(case_all_tokens))\n                    match_score += semantic_matches * 2.0\n                    \n                    # Fuzzy substring matching (medium weight)\n                    for query_token in query_tokens:\n                        if len(query_token) > 3:\n                            for case_token in case_all_tokens:\n                                if len(case_token) > 3:\n                                    # Check if tokens are similar (levenshtein-like)\n                                    if (query_token in case_token or case_token in query_token or\n                                        self._tokens_similar(query_token, case_token)):\n                                        match_score += 1.0\n                    \n                    # Raw text substring matching (lower weight but important for phrases)\n                    query_parts = query_normalized.split()\n                    case_full_text = (case_description_norm + ' ' + case_solution_norm).lower()\n                    for part in query_parts:\n                        if len(part) > 2 and part in case_full_text:\n                            match_score += 0.8\n                    \n                    # Include case if there's any meaningful match (lowered threshold)\n                    if match_score > 0.5:\n                        filtered_cases.append((case, match_score))\n                \n                # Sort by match score (highest first)\n                filtered_cases.sort(key=lambda x: x[1], reverse=True)\n                filtered_cases = [case for case, score in filtered_cases]\n                \n            else:\n                # Only system filter, no text query\n                for case in cases:\n                    if system_filter and case.system_type.lower() != system_filter.lower():\n                        continue\n                    filtered_cases.append(case)\n            \n            return filtered_cases\n            \n        except Exception as e:\n            logging.error(f\"Error in enhanced search: {str(e)}\")\n            # Fallback to simple search\n            return self._simple_search_fallback(query, system_filter, cases)\n    \n    def _tokens_similar(self, token1: str, token2: str) -> bool:\n        \"\"\"Check if two tokens are similar using simple fuzzy logic\"\"\"\n        if len(token1) < 3 or len(token2) < 3:\n            return False\n        \n        # Check if one token is contained in another with some flexibility\n        longer = max(token1, token2, key=len)\n        shorter = min(token1, token2, key=len)\n        \n        if len(shorter) / len(longer) < 0.6:  # Too different in length\n            return False\n        \n        # Simple similarity check\n        common_chars = sum(1 for i, char in enumerate(shorter) \n                          if i < len(longer) and char == longer[i])\n        \n        return common_chars / len(shorter) > 0.7\n    \n    def _simple_search_fallback(self, query: str, system_filter: str, cases: List[Case]) -> List[Case]:\n        \"\"\"Fallback simple search if enhanced search fails\"\"\"\n        filtered_cases = []\n        \n        for case in cases:\n            # Apply system filter\n            if system_filter and case.system_type.lower() != system_filter.lower():\n                continue\n            \n            # Apply text search\n            if query:\n                query_lower = query.lower()\n                if (query_lower in case.problem_description.lower() or \n                    query_lower in case.solution.lower()):\n                    filtered_cases.append(case)\n            else:\n                filtered_cases.append(case)\n        \n        return filtered_cases\n    \n    def get_recent_cases(self, limit: int = 10) -> List[Case]:\n        \"\"\"Get most recently added cases\"\"\"\n        try:\n            cases = self.get_all_cases()\n            # Sort by creation date (most recent first)\n            sorted_cases = sorted(cases, key=lambda x: x.created_at, reverse=True)\n            return sorted_cases[:limit]\n            \n        except Exception as e:\n            logging.error(f\"Error getting recent cases: {str(e)}\")\n            return []\n    \n    def get_statistics(self) -> Dict:\n        \"\"\"Get system statistics\"\"\"\n        try:\n            cases = self.get_all_cases()\n            \n            if not cases:\n                return {\n                    'total_cases': 0,\n                    'systems': [],\n                    'systems_dict': {},\n                    'avg_effectiveness': 0,\n                    'cases_with_feedback': 0,\n                    'total_feedback': 0,\n                    'recent_activity': 0\n                }\n            \n            # Count by system type\n            systems = {}\n            total_effectiveness = 0\n            cases_with_feedback = 0\n            recent_cases = 0\n            \n            week_ago = datetime.now() - timedelta(days=7)\n            \n            for case in cases:\n                # System type counts\n                systems[case.system_type] = systems.get(case.system_type, 0) + 1\n                \n                # Effectiveness tracking\n                if case.effectiveness_score is not None:\n                    total_effectiveness += case.effectiveness_score\n                    cases_with_feedback += 1\n                \n                # Recent activity\n                if case.created_at > week_ago:\n                    recent_cases += 1\n            \n            avg_effectiveness = (total_effectiveness / cases_with_feedback) if cases_with_feedback > 0 else 0\n            \n            # Convert systems dict to sorted list for template\n            systems_list = sorted(systems.items(), key=lambda x: x[1], reverse=True)\n            \n            return {\n                'total_cases': len(cases),\n                'systems': systems_list,\n                'systems_dict': systems,\n                'avg_effectiveness': round(avg_effectiveness, 2),\n                'cases_with_feedback': cases_with_feedback,\n                'total_feedback': cases_with_feedback,\n                'recent_activity': recent_cases\n            }\n            \n        except Exception as e:\n            logging.error(f\"Error getting statistics: {str(e)}\")\n            return {\n                'total_cases': 0,\n                'systems': [],\n                'systems_dict': {},\n                'avg_effectiveness': 0,\n                'cases_with_feedback': 0,\n                'total_feedback': 0,\n                'recent_activity': 0\n            }\n    \n    def get_unique_systems(self) -> List[str]:\n        \"\"\"Get list of unique system types\"\"\"\n        try:\n            cases = self.get_all_cases()\n            systems = set(case.system_type for case in cases)\n            return sorted(list(systems))\n            \n        except Exception as e:\n            logging.error(f\"Error getting unique systems: {str(e)}\")\n            return []\n    \n    def add_feedback(self, case_id: int, effectiveness: int) -> bool:\n        \"\"\"Add effectiveness feedback to a case\"\"\"\n        try:\n            case = self.get_case_by_id(case_id)\n            if case:\n                case.add_feedback(effectiveness)\n                logging.info(f\"Added feedback to case #{case_id}: {effectiveness}\")\n                return True\n            return False\n            \n        except Exception as e:\n            logging.error(f\"Error adding feedback: {str(e)}\")\n            return False\n    \n    def delete_all_cases(self) -> int:\n        \"\"\"Delete ALL cases from the database - DESTRUCTIVE OPERATION\"\"\"\n        try:\n            cases = self.get_all_cases()\n            if not cases:\n                return 0\n            \n            deleted_count = 0\n            \n            # Try to delete from database first\n            try:\n                deleted_count = Case.query.count()\n                Case.query.delete()\n                db.session.commit()\n                \n                # Reset vectorizer since all data is gone\n                self._fitted = False\n                \n                logging.warning(f\"BULK DELETE: Removed {deleted_count} cases from database\")\n                \n            except Exception as db_error:\n                logging.error(f\"Database bulk delete failed: {str(db_error)}\")\n                try:\n                    db.session.rollback()\n                except:\n                    pass\n                \n                # Fallback: clear in-memory storage\n                current_app.config['CASES_STORAGE'] = []\n                current_app.config['NEXT_CASE_ID'] = 1\n                deleted_count = len(cases)\n                logging.warning(f\"Fallback: Cleared {deleted_count} cases from memory\")\n            \n            return deleted_count\n            \n        except Exception as e:\n            logging.error(f\"Critical error in bulk delete: {str(e)}\")\n            return 0\n","size_bytes":21405},"file_processor.py":{"content":"\"\"\"\nFile processing module for importing cases from various file formats\n\"\"\"\nimport os\nimport logging\nimport pandas as pd\nfrom typing import List, Dict, Optional\nimport csv\nfrom io import StringIO\nimport json\n\ntry:\n    import PyPDF2\n    PDF_AVAILABLE = True\nexcept ImportError:\n    PDF_AVAILABLE = False\n\ntry:\n    from openai import OpenAI\n    OPENAI_AVAILABLE = True\nexcept ImportError:\n    OPENAI_AVAILABLE = False\n\nclass FileProcessor:\n    def __init__(self):\n        # Sistema 100% interno - sem OpenAI\n        self.openai_client = None\n    \n    def process_file(self, file_path: str, format_type: str = \"auto\") -> List[Dict[str, str]]:\n        \"\"\"\n        Process uploaded file and extract cases\n        \n        Args:\n            file_path: Path to the uploaded file\n            format_type: Only 'structured' supported - no external AI processing\n        \n        Returns:\n            List of dictionaries with 'system_type', 'problem_description', 'solution'\n        \"\"\"\n        file_extension = os.path.splitext(file_path)[1].lower()\n        \n        try:\n            # Sistema interno - apenas formatos estruturados\n            if format_type != \"structured\":\n                raise ValueError(\"Apenas formato estruturado é suportado (sistema 100% interno)\")\n            \n            # Extract raw content based on file type\n            if file_extension in ['.xlsx', '.xls']:\n                content = self._process_excel(file_path, format_type)\n            elif file_extension == '.csv':\n                content = self._process_csv(file_path, format_type)\n            elif file_extension == '.txt':\n                content = self._process_txt(file_path, format_type)\n            elif file_extension == '.pdf' and PDF_AVAILABLE:\n                content = self._process_pdf(file_path, format_type)\n            else:\n                raise ValueError(f\"Formato de arquivo não suportado: {file_extension}\")\n            \n            return content\n            \n        except Exception as e:\n            logging.error(f\"Erro ao processar arquivo {file_path}: {str(e)}\")\n            raise\n    \n    def _process_excel(self, file_path: str, format_type: str) -> List[Dict[str, str]]:\n        \"\"\"Process Excel files\"\"\"\n        df = pd.read_excel(file_path)\n        return self._process_structured_dataframe(df)\n    \n    def _process_csv(self, file_path: str, format_type: str) -> List[Dict[str, str]]:\n        \"\"\"Process CSV files\"\"\"\n        df = pd.read_csv(file_path)\n        return self._process_structured_dataframe(df)\n    \n    def _process_txt(self, file_path: str, format_type: str) -> List[Dict[str, str]]:\n        \"\"\"Process text files\"\"\"\n        with open(file_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n        return self._process_structured_text(content)\n    \n    def _process_pdf(self, file_path: str, format_type: str) -> List[Dict[str, str]]:\n        \"\"\"Process PDF files\"\"\"\n        if not PDF_AVAILABLE:\n            raise ValueError(\"PyPDF2 não está disponível para processar arquivos PDF\")\n        \n        import PyPDF2\n        with open(file_path, 'rb') as f:\n            reader = PyPDF2.PdfReader(f)\n            content = \"\"\n            for page in reader.pages:\n                content += page.extract_text() + \"\\n\"\n        \n        return self._process_structured_text(content)\n    \n    def _process_structured_dataframe(self, df: pd.DataFrame) -> List[Dict[str, str]]:\n        \"\"\"Process structured Excel/CSV with expected columns\"\"\"\n        cases = []\n        \n        # Try to find relevant columns (case-insensitive)\n        columns = {col.lower(): col for col in df.columns}\n        \n        system_col = None\n        problem_col = None\n        solution_col = None\n        \n        # Map common column names (including Portuguese variations)\n        for col_lower, col_original in columns.items():\n            if any(word in col_lower for word in ['sistema', 'system', 'tipo']):\n                system_col = col_original\n            elif any(word in col_lower for word in ['problema', 'problem', 'issue', 'erro', 'error']):\n                problem_col = col_original\n            elif any(word in col_lower for word in ['solução', 'soluçao', 'solution', 'resolução', 'resolucao', 'fix']):\n                solution_col = col_original\n        \n        if not problem_col or not solution_col:\n            raise ValueError(\"Não foi possível identificar as colunas de problema e solução no arquivo\")\n        \n        for _, row in df.iterrows():\n            # Skip empty rows\n            if pd.isna(row[problem_col]).any() if hasattr(pd.isna(row[problem_col]), 'any') else pd.isna(row[problem_col]) or \\\n               pd.isna(row[solution_col]).any() if hasattr(pd.isna(row[solution_col]), 'any') else pd.isna(row[solution_col]):\n                continue\n                \n            system_val = row[system_col] if system_col else None\n            case = {\n                'system_type': str(system_val).strip() if system_col and not (pd.isna(system_val).any() if hasattr(pd.isna(system_val), 'any') else pd.isna(system_val)) else 'Desconhecido',\n                'problem_description': str(row[problem_col]).strip(),\n                'solution': str(row[solution_col]).strip()\n            }\n            \n            # Only add cases with meaningful content\n            if (case['problem_description'] and case['solution'] and \n                case['problem_description'] != 'nan' and case['solution'] != 'nan' and\n                len(case['problem_description']) > 10 and len(case['solution']) > 10):\n                cases.append(case)\n        \n        return cases\n    \n    def _process_structured_text(self, content: str) -> List[Dict[str, str]]:\n        \"\"\"Process structured text with separators\"\"\"\n        cases = []\n        \n        # Split by common separators\n        sections = []\n        if \"---\" in content:\n            sections = content.split(\"---\")\n        elif \"\\n\\n\\n\" in content:\n            sections = content.split(\"\\n\\n\\n\")\n        else:\n            sections = content.split(\"\\n\\n\")\n        \n        for section in sections:\n            section = section.strip()\n            if not section:\n                continue\n            \n            case = self._extract_case_from_text(section)\n            if case:\n                cases.append(case)\n        \n        return cases\n    \n    def _extract_case_from_text(self, text: str) -> Optional[Dict[str, str]]:\n        \"\"\"Extract a case from a text section\"\"\"\n        lines = [line.strip() for line in text.split('\\n') if line.strip()]\n        \n        if len(lines) < 2:\n            return None\n        \n        system_type = \"Desconhecido\"\n        problem_description = \"\"\n        solution = \"\"\n        \n        current_section = \"problem\"\n        \n        for line in lines:\n            # Check for section headers\n            line_lower = line.lower()\n            if any(word in line_lower for word in ['sistema:', 'system:']):\n                system_type = line.split(':', 1)[1].strip()\n            elif any(word in line_lower for word in ['problema:', 'problem:', 'issue:']):\n                current_section = \"problem\"\n                if ':' in line:\n                    problem_description += line.split(':', 1)[1].strip() + \" \"\n            elif any(word in line_lower for word in ['solução:', 'solution:', 'fix:']):\n                current_section = \"solution\"\n                if ':' in line:\n                    solution += line.split(':', 1)[1].strip() + \" \"\n            else:\n                # Add to current section\n                if current_section == \"problem\":\n                    problem_description += line + \" \"\n                elif current_section == \"solution\":\n                    solution += line + \" \"\n        \n        if problem_description.strip() and solution.strip():\n            return {\n                'system_type': system_type,\n                'problem_description': problem_description.strip(),\n                'solution': solution.strip()\n            }\n        \n        return None\n    \n","size_bytes":8050},"main.py":{"content":"from app import app\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000, debug=True)\n","size_bytes":99},"ml_service.py":{"content":"import os\nimport pickle\nimport logging\nimport re\nimport unicodedata\nimport numpy as np\nfrom typing import List, Dict, Tuple, Optional\nfrom datetime import datetime\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\nfrom models import SolutionSuggestion, Case\n\nclass MLService:\n    \"\"\"Machine Learning service for problem analysis and solution suggestions\"\"\"\n    \n    def __init__(self):\n        self.system_classifier = None\n        self.solution_generator = None\n        \n        # Initialize vectorizers without custom methods first\n        self.vectorizer = None\n        self.semantic_vectorizer = None\n        \n        self.label_encoder = LabelEncoder()\n        self.is_trained = False\n        \n        # Multilingual stop words\n        self.stop_words = {\n            'portuguese': {'o', 'a', 'os', 'as', 'um', 'uma', 'uns', 'umas', 'de', 'do', 'da', 'dos', 'das', \n                          'em', 'no', 'na', 'nos', 'nas', 'por', 'para', 'com', 'sem', 'sob', 'sobre',\n                          'e', 'ou', 'mas', 'que', 'se', 'quando', 'onde', 'como', 'porque', 'pois',\n                          'ser', 'estar', 'ter', 'haver', 'fazer', 'ir', 'vir', 'dar', 'ver', 'dizer',\n                          'muito', 'mais', 'menos', 'bem', 'mal', 'só', 'também', 'já', 'ainda', 'sempre'},\n            'english': {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with',\n                       'by', 'from', 'up', 'about', 'into', 'through', 'during', 'before', 'after',\n                       'above', 'below', 'between', 'among', 'this', 'that', 'these', 'those',\n                       'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',\n                       'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must'}\n        }\n        \n        # Enhanced semantic equivalents for better matching\n        self.semantic_equivalents = {\n            # Password related terms - expanded\n            'senha': ['password', 'pass', 'pwd', 'login', 'credencial', 'acesso', 'autenticacao', 'logon', 'autenticar'],\n            'password': ['senha', 'pass', 'pwd', 'login', 'credencial', 'acesso', 'autenticacao', 'logon', 'autenticar'],\n            'recuperar': ['recover', 'reset', 'resetar', 'restaurar', 'redefinir', 'resgatar', 'recuperacao'],\n            'esqueci': ['forgot', 'perdeu', 'perdi', 'esqueceu', 'nao lembro', 'nao sei'],\n            'expirada': ['expired', 'vencida', 'bloqueada', 'blocked', 'invalid', 'invalida', 'venceu'],\n            'expiry': ['expiracao', 'vencimento', 'validade'],\n            'bloqueado': ['blocked', 'travado', 'locked', 'impedido', 'restrito'],\n            'acesso': ['access', 'login', 'entrada', 'logon', 'conectar', 'acessar'],\n            \n            # Network terms\n            'rede': ['network', 'net', 'conectividade', 'conexao', 'connection'],\n            'network': ['rede', 'net', 'conectividade', 'conexao', 'connection'],\n            'internet': ['web', 'online', 'conectividade'],\n            'wifi': ['wireless', 'sem fio', 'wi-fi'],\n            \n            # System terms\n            'sistema': ['system', 'aplicacao', 'application', 'app', 'software'],\n            'system': ['sistema', 'aplicacao', 'application', 'app', 'software'],\n            'erro': ['error', 'falha', 'failure', 'problema', 'problem', 'issue'],\n            'error': ['erro', 'falha', 'failure', 'problema', 'problem', 'issue'],\n            'lento': ['slow', 'devagar', 'performance', 'lag', 'delay'],\n            'slow': ['lento', 'devagar', 'performance', 'lag', 'delay'],\n            \n            # Actions\n            'reiniciar': ['restart', 'reboot', 'reset', 'resetar'],\n            'restart': ['reiniciar', 'reboot', 'reset', 'resetar'],\n            'instalar': ['install', 'setup', 'configurar', 'configure'],\n            'install': ['instalar', 'setup', 'configurar', 'configure'],\n            'atualizar': ['update', 'upgrade', 'refresh', 'sync'],\n            'update': ['atualizar', 'upgrade', 'refresh', 'sync'],\n            \n            # Medical/Hospital terms\n            'paciente': ['patient', 'cliente', 'user', 'usuario'],\n            'medico': ['doctor', 'physician', 'clinician'],\n            'consulta': ['appointment', 'visit', 'session'],\n            'exame': ['exam', 'test', 'procedure', 'procedimento'],\n            'prontuario': ['record', 'chart', 'file', 'history']\n        }\n        \n        # Enhanced system keywords with semantic variations\n        self.system_keywords = {\n            'Tasy': ['tasy', 'hospitalar', 'hospital', 'prontuario', 'paciente', 'atendimento', 'medico',\n                    'record', 'patient', 'medical', 'clinical', 'clinico', 'internacao', 'alta',\n                    'prescricao', 'prescription', 'medication', 'medicamento'],\n            'SGU': ['sgu', 'sistema gestao', 'gestao hospitalar', 'modulo sgu', 'management system',\n                   'hospital management', 'sgu suite', 'suite sgu', 'gestao', 'management'],\n            'SGU Card': ['sgu card', 'cartao', 'card', 'credenciamento', 'carteirinha', 'credential',\n                        'badge', 'identification', 'id card', 'access card', 'cartao acesso'],\n            'Autorizador': ['autorizador', 'autorizacao', 'autorizar', 'procedimento', 'guia',\n                           'authorization', 'authorize', 'procedure', 'guide', 'approval',\n                           'aprovacao', 'liberacao', 'release'],\n            'AutSC': ['autsc', 'aut sc', 'autorizador sc', 'santa catarina', 'sc authorization'],\n            'Contábil': ['contabil', 'accounting', 'financeiro', 'financial', 'contabilidade',\n                        'fiscal', 'tax', 'imposto', 'lancamento', 'entry'],\n            'ERP': ['erp', 'enterprise resource', 'gestao empresarial', 'business management',\n                   'sistema integrado', 'integrated system'],\n            'Exchange Online': ['exchange', 'email', 'outlook', 'mail', 'correio', 'office365',\n                               'o365', 'microsoft exchange', 'webmail'],\n            'Hardware': ['hardware', 'computador', 'computer', 'pc', 'notebook', 'laptop',\n                        'impressora', 'printer', 'monitor', 'teclado', 'keyboard', 'mouse'],\n            'Portal Interno': ['portal interno', 'internal portal', 'intranet', 'portal corporativo',\n                              'corporate portal', 'employee portal', 'funcionario'],\n            'Rede SMB': ['rede smb', 'smb network', 'file sharing', 'compartilhamento arquivo',\n                        'shared folder', 'pasta compartilhada', 'network drive'],\n            'SGUSuite': ['sgu suite', 'sgusuite', 'suite sgu', 'sgu sistema completo'],\n            'VPN FortiClient': ['vpn', 'forticlient', 'forti client', 'remote access', 'acesso remoto',\n                               'conexao remota', 'remote connection', 'trabalho remoto'],\n            'Healthcare': ['saude', 'health', 'emr', 'ehr', 'clinico', 'diagnostico', 'exame',\n                          'clinical', 'diagnosis', 'exam', 'teste', 'laboratorio', 'lab'],\n            'Administrative': ['administrativo', 'admin', 'rh', 'financeiro', 'contabil', 'gestao',\n                              'human resources', 'hr', 'payroll', 'folha pagamento'],\n            'Network': ['rede', 'network', 'router', 'switch', 'firewall', 'ip', 'dns', 'dhcp',\n                       'conectividade', 'connectivity', 'internet', 'wifi', 'wireless'],\n            'Database': ['banco', 'database', 'sql', 'mysql', 'postgres', 'oracle', 'mongodb',\n                        'dados', 'data', 'base dados', 'bd', 'db'],\n            'Application Server': ['servidor', 'server', 'apache', 'nginx', 'tomcat', 'iis', 'aplicacao',\n                                  'application', 'app server', 'web server', 'servico', 'service']\n        }\n        \n        # Common solutions patterns\n        self.solution_patterns = {\n            'restart': ['Reiniciar o serviço', 'Verificar se o processo está rodando', 'Realizar restart do sistema'],\n            'permissions': ['Verificar permissões de usuário', 'Checar grupos de acesso', 'Validar credenciais'],\n            'network': ['Testar conectividade de rede', 'Verificar configurações de firewall', 'Validar DNS'],\n            'database': ['Verificar conexão com banco de dados', 'Checar logs do banco', 'Validar consultas SQL'],\n            'memory': ['Verificar uso de memória', 'Limpar cache', 'Reiniciar serviços que consomem muita RAM'],\n            'disk': ['Verificar espaço em disco', 'Limpar arquivos temporários', 'Mover arquivos grandes']\n        }\n        \n        # Initialize vectorizers after methods are defined\n        self._initialize_vectorizers()\n        \n        # Load trained models if they exist\n        self._load_models()\n    \n    def _initialize_vectorizers(self):\n        \"\"\"Initialize vectorizers after methods are defined\"\"\"\n        # Enhanced vectorizer with multilingual support\n        self.vectorizer = TfidfVectorizer(\n            max_features=2000,\n            ngram_range=(1, 3),  # Unigrams, bigrams, and trigrams\n            min_df=1,\n            max_df=0.95,\n            analyzer='word',\n            lowercase=True,\n            stop_words=None,  # We'll handle stop words ourselves\n            preprocessor=self._preprocess_text,\n            tokenizer=self._enhanced_tokenizer\n        )\n        \n        # Enhanced semantic vectorizer for similarity matching\n        self.semantic_vectorizer = TfidfVectorizer(\n            max_features=5000,\n            ngram_range=(1, 4),\n            min_df=1,\n            max_df=0.9,\n            analyzer='word',\n            lowercase=True,\n            preprocessor=self._semantic_preprocess,\n            tokenizer=self._semantic_tokenizer\n        )\n    \n    def _preprocess_text(self, text: str) -> str:\n        \"\"\"Enhanced text preprocessing with aggressive normalization\"\"\"\n        if not text:\n            return \"\"\n        \n        # Convert to lowercase\n        text = text.lower()\n        \n        # Remove accents and normalize unicode more aggressively\n        text = unicodedata.normalize('NFD', text)\n        text = ''.join(char for char in text if unicodedata.category(char) != 'Mn')\n        \n        # Enhanced accent handling - specific Portuguese replacements\n        accent_map = {\n            'à': 'a', 'á': 'a', 'â': 'a', 'ã': 'a', 'ä': 'a',\n            'è': 'e', 'é': 'e', 'ê': 'e', 'ë': 'e',\n            'ì': 'i', 'í': 'i', 'î': 'i', 'ï': 'i',\n            'ò': 'o', 'ó': 'o', 'ô': 'o', 'õ': 'o', 'ö': 'o',\n            'ù': 'u', 'ú': 'u', 'û': 'u', 'ü': 'u',\n            'ç': 'c', 'ñ': 'n'\n        }\n        for accented, plain in accent_map.items():\n            text = text.replace(accented, plain)\n        \n        # Normalize common contractions and abbreviations\n        contractions = {\n            'nao': 'não', 'pq': 'porque', 'vc': 'voce', 'tb': 'tambem',\n            'q': 'que', 'eh': 'e', 'soh': 'so', 'td': 'tudo'\n        }\n        for short, full in contractions.items():\n            text = text.replace(short, full)\n        \n        # Remove punctuation but keep meaningful characters\n        text = re.sub(r'[^\\w\\s-]', ' ', text)\n        \n        # Normalize whitespace\n        text = re.sub(r'\\s+', ' ', text).strip()\n        \n        return text\n    \n    def _enhanced_tokenizer(self, text: str) -> List[str]:\n        \"\"\"Enhanced tokenizer with semantic expansion\"\"\"\n        if not text:\n            return []\n        \n        # Basic tokenization\n        tokens = text.split()\n        \n        # Filter out stop words\n        filtered_tokens = []\n        for token in tokens:\n            if token not in self.stop_words['portuguese'] and token not in self.stop_words['english']:\n                if len(token) > 1:  # Keep tokens with more than 1 character\n                    filtered_tokens.append(token)\n        \n        # Add semantic equivalents\n        expanded_tokens = filtered_tokens.copy()\n        for token in filtered_tokens:\n            if token in self.semantic_equivalents:\n                expanded_tokens.extend(self.semantic_equivalents[token][:3])  # Add top 3 equivalents\n        \n        return expanded_tokens\n    \n    def _semantic_preprocess(self, text: str) -> str:\n        \"\"\"Semantic preprocessing for similarity matching\"\"\"\n        if not text:\n            return \"\"\n        \n        # Basic preprocessing\n        text = self._preprocess_text(text)\n        \n        # Expand with semantic equivalents\n        words = text.split()\n        expanded_words = []\n        \n        for word in words:\n            expanded_words.append(word)\n            if word in self.semantic_equivalents:\n                # Add semantic equivalents with lower weight\n                for equiv in self.semantic_equivalents[word][:2]:\n                    expanded_words.append(equiv)\n        \n        return ' '.join(expanded_words)\n    \n    def _semantic_tokenizer(self, text: str) -> List[str]:\n        \"\"\"Semantic tokenizer for enhanced similarity matching\"\"\"\n        if not text:\n            return []\n        \n        tokens = text.split()\n        \n        # Remove stop words and short tokens\n        meaningful_tokens = []\n        for token in tokens:\n            if (token not in self.stop_words['portuguese'] and \n                token not in self.stop_words['english'] and \n                len(token) > 2):\n                meaningful_tokens.append(token)\n        \n        return meaningful_tokens\n    \n    def analyze_problem(self, problem_description: str, similar_cases: list = None) -> SolutionSuggestion:\n        \"\"\"Analyze problem description and provide ML-based suggestions with priority for similar cases\"\"\"\n        try:\n            # Detect system type\n            system_type = self._detect_system_type(problem_description)\n            \n            # Generate solution suggestions with similar cases priority\n            suggestions = self._generate_solutions_with_similar_cases(problem_description, system_type, similar_cases)\n            \n            # Calculate confidence\n            confidence = self._calculate_confidence(problem_description, system_type, suggestions)\n            \n            return SolutionSuggestion(\n                problem_description=problem_description,\n                suggested_solutions=suggestions,\n                confidence=confidence,\n                system_type=system_type\n            )\n            \n        except Exception as e:\n            logging.error(f\"Error in ML analysis: {str(e)}\")\n            return SolutionSuggestion(\n                problem_description=problem_description,\n                suggested_solutions=[\"Erro na análise ML. Consulte a base de conhecimento manualmente.\"],\n                confidence=0.1,\n                system_type=\"Unknown\"\n            )\n    \n    def _detect_system_type(self, problem_description: str) -> str:\n        \"\"\"Detect system type using keyword matching and ML if available\"\"\"\n        problem_lower = problem_description.lower()\n        \n        # Score each system type based on keywords\n        scores = {}\n        for system, keywords in self.system_keywords.items():\n            score = 0\n            for keyword in keywords:\n                if keyword in problem_lower:\n                    score += 1\n            scores[system] = score\n        \n        # Get the system with highest score\n        if scores and max(scores.values()) > 0:\n            detected_system = max(scores.keys(), key=lambda k: scores[k])\n            return detected_system\n        \n        # If no keywords matched, try ML classifier if trained\n        if self.system_classifier and self.is_trained:\n            try:\n                prediction = self.system_classifier.predict([problem_description])\n                return self.label_encoder.inverse_transform(prediction)[0]\n            except Exception as e:\n                logging.error(f\"Error in ML system detection: {str(e)}\")\n        \n        return \"Unknown\"\n    \n    def _generate_solutions(self, problem_description: str, system_type: str) -> List[str]:\n        \"\"\"Generate diverse solution suggestions based on enhanced problem analysis\"\"\"\n        problem_normalized = self._preprocess_text(problem_description)\n        problem_tokens = set(self._semantic_tokenizer(problem_normalized))\n        suggestions = []\n        \n        # Enhanced pattern-based solution generation with more variety\n        \n        # Password/Authentication issues\n        if any(token in problem_tokens for token in ['senha', 'password', 'login', 'acesso', 'autenticacao', 'esqueci']):\n            auth_solutions = [\n                \"Verificar se o usuário está digitando a senha corretamente\",\n                \"Resetar senha do usuário no sistema administrativo\",\n                \"Verificar se a conta não está bloqueada por tentativas\",\n                \"Checar configurações de política de senhas\",\n                \"Validar sincronização com Active Directory se aplicável\"\n            ]\n            suggestions.extend(auth_solutions[:3])  # Add variety by taking different amounts\n        \n        # Network/Connection issues\n        if any(token in problem_tokens for token in ['conectar', 'conexao', 'rede', 'network', 'internet']):\n            network_solutions = [\n                \"Testar conectividade com ping para o servidor\",\n                \"Verificar configurações de proxy e firewall\",\n                \"Reiniciar adaptador de rede no computador\",\n                \"Checar cabos de rede e switches\",\n                \"Verificar configurações DNS e DHCP\",\n                \"Testar conectividade em outro computador\"\n            ]\n            suggestions.extend(network_solutions[:2])  # Take fewer to keep variety\n        \n        # Database/Performance issues\n        if any(token in problem_tokens for token in ['banco', 'database', 'sql', 'lento', 'slow', 'performance']):\n            db_solutions = [\n                \"Verificar logs de erro do banco de dados\",\n                \"Analisar queries lentas em execução\",\n                \"Checar espaço disponível no servidor\",\n                \"Reiniciar serviços do banco de dados\",\n                \"Verificar índices e estatísticas do banco\",\n                \"Monitorar uso de CPU e memória do servidor\"\n            ]\n            suggestions.extend(db_solutions[:2])\n        \n        # System/Application errors\n        if any(token in problem_tokens for token in ['erro', 'error', 'falha', 'exception', 'crash']):\n            error_solutions = [\n                \"Consultar logs de aplicação para detalhes do erro\",\n                \"Verificar se problema é reproduzível\",\n                \"Checar atualizações pendentes do sistema\",\n                \"Validar integridade dos arquivos de sistema\",\n                \"Reiniciar serviços relacionados ao problema\"\n            ]\n            suggestions.extend(error_solutions[:2])\n        \n        # Hardware/Infrastructure issues  \n        if any(token in problem_tokens for token in ['hardware', 'impressora', 'printer', 'computador', 'pc']):\n            hardware_solutions = [\n                \"Verificar conexões físicas dos equipamentos\",\n                \"Testar em outro computador para isolar problema\",\n                \"Verificar drivers de dispositivos\",\n                \"Checar logs de eventos do Windows\",\n                \"Reiniciar equipamentos envolvidos\"\n            ]\n            suggestions.extend(hardware_solutions[:2])\n        \n        # Add system-specific solutions for variety\n        system_specific = self._get_diversified_system_solutions(system_type, problem_tokens)\n        suggestions.extend(system_specific)\n        \n        # If no specific patterns matched, add contextual generic solutions\n        if not suggestions:\n            generic_solutions = [\n                \"Verificar logs do sistema para identificar causa raiz\",\n                \"Reproduzir problema com usuário de teste\",\n                \"Documentar passos exatos que levaram ao problema\",\n                \"Checar se problema afeta outros usuários\",\n                \"Verificar últimas alterações no sistema\"\n            ]\n            suggestions.extend(generic_solutions[:3])\n        \n        # Ensure variety by shuffling and limiting\n        import random\n        unique_suggestions = list(dict.fromkeys(suggestions))\n        if len(unique_suggestions) > 5:\n            # Keep some determinism but add variety\n            priority_suggestions = unique_suggestions[:3]  # Keep top 3\n            random_suggestions = random.sample(unique_suggestions[3:], min(2, len(unique_suggestions)-3))\n            unique_suggestions = priority_suggestions + random_suggestions\n        \n        return unique_suggestions[:5] if unique_suggestions else [\n            \"Analisar logs detalhados do sistema\",\n            \"Contatar suporte especializado\",\n            \"Documentar cenário completo do problema\"\n        ]\n    \n    def _convert_to_infinitive(self, text: str) -> str:\n        \"\"\"Convert common past participle forms to infinitive\"\"\"\n        # Common past participle to infinitive conversions for Portuguese\n        conversions = {\n            # Pattern: past participle -> infinitive\n            'corrigida': 'corrigir',\n            'corrigido': 'corrigir', \n            'analisada': 'analisar',\n            'analisado': 'analisar',\n            'ajustada': 'ajustar',\n            'ajustado': 'ajustar',\n            'verificada': 'verificar',\n            'verificado': 'verificar',\n            'checada': 'checar',\n            'checado': 'checar',\n            'configurada': 'configurar',\n            'configurado': 'configurar',\n            'resetada': 'resetar',\n            'resetado': 'resetar',\n            'reiniciada': 'reiniciar',\n            'reiniciado': 'reiniciar',\n            'atualizada': 'atualizar',\n            'atualizado': 'atualizar',\n            'validada': 'validar',\n            'validado': 'validar',\n            'testada': 'testar',\n            'testado': 'testar',\n            'consultada': 'consultar',\n            'consultado': 'consultar',\n            'documentada': 'documentar',\n            'documentado': 'documentar',\n            'monitorada': 'monitorar',\n            'monitorado': 'monitorar'\n        }\n        \n        # Apply conversions\n        result = text.lower()\n        for past_participle, infinitive in conversions.items():\n            result = result.replace(past_participle, infinitive)\n        \n        # Capitalize first letter to maintain original format\n        if result and result[0].islower() and text and text[0].isupper():\n            result = result[0].upper() + result[1:]\n            \n        return result\n\n    def _generate_solutions_with_similar_cases(self, problem_description: str, system_type: str, similar_cases: list = None) -> List[str]:\n        \"\"\"Generate solutions with INTELLIGENT RANKING based on feedback learning\"\"\"\n        suggestions = []\n        \n        # PRIORITY 1: Solutions from similar cases with SMART SCORING\n        if similar_cases:\n            similar_solutions = []\n            for case in similar_cases[:5]:  # Consider more cases for better learning\n                if hasattr(case, 'solution') and case.solution:\n                    solution = case.solution.strip()\n                    solution = self._convert_to_infinitive(solution)\n                    \n                    if solution and solution not in [s['text'] for s in similar_solutions]:\n                        # Calculate intelligent score based on feedback learning\n                        effectiveness_score = self._calculate_solution_effectiveness_score(solution, problem_description)\n                        similar_solutions.append({\n                            'text': solution,\n                            'score': effectiveness_score,\n                            'case_id': getattr(case, 'id', None),\n                            'source': 'similar_case'\n                        })\n            \n            # Sort by intelligent score (highest first)\n            similar_solutions.sort(key=lambda x: x['score'], reverse=True)\n            suggestions.extend([s['text'] for s in similar_solutions[:3]])  # Top 3 by score\n            logging.info(f\"Added {len(similar_solutions)} intelligently ranked solutions from similar cases\")\n        \n        # PRIORITY 2: Pattern-based solutions with SMART RANKING\n        if len(suggestions) < 4:\n            pattern_solutions = self._generate_solutions(problem_description, system_type)\n            \n            # Apply intelligent scoring to pattern solutions\n            scored_pattern_solutions = []\n            for solution in pattern_solutions:\n                converted_solution = self._convert_to_infinitive(solution)\n                if converted_solution not in suggestions:\n                    effectiveness_score = self._calculate_solution_effectiveness_score(converted_solution, problem_description)\n                    scored_pattern_solutions.append({\n                        'text': converted_solution,\n                        'score': effectiveness_score,\n                        'source': 'pattern'\n                    })\n            \n            # Sort by score and add the best ones\n            scored_pattern_solutions.sort(key=lambda x: x['score'], reverse=True)\n            for solution in scored_pattern_solutions:\n                if len(suggestions) < 5:\n                    suggestions.append(solution['text'])\n        \n        # INTELLIGENT FINAL RANKING: Re-rank all suggestions by combined score\n        if hasattr(self, 'suggestion_ranking_weights'):\n            suggestions = self._apply_intelligent_final_ranking(suggestions, problem_description)\n        \n        # Ensure we have suggestions with fallback\n        if not suggestions:\n            suggestions = [\n                \"Verificar logs detalhados do sistema para identificar a causa raiz\",\n                \"Reproduzir o problema em ambiente de teste\",\n                \"Consultar base de conhecimento interna\",\n                \"Contatar suporte especializado se necessário\",\n                \"Documentar cenário completo para análise\"\n            ]\n        \n        # Apply infinitive conversion to ALL suggestions\n        final_suggestions = [self._convert_to_infinitive(solution) for solution in suggestions[:5]]\n        \n        logging.info(f\"Generated {len(final_suggestions)} intelligently ranked solutions\")\n        return final_suggestions\n    \n    def _calculate_solution_effectiveness_score(self, solution_text: str, problem_description: str) -> float:\n        \"\"\"Calculate effectiveness score for a solution based on learned feedback patterns\"\"\"\n        try:\n            if not hasattr(self, 'solution_effectiveness'):\n                return 1.0  # Default score\n            \n            # Extract tokens from both solution and problem\n            solution_tokens = set(self._semantic_tokenizer(self._preprocess_text(solution_text)))\n            problem_tokens = set(self._semantic_tokenizer(self._preprocess_text(problem_description)))\n            \n            # Calculate base score using solution effectiveness weights\n            total_score = 0.0\n            token_count = 0\n            \n            for token in solution_tokens.union(problem_tokens):\n                # Look for helpful patterns\n                helpful_pattern = f\"{token}_helpful\"\n                not_helpful_pattern = f\"{token}_not_helpful\"\n                \n                if helpful_pattern in self.solution_effectiveness:\n                    total_score += self.solution_effectiveness[helpful_pattern]['weight']\n                    token_count += 1\n                elif not_helpful_pattern in self.solution_effectiveness:\n                    # Penalize tokens associated with not helpful feedback\n                    total_score += (2.0 - self.solution_effectiveness[not_helpful_pattern]['weight'])\n                    token_count += 1\n                else:\n                    total_score += 1.0  # Neutral score for unknown tokens\n                    token_count += 1\n            \n            # Calculate average score\n            if token_count > 0:\n                average_score = total_score / token_count\n            else:\n                average_score = 1.0\n            \n            # Bonus for successful combination patterns\n            if hasattr(self, 'feedback_patterns'):\n                for combo in self.feedback_patterns.get('successful_combinations', []):\n                    # Check if this solution matches successful patterns\n                    matching_tokens = set(combo['problem_tokens']).intersection(solution_tokens.union(problem_tokens))\n                    if len(matching_tokens) >= 2:  # At least 2 tokens match\n                        # Apply success rate bonus\n                        average_score *= (1 + combo['success_rate'] * 0.3)\n            \n            # Ensure score is within reasonable bounds\n            return max(0.1, min(3.0, average_score))\n            \n        except Exception as e:\n            logging.error(f\"Error calculating solution effectiveness score: {str(e)}\")\n            return 1.0\n    \n    def _apply_intelligent_final_ranking(self, suggestions: List[str], problem_description: str) -> List[str]:\n        \"\"\"Apply final intelligent ranking to suggestions based on learned patterns\"\"\"\n        try:\n            # Score each suggestion\n            scored_suggestions = []\n            problem_tokens = set(self._semantic_tokenizer(self._preprocess_text(problem_description)))\n            \n            for suggestion in suggestions:\n                # Calculate comprehensive score\n                effectiveness_score = self._calculate_solution_effectiveness_score(suggestion, problem_description)\n                \n                # Apply ranking weights\n                ranking_bonus = 0.0\n                suggestion_tokens = set(self._semantic_tokenizer(self._preprocess_text(suggestion)))\n                \n                for token in suggestion_tokens.intersection(problem_tokens):\n                    if hasattr(self, 'suggestion_ranking_weights') and token in self.suggestion_ranking_weights:\n                        ranking_bonus += self.suggestion_ranking_weights[token]\n                \n                final_score = effectiveness_score + (ranking_bonus * 0.2)  # 20% bonus from ranking weights\n                \n                scored_suggestions.append({\n                    'text': suggestion,\n                    'score': final_score\n                })\n            \n            # Sort by final score\n            scored_suggestions.sort(key=lambda x: x['score'], reverse=True)\n            \n            # Return ranked suggestions\n            return [s['text'] for s in scored_suggestions]\n            \n        except Exception as e:\n            logging.error(f\"Error applying intelligent final ranking: {str(e)}\")\n            return suggestions\n    \n    def _get_diversified_system_solutions(self, system_type: str, problem_tokens: set) -> List[str]:\n        \"\"\"Get diversified system-specific solutions based on context\"\"\"\n        solutions = []\n        \n        if system_type == \"Tasy\":\n            if 'login' in problem_tokens or 'senha' in problem_tokens:\n                solutions.append(\"Verificar usuário no cadastro de funcionários do Tasy\")\n            elif 'impressao' in problem_tokens or 'relatorio' in problem_tokens:\n                solutions.append(\"Checar configuração de impressoras no Tasy\")\n            elif 'lento' in problem_tokens or 'performance' in problem_tokens:\n                solutions.append(\"Verificar performance de queries no banco Tasy\")\n            else:\n                solutions.append(\"Consultar logs específicos do módulo Tasy afetado\")\n        \n        elif system_type == \"SGU\":\n            if 'autorizacao' in problem_tokens:\n                solutions.append(\"Verificar regras de autorização no SGU\")\n            elif 'relatorio' in problem_tokens:\n                solutions.append(\"Checar permissões de relatórios no SGU\")\n            else:\n                solutions.append(\"Validar configurações de módulos SGU\")\n        \n        elif system_type == \"Autorizador\":\n            if 'guia' in problem_tokens or 'procedimento' in problem_tokens:\n                solutions.append(\"Verificar fila de processamento de guias\")\n            elif 'operadora' in problem_tokens:\n                solutions.append(\"Checar conectividade com webservices das operadoras\")\n            else:\n                solutions.append(\"Analisar logs de autorização em tempo real\")\n        \n        # Add escalation path\n        solutions.append(\"Considerar abertura de chamado Nexdow se necessário\")\n        \n        return solutions[:2]  # Limit to 2 for variety\n    \n    def _get_system_specific_solutions(self, system_type: str, problem_description: str) -> List[str]:\n        \"\"\"Get system-specific solution suggestions\"\"\"\n        solutions = []\n        \n        if system_type == \"Tasy\":\n            solutions = [\n                \"Verificar configurações do módulo Tasy específico\",\n                \"Consultar logs do sistema Tasy\",\n                \"Verificar integridade da base de dados Tasy\",\n                \"Checar configurações de usuário no Tasy\",\n                \"Verificar se problema requer chamado para Nexdow\"\n            ]\n        elif system_type == \"SGU\":\n            solutions = [\n                \"Verificar status dos serviços SGU\",\n                \"Consultar logs de erro do SGU\",\n                \"Checar conectividade com base de dados SGU\",\n                \"Validar configurações de módulos SGU\",\n                \"Considerar abertura de chamado Nexdow se necessário\"\n            ]\n        elif system_type == \"SGU Card\":\n            solutions = [\n                \"Verificar serviços de credenciamento\",\n                \"Consultar logs do módulo Card\",\n                \"Checar sincronização de dados de carteirinha\",\n                \"Validar configurações de impressão de cartões\",\n                \"Abrir chamado Nexdow se problema persistir\"\n            ]\n        elif system_type == \"Autorizador\":\n            solutions = [\n                \"Verificar fila de autorizações pendentes\",\n                \"Consultar logs do sistema autorizador\",\n                \"Checar conectividade com operadoras\",\n                \"Validar regras de autorização\",\n                \"Escalar para Nexdow casos complexos\"\n            ]\n        elif system_type == \"Healthcare\":\n            solutions = [\n                \"Verificar conectividade com sistemas de saúde\",\n                \"Validar protocolos de comunicação HL7/FHIR\",\n                \"Checar configurações de prontuário eletrônico\"\n            ]\n        elif system_type == \"Network\":\n            solutions = [\n                \"Verificar configurações de switch/router\",\n                \"Testar conectividade ping/traceroute\",\n                \"Analisar logs de firewall\",\n                \"Verificar configurações VLAN\"\n            ]\n        elif system_type == \"Database\":\n            solutions = [\n                \"Verificar performance de queries\",\n                \"Analisar locks e deadlocks\",\n                \"Checar espaço em tablespaces\",\n                \"Validar backup e recovery\"\n            ]\n        \n        # Add generic Nexdow escalation option\n        solutions.append(\"Se problema não for resolvido, abrir chamado para Nexdow\")\n        \n        return solutions\n    \n    def _calculate_confidence(self, problem_description: str, system_type: str, suggestions: List[str]) -> float:\n        \"\"\"Calculate confidence score based on various factors\"\"\"\n        confidence = 0.5  # Base confidence\n        \n        # Increase confidence based on description length and detail\n        if len(problem_description) > 50:\n            confidence += 0.1\n        if len(problem_description) > 100:\n            confidence += 0.1\n        if len(problem_description) > 200:\n            confidence += 0.1\n        \n        # Increase confidence if system type is detected\n        if system_type != \"Unknown\":\n            confidence += 0.2\n        \n        # Increase confidence based on number of relevant suggestions\n        if len(suggestions) >= 3:\n            confidence += 0.1\n        \n        # Check for technical keywords\n        technical_keywords = ['erro', 'falha', 'exception', 'timeout', 'connection', 'database', 'server']\n        keyword_count = sum(1 for keyword in technical_keywords if keyword in problem_description.lower())\n        confidence += min(keyword_count * 0.05, 0.2)\n        \n        return min(confidence, 1.0)\n    \n    def train_models(self, cases: List[Case]) -> bool:\n        \"\"\"Train ML models with existing cases\"\"\"\n        if len(cases) < 5:  # Need minimum cases to train\n            logging.info(\"Not enough cases to train ML models\")\n            return False\n        \n        try:\n            # Prepare training data\n            descriptions = [case.problem_description for case in cases]\n            system_types = [case.system_type for case in cases if case.system_type != \"Unknown\"]\n            \n            if len(system_types) < 3:  # Need minimum variety\n                logging.info(\"Not enough system type variety to train classifier\")\n                return False\n            \n            # Train system type classifier\n            filtered_descriptions = [cases[i].problem_description for i, case in enumerate(cases) \n                                   if case.system_type != \"Unknown\"]\n            \n            if len(filtered_descriptions) >= 3:\n                # Encode labels\n                encoded_labels = self.label_encoder.fit_transform(system_types)\n                \n                # Create and train pipeline\n                self.system_classifier = Pipeline([\n                    ('tfidf', TfidfVectorizer(stop_words='english', max_features=500)),\n                    ('classifier', MultinomialNB())\n                ])\n                \n                self.system_classifier.fit(filtered_descriptions, encoded_labels)\n                self.is_trained = True\n                \n                # Save models\n                self._save_models()\n                \n                logging.info(f\"Trained ML models with {len(cases)} cases\")\n                return True\n            \n            return False\n            \n        except Exception as e:\n            logging.error(f\"Error training ML models: {str(e)}\")\n            return False\n    \n    def process_analysis_feedback(self, feedback):\n        \"\"\"Process feedback from analysis to improve future suggestions using advanced ML learning\"\"\"\n        try:\n            import json\n            from app import db\n            from models import AnalysisFeedback\n            \n            # Parse feedback data\n            suggestion_ratings = json.loads(feedback.suggestion_ratings or \"{}\")\n            good_aspects = json.loads(feedback.good_aspects or \"[]\")\n            improvements = json.loads(feedback.improvements or \"[]\")\n            \n            # Analyze feedback patterns\n            helpful_suggestions = sum(1 for rating in suggestion_ratings.values() if rating == \"helpful\")\n            total_suggestions = len(suggestion_ratings)\n            \n            if total_suggestions > 0:\n                success_rate = helpful_suggestions / total_suggestions\n                \n                # ADVANCED LEARNING: Update solution effectiveness weights\n                self._update_solution_effectiveness_weights(feedback.problem_description, suggestion_ratings)\n                \n                # SMART PATTERN DETECTION: Learn from feedback patterns\n                self._learn_from_feedback_patterns(feedback.problem_description, suggestion_ratings, \n                                                 feedback.detected_system, good_aspects, improvements)\n                \n                # Log comprehensive feedback analysis\n                logging.info(f\"Advanced ML Feedback: {success_rate:.1%} helpful, Score: {feedback.overall_score}/5, \"\n                           f\"System: {feedback.detected_system}, Learning from patterns\")\n                \n                # INTELLIGENT RETRAINING: Based on feedback quality and frequency\n                feedback_count = db.session.query(AnalysisFeedback).count()\n                \n                # More frequent retraining for better learning\n                if feedback_count % 5 == 0:  # Retrain every 5 feedback entries for faster learning\n                    logging.info(f\"Triggering intelligent ML retrain after {feedback_count} feedback entries\")\n                    case_service = self._get_case_service()\n                    all_cases = case_service.get_all_cases()\n                    if len(all_cases) >= 3:  # Lower threshold for more dynamic learning\n                        self.train_models(all_cases)\n                        self._update_suggestion_ranking_model()\n                \n        except Exception as e:\n            logging.error(f\"Error processing analysis feedback: {str(e)}\")\n    \n    def _update_solution_effectiveness_weights(self, problem_description, suggestion_ratings):\n        \"\"\"Update effectiveness weights for solution patterns based on feedback\"\"\"\n        try:\n            # Initialize solution effectiveness tracking if not exists\n            if not hasattr(self, 'solution_effectiveness'):\n                self.solution_effectiveness = {}\n            \n            # Extract key terms from problem for pattern matching\n            problem_tokens = set(self._semantic_tokenizer(self._preprocess_text(problem_description)))\n            \n            # Update weights for each rated suggestion\n            for suggestion_index, rating in suggestion_ratings.items():\n                # Create pattern key from problem tokens and rating\n                for token in problem_tokens:\n                    pattern_key = f\"{token}_{rating}\"\n                    \n                    if pattern_key not in self.solution_effectiveness:\n                        self.solution_effectiveness[pattern_key] = {'helpful': 0, 'not_helpful': 0, 'weight': 1.0}\n                    \n                    # Update counters\n                    self.solution_effectiveness[pattern_key][rating] += 1\n                    \n                    # Calculate new effectiveness weight (helpful vs not_helpful ratio)\n                    helpful_count = self.solution_effectiveness[pattern_key]['helpful']\n                    not_helpful_count = self.solution_effectiveness[pattern_key]['not_helpful']\n                    \n                    if helpful_count + not_helpful_count > 0:\n                        # Weight between 0.1 and 2.0 based on success rate\n                        success_rate = helpful_count / (helpful_count + not_helpful_count)\n                        self.solution_effectiveness[pattern_key]['weight'] = 0.1 + (success_rate * 1.9)\n            \n            logging.info(f\"Updated solution effectiveness weights for {len(problem_tokens)} tokens\")\n            \n        except Exception as e:\n            logging.error(f\"Error updating solution effectiveness weights: {str(e)}\")\n    \n    def _learn_from_feedback_patterns(self, problem_description, suggestion_ratings, detected_system, good_aspects, improvements):\n        \"\"\"Advanced pattern learning from comprehensive feedback data\"\"\"\n        try:\n            # Initialize pattern learning storage\n            if not hasattr(self, 'feedback_patterns'):\n                self.feedback_patterns = {\n                    'system_accuracy': {},  # Track system detection accuracy\n                    'solution_patterns': {},  # Track which solution patterns work best\n                    'improvement_requests': {},  # Track what users want improved\n                    'successful_combinations': []  # Track successful problem-solution combinations\n                }\n            \n            # Learn system detection accuracy\n            system_key = detected_system or 'Unknown'\n            if system_key not in self.feedback_patterns['system_accuracy']:\n                self.feedback_patterns['system_accuracy'][system_key] = {'correct': 0, 'total': 0}\n            \n            # Assume system detection is correct if overall feedback is positive\n            helpful_count = sum(1 for rating in suggestion_ratings.values() if rating == \"helpful\")\n            if helpful_count >= len(suggestion_ratings) / 2:  # If majority helpful, system detection likely correct\n                self.feedback_patterns['system_accuracy'][system_key]['correct'] += 1\n            self.feedback_patterns['system_accuracy'][system_key]['total'] += 1\n            \n            # Learn from improvement requests\n            for improvement in improvements:\n                if improvement not in self.feedback_patterns['improvement_requests']:\n                    self.feedback_patterns['improvement_requests'][improvement] = 0\n                self.feedback_patterns['improvement_requests'][improvement] += 1\n            \n            # Record successful combinations for future reference\n            if helpful_count >= len(suggestion_ratings) / 2:\n                self.feedback_patterns['successful_combinations'].append({\n                    'problem_tokens': self._semantic_tokenizer(self._preprocess_text(problem_description)),\n                    'system': detected_system,\n                    'success_rate': helpful_count / len(suggestion_ratings),\n                    'good_aspects': good_aspects\n                })\n                \n                # Keep only the best 100 combinations to avoid memory issues\n                if len(self.feedback_patterns['successful_combinations']) > 100:\n                    # Sort by success rate and keep top 100\n                    self.feedback_patterns['successful_combinations'].sort(\n                        key=lambda x: x['success_rate'], reverse=True\n                    )\n                    self.feedback_patterns['successful_combinations'] = self.feedback_patterns['successful_combinations'][:100]\n            \n            logging.info(f\"Advanced pattern learning: Updated patterns for {detected_system}, \"\n                        f\"Success combinations: {len(self.feedback_patterns['successful_combinations'])}\")\n            \n        except Exception as e:\n            logging.error(f\"Error in feedback pattern learning: {str(e)}\")\n    \n    def _update_suggestion_ranking_model(self):\n        \"\"\"Update internal ranking model based on learned feedback patterns\"\"\"\n        try:\n            if not hasattr(self, 'feedback_patterns') or not hasattr(self, 'solution_effectiveness'):\n                return\n            \n            # Create intelligent suggestion ranking weights\n            self.suggestion_ranking_weights = {}\n            \n            # Weight based on solution effectiveness\n            for pattern_key, effectiveness_data in self.solution_effectiveness.items():\n                if '_helpful' in pattern_key:\n                    token = pattern_key.replace('_helpful', '')\n                    self.suggestion_ranking_weights[token] = effectiveness_data.get('weight', 1.0)\n            \n            # Weight successful combinations higher\n            for combo in self.feedback_patterns.get('successful_combinations', []):\n                for token in combo['problem_tokens']:\n                    if token in self.suggestion_ranking_weights:\n                        # Boost weight for tokens in successful combinations\n                        self.suggestion_ranking_weights[token] *= (1 + combo['success_rate'] * 0.5)\n                    else:\n                        self.suggestion_ranking_weights[token] = 1 + combo['success_rate'] * 0.5\n            \n            logging.info(f\"Updated suggestion ranking model with {len(self.suggestion_ranking_weights)} intelligent weights\")\n            \n        except Exception as e:\n            logging.error(f\"Error updating suggestion ranking model: {str(e)}\")\n    \n    def _get_case_service(self):\n        \"\"\"Get case service instance with import handling\"\"\"\n        try:\n            from case_service import CaseService\n            return CaseService()\n        except ImportError:\n            # Fallback for circular import issues\n            from app import current_app\n            return current_app.config.get('case_service_instance')\n    \n    def _save_models(self):\n        \"\"\"Save trained models AND intelligent learning data to disk\"\"\"\n        try:\n            models_dir = \"ml_models\"\n            os.makedirs(models_dir, exist_ok=True)\n            \n            if self.system_classifier:\n                with open(f\"{models_dir}/system_classifier.pkl\", \"wb\") as f:\n                    pickle.dump(self.system_classifier, f)\n            \n            if hasattr(self, 'label_encoder'):\n                with open(f\"{models_dir}/label_encoder.pkl\", \"wb\") as f:\n                    pickle.dump(self.label_encoder, f)\n            \n            # ADVANCED: Save intelligent learning data\n            learning_data = {\n                'solution_effectiveness': getattr(self, 'solution_effectiveness', {}),\n                'feedback_patterns': getattr(self, 'feedback_patterns', {}),\n                'suggestion_ranking_weights': getattr(self, 'suggestion_ranking_weights', {}),\n                'learning_version': '2.0'  # Version for future compatibility\n            }\n            with open(f\"{models_dir}/intelligent_learning.pkl\", \"wb\") as f:\n                pickle.dump(learning_data, f)\n            \n            # Save enhanced metadata\n            metadata = {\n                'trained_at': datetime.now().isoformat(),\n                'is_trained': self.is_trained,\n                'learning_data_saved': True,\n                'solution_patterns_count': len(getattr(self, 'solution_effectiveness', {})),\n                'successful_combinations_count': len(getattr(self, 'feedback_patterns', {}).get('successful_combinations', [])),\n                'ranking_weights_count': len(getattr(self, 'suggestion_ranking_weights', {}))\n            }\n            with open(f\"{models_dir}/metadata.pkl\", \"wb\") as f:\n                pickle.dump(metadata, f)\n            \n            logging.info(f\"Saved ML models with intelligent learning data: \"\n                        f\"{metadata['solution_patterns_count']} patterns, \"\n                        f\"{metadata['successful_combinations_count']} successful combinations\")\n                \n        except Exception as e:\n            logging.error(f\"Error saving ML models: {str(e)}\")\n    \n    def _load_models(self):\n        \"\"\"Load trained models AND intelligent learning data from disk\"\"\"\n        try:\n            models_dir = \"ml_models\"\n            \n            # Load system classifier\n            classifier_path = f\"{models_dir}/system_classifier.pkl\"\n            if os.path.exists(classifier_path):\n                with open(classifier_path, \"rb\") as f:\n                    self.system_classifier = pickle.load(f)\n            \n            # Load label encoder\n            encoder_path = f\"{models_dir}/label_encoder.pkl\"\n            if os.path.exists(encoder_path):\n                with open(encoder_path, \"rb\") as f:\n                    self.label_encoder = pickle.load(f)\n            \n            # ADVANCED: Load intelligent learning data\n            learning_path = f\"{models_dir}/intelligent_learning.pkl\"\n            if os.path.exists(learning_path):\n                with open(learning_path, \"rb\") as f:\n                    learning_data = pickle.load(f)\n                    \n                    # Restore intelligent learning attributes\n                    self.solution_effectiveness = learning_data.get('solution_effectiveness', {})\n                    self.feedback_patterns = learning_data.get('feedback_patterns', {})\n                    self.suggestion_ranking_weights = learning_data.get('suggestion_ranking_weights', {})\n                    \n                    logging.info(f\"Loaded intelligent learning data: \"\n                               f\"{len(self.solution_effectiveness)} solution patterns, \"\n                               f\"{len(self.feedback_patterns.get('successful_combinations', []))} successful combinations, \"\n                               f\"{len(self.suggestion_ranking_weights)} ranking weights\")\n            \n            # Load metadata\n            metadata_path = f\"{models_dir}/metadata.pkl\"\n            if os.path.exists(metadata_path):\n                with open(metadata_path, \"rb\") as f:\n                    metadata = pickle.load(f)\n                    self.is_trained = metadata.get('is_trained', False)\n            \n            if self.system_classifier and self.is_trained:\n                learning_info = \"\"\n                if hasattr(self, 'solution_effectiveness'):\n                    learning_info = f\" with {len(self.solution_effectiveness)} learned patterns\"\n                logging.info(f\"Loaded trained ML models{learning_info}\")\n            \n        except Exception as e:\n            logging.error(f\"Error loading ML models: {str(e)}\")\n            self.is_trained = False\n    \n    def get_model_info(self) -> Dict:\n        \"\"\"Get comprehensive information about trained models and learning progress\"\"\"\n        # Calculate learning statistics\n        solution_effectiveness_count = len(getattr(self, 'solution_effectiveness', {}))\n        successful_combinations_count = len(getattr(self, 'feedback_patterns', {}).get('successful_combinations', []))\n        ranking_weights_count = len(getattr(self, 'suggestion_ranking_weights', {}))\n        \n        # Calculate system detection accuracy if available\n        system_accuracy = {}\n        if hasattr(self, 'feedback_patterns') and 'system_accuracy' in self.feedback_patterns:\n            for system, stats in self.feedback_patterns['system_accuracy'].items():\n                if stats['total'] > 0:\n                    accuracy = stats['correct'] / stats['total']\n                    system_accuracy[system] = {\n                        'accuracy': round(accuracy * 100, 1),\n                        'total_analyzed': stats['total']\n                    }\n        \n        # Get top improvement requests\n        top_improvements = {}\n        if hasattr(self, 'feedback_patterns') and 'improvement_requests' in self.feedback_patterns:\n            improvements = self.feedback_patterns['improvement_requests']\n            # Get top 5 most requested improvements\n            sorted_improvements = sorted(improvements.items(), key=lambda x: x[1], reverse=True)\n            top_improvements = dict(sorted_improvements[:5])\n        \n        return {\n            'is_trained': self.is_trained,\n            'has_system_classifier': self.system_classifier is not None,\n            'supported_systems': list(self.system_keywords.keys()),\n            'learning_statistics': {\n                'solution_effectiveness_patterns': solution_effectiveness_count,\n                'successful_combinations': successful_combinations_count,\n                'ranking_weights': ranking_weights_count,\n                'learning_active': solution_effectiveness_count > 0\n            },\n            'system_detection_accuracy': system_accuracy,\n            'top_improvement_requests': top_improvements,\n            'learning_version': '2.0 - Advanced Intelligent Learning'\n        }\n    \n    def get_learning_insights(self) -> Dict:\n        \"\"\"Get insights about what the system has learned from feedback\"\"\"\n        insights = {\n            'most_effective_solutions': [],\n            'least_effective_patterns': [],\n            'best_performing_systems': [],\n            'learning_recommendations': []\n        }\n        \n        try:\n            # Most effective solution patterns\n            if hasattr(self, 'solution_effectiveness'):\n                effective_patterns = []\n                for pattern_key, data in self.solution_effectiveness.items():\n                    if '_helpful' in pattern_key and data['helpful'] > 2:  # At least 3 helpful votes\n                        token = pattern_key.replace('_helpful', '')\n                        success_rate = data['helpful'] / (data['helpful'] + data.get('not_helpful', 0))\n                        effective_patterns.append({\n                            'pattern': token,\n                            'success_rate': round(success_rate * 100, 1),\n                            'total_feedback': data['helpful'] + data.get('not_helpful', 0)\n                        })\n                \n                # Sort by success rate and take top 10\n                effective_patterns.sort(key=lambda x: x['success_rate'], reverse=True)\n                insights['most_effective_solutions'] = effective_patterns[:10]\n            \n            # Best performing systems\n            if hasattr(self, 'feedback_patterns') and 'system_accuracy' in self.feedback_patterns:\n                system_performance = []\n                for system, stats in self.feedback_patterns['system_accuracy'].items():\n                    if stats['total'] >= 3:  # At least 3 analyses\n                        accuracy = stats['correct'] / stats['total']\n                        system_performance.append({\n                            'system': system,\n                            'accuracy': round(accuracy * 100, 1),\n                            'total_analyses': stats['total']\n                        })\n                \n                system_performance.sort(key=lambda x: x['accuracy'], reverse=True)\n                insights['best_performing_systems'] = system_performance\n            \n            # Learning recommendations\n            recommendations = []\n            if len(insights['most_effective_solutions']) > 0:\n                recommendations.append(\"Sistema aprendendo com sucesso - padrões efetivos identificados\")\n            if len(insights['best_performing_systems']) > 0:\n                best_system = insights['best_performing_systems'][0]\n                recommendations.append(f\"Detecção mais precisa para sistema {best_system['system']} ({best_system['accuracy']}%)\")\n            \n            if hasattr(self, 'feedback_patterns') and len(self.feedback_patterns.get('improvement_requests', {})) > 0:\n                top_request = max(self.feedback_patterns['improvement_requests'].items(), key=lambda x: x[1])\n                recommendations.append(f\"Principal melhoria solicitada: {top_request[0]}\")\n            \n            insights['learning_recommendations'] = recommendations\n            \n        except Exception as e:\n            logging.error(f\"Error generating learning insights: {str(e)}\")\n        \n        return insights","size_bytes":58837},"models.py":{"content":"from app import db\nfrom datetime import datetime\nfrom typing import List, Dict, Optional\nfrom flask_sqlalchemy import SQLAlchemy\n\n\nclass Case(db.Model):\n    \"\"\"Model for storing work order cases\"\"\"\n    \n    __tablename__ = 'cases'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    problem_description = db.Column(db.Text, nullable=False)\n    solution = db.Column(db.Text, nullable=False)\n    system_type = db.Column(db.String(100), default=\"Unknown\")\n    created_at = db.Column(db.DateTime, default=datetime.now)\n    effectiveness_score = db.Column(db.Float, nullable=True)\n    feedback_count = db.Column(db.Integer, default=0)\n    tags = db.Column(db.String(500), default=\"\")  # Stored as comma-separated string\n    \n    # Relationship to feedback entries\n    feedbacks = db.relationship(\"CaseFeedback\", backref=\"case\", cascade=\"all, delete-orphan\")\n    \n    def get_tags_list(self) -> List[str]:\n        \"\"\"Get tags as a list\"\"\"\n        return [tag.strip() for tag in self.tags.split(',') if tag.strip()] if self.tags else []\n    \n    def set_tags_list(self, tags: List[str]):\n        \"\"\"Set tags from a list\"\"\"\n        self.tags = ','.join(tags) if tags else \"\"\n        \n    def to_dict(self) -> Dict:\n        \"\"\"Convert case to dictionary for JSON serialization\"\"\"\n        return {\n            'id': self.id,\n            'problem_description': self.problem_description,\n            'solution': self.solution,\n            'system_type': self.system_type,\n            'created_at': self.created_at.isoformat() if self.created_at else None,\n            'effectiveness_score': self.effectiveness_score,\n            'feedback_count': self.feedback_count,\n            'tags': self.get_tags_list()\n        }\n    \n    def add_feedback(self, effectiveness: int, resolution_method: str = \"\", \n                    custom_solution: str = \"\"):\n        \"\"\"Add effectiveness feedback (1-5 scale)\"\"\"\n        if self.effectiveness_score is None:\n            self.effectiveness_score = effectiveness\n        else:\n            # Calculate running average\n            total_score = self.effectiveness_score * self.feedback_count + effectiveness\n            self.effectiveness_score = total_score / (self.feedback_count + 1)\n        \n        self.feedback_count += 1\n        \n        # Create feedback record\n        feedback = CaseFeedback()\n        feedback.case_id = self.id\n        feedback.effectiveness_score = effectiveness\n        feedback.resolution_method = resolution_method\n        feedback.custom_solution = custom_solution\n        db.session.add(feedback)\n        db.session.commit()\n\n\nclass CaseFeedback(db.Model):\n    \"\"\"Model for storing detailed feedback on case resolutions\"\"\"\n    \n    __tablename__ = 'case_feedbacks'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    case_id = db.Column(db.Integer, db.ForeignKey('cases.id'), nullable=False)\n    effectiveness_score = db.Column(db.Integer, nullable=False)  # 1-5 scale\n    resolution_method = db.Column(db.String(50), default=\"\")  # \"first_suggestion\", \"custom\", \"not_resolved\"\n    custom_solution = db.Column(db.Text, default=\"\")  # What actually worked\n    created_at = db.Column(db.DateTime, default=datetime.now)\n\n\nclass AnalysisFeedback(db.Model):\n    \"\"\"Model for storing feedback on AI analysis and suggestions\"\"\"\n    \n    __tablename__ = 'analysis_feedbacks'\n    \n    id = db.Column(db.Integer, primary_key=True)\n    problem_description = db.Column(db.Text, nullable=False)  # The analyzed problem\n    overall_score = db.Column(db.Integer, nullable=False)  # 1-5 scale\n    suggestion_ratings = db.Column(db.Text, default=\"{}\")  # JSON: {\"0\": \"helpful\", \"1\": \"not_helpful\"}\n    good_aspects = db.Column(db.Text, default=\"[]\")  # JSON: [\"relevant\", \"clear\"]\n    improvements = db.Column(db.Text, default=\"[]\")  # JSON: [\"speed\", \"detail\"]\n    comments = db.Column(db.Text, default=\"\")\n    detected_system = db.Column(db.String(100), default=\"\")  # What system was detected\n    created_at = db.Column(db.DateTime, default=datetime.now)\n    \n    def to_dict(self) -> Dict:\n        \"\"\"Convert analysis feedback to dictionary\"\"\"\n        import json\n        return {\n            'id': self.id,\n            'problem_description': self.problem_description,\n            'overall_score': self.overall_score,\n            'suggestion_ratings': json.loads(self.suggestion_ratings or \"{}\"),\n            'good_aspects': json.loads(self.good_aspects or \"[]\"),\n            'improvements': json.loads(self.improvements or \"[]\"),\n            'comments': self.comments,\n            'detected_system': self.detected_system,\n            'created_at': self.created_at.isoformat() if self.created_at else None\n        }\n        \"\"\"Convert feedback to dictionary\"\"\"\n        return {\n            'id': self.id,\n            'case_id': self.case_id,\n            'effectiveness_score': self.effectiveness_score,\n            'resolution_method': self.resolution_method,\n            'custom_solution': self.custom_solution,\n            'created_at': self.created_at.isoformat() if self.created_at else None\n        }\n\n\nclass SolutionSuggestion:\n    \"\"\"Model for ML-generated solution suggestions\"\"\"\n    \n    def __init__(self, problem_description: str, suggested_solutions: List[str],\n                 confidence: float, system_type: str, similar_cases: Optional[List[Case]] = None):\n        self.problem_description = problem_description\n        self.suggested_solutions = suggested_solutions\n        self.confidence = confidence\n        self.system_type = system_type\n        self.similar_cases = similar_cases or []\n        self.generated_at = datetime.now()\n    \n    def to_dict(self) -> Dict:\n        \"\"\"Convert suggestion to dictionary\"\"\"\n        return {\n            'problem_description': self.problem_description,\n            'suggested_solutions': self.suggested_solutions,\n            'confidence': self.confidence,\n            'system_type': self.system_type,\n            'similar_cases': [case.to_dict() for case in self.similar_cases],\n            'generated_at': self.generated_at.isoformat()\n        }","size_bytes":6063},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"email-validator>=2.2.0\",\n    \"flask>=3.1.1\",\n    \"flask-sqlalchemy>=3.1.1\",\n    \"gunicorn>=23.0.0\",\n    \"numpy>=2.3.2\",\n    \"openai>=1.99.9\",\n    \"openpyxl>=3.1.5\",\n    \"pandas>=2.3.1\",\n    \"psycopg2-binary>=2.9.10\",\n    \"pypdf2>=3.0.1\",\n    \"scikit-learn>=1.7.1\",\n    \"sqlalchemy>=2.0.43\",\n    \"werkzeug>=3.1.3\",\n]\n","size_bytes":463},"replit.md":{"content":"# OS Assistant - AI Technical Support System\n\n## Overview\n\nOS Assistant is a machine learning-powered technical support system designed to help technicians diagnose and resolve work order issues across multiple systems. The application serves as a \"digital mentor\" that analyzes problem descriptions and suggests solutions based on historical cases and proprietary ML models.\n\nThe system focuses on multi-system support (particularly Brazilian hospital management systems like Tasy, SGU, SGU Card, and Autorizador) and uses custom machine learning algorithms to continuously improve its recommendations through user feedback and case history. It operates as a completely internal system with NO external AI dependencies, learning from exported data, reports, or manually entered information using its own ML engine. The system includes workflow for escalating complex cases to Nexdow when internal resolution is not possible.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\nInterface language: Portuguese (complete system translation implemented)\nSpecific systems supported: Tasy, SGU, SGU Card, Autorizador (Brazilian hospital systems)\nEscalation workflow: Include Nexdow escalation options when internal resolution fails\nCase management: Full CRUD operations (Create, Read, Update, Delete) for case management\nUpload functionality: Excel/CSV/PDF import for bulk case addition (structured format only)\nTutorial system: Complete documentation and usage guide integrated\nSecurity requirement: NO external AI connections - system must be 100% internal\nSearch integration: Integrated search within cases panel (no separate search box)\nColor preferences: Avoid black, gray, and silver in system badge colors - use bright color palette only\nUI guidance: Remove all tooltips and hints from interface, consolidate all guidance in tutorial menu (keep input placeholders)\n\n## System Architecture\n\n### Core Architecture Pattern\nThe application follows a traditional Flask MVC architecture with service layer separation:\n\n- **Frontend**: Server-side rendered HTML templates with Bootstrap for responsive UI\n- **Backend**: Flask web framework with modular service-based architecture\n- **Storage**: PostgreSQL database with full persistence and multi-user synchronization\n- **AI Processing**: Custom ML service using scikit-learn for intelligent problem analysis (100% internal)\n\n### Key Architectural Components\n\n**Web Framework**\n- Flask application with blueprint-style route organization\n- Session management with configurable secret keys\n- Template-based rendering using Jinja2\n\n**Service Layer Architecture**\n- `MLService`: Custom machine learning service using scikit-learn for problem analysis, system type detection, and solution generation\n- `CaseService`: Manages case storage, similarity searches using TF-IDF vectorization, and statistics generation\n- Modular design allows easy service replacement or enhancement\n\n**Machine Learning Architecture**\n- Custom ML pipeline using scikit-learn for classification and pattern recognition\n- TF-IDF vectorization for text analysis and similarity matching\n- Support Vector Machine (SVM) and Naive Bayes classifiers for system type detection\n- Rule-based solution generation with pattern matching\n- Incremental learning capabilities that improve with more case data\n\n**Data Models**\n- `Case`: Core entity storing problem descriptions, solutions, system types, and effectiveness feedback\n- `SolutionSuggestion`: Container for AI-generated recommendations with confidence scoring\n- In-memory storage with simple list-based persistence for rapid prototyping\n- Full CRUD operations implemented: Create, Read, Update, Delete cases\n- Real-time ML model retraining after case modifications\n\n**Machine Learning Integration**\n- Scikit-learn TF-IDF vectorization for case similarity matching\n- Cosine similarity calculations for finding related historical cases\n- Continuous learning through user feedback and effectiveness scoring\n\n**Frontend Architecture**\n- Bootstrap-based responsive design with dark theme\n- Feather Icons for consistent iconography\n- Complete Portuguese language interface\n- JavaScript for enhanced UX (form validation, auto-save, search functionality, deletion confirmation)\n- CRUD interface for case management with inline editing and deletion\n\n### Design Patterns and Principles\n\n**Service-Oriented Design**\nThe application separates concerns into distinct services, making it easy to replace components (e.g., switching from in-memory to database storage, or changing AI providers).\n\n**Template-Based UI**\nUses Flask's template inheritance for consistent page layouts and reusable components across all views.\n\n**Stateless Design**\nThe application stores state in Flask's application config, making it easy to transition to external databases when needed.\n\n## External Dependencies\n\n### AI/ML Services (100% Internal)\n- **Scikit-learn**: Complete ML pipeline including TF-IDF vectorization, classification models (SVM, Naive Bayes), and similarity calculations\n- **Custom ML Service**: Proprietary machine learning algorithms for system type detection and solution pattern matching\n- **Model Persistence**: Pickle-based model storage for training persistence and performance optimization\n- **No External AI**: System operates completely offline without OpenAI or any external AI service dependencies\n\n### Frontend Libraries\n- **Bootstrap**: Responsive UI framework with dark theme support\n- **Feather Icons**: Icon library for consistent interface elements\n\n### Python Framework Stack\n- **Flask**: Core web framework for routing and request handling\n- **Jinja2**: Template engine for server-side rendering\n- **NumPy**: Mathematical operations for similarity calculations\n\n### Development Dependencies\n- **Logging**: Built-in Python logging for debugging and error tracking\n- Environment variable management for API keys and configuration\n\nThe system is designed to be easily deployable with Docker and can be hosted on various cloud platforms (AWS, Azure, GCP) or on-premises servers.\n\n## Recent Updates (August 2025)\n\n**Migration to Replit Standard Environment (Completed August 18, 2025):**\n- ✅ Successfully migrated from Replit Agent to standard Replit environment\n- ✅ Fixed all package dependencies and gunicorn server configuration\n- ✅ Corrected navbar alignment and centering issues for perfect UI presentation\n- ✅ Fixed JavaScript scroll button errors and undefined variable issues\n- ✅ Fixed JavaScript syntax errors in templates that were causing browser console errors\n- ✅ Updated case detail page button to properly navigate to recent cases instead of dashboard\n- ✅ Migration to Replit standard environment completed successfully on August 18, 2025\n- ✅ Dashboard completely restructured with modern design and improved graphics\n- ✅ Fixed 'total_feedback' attribute error in statistics system\n- ✅ Removed unnecessary feedback card as requested by user\n- ✅ Improved layout with 3-column card structure for better proportions\n- ✅ Implemented unique color system with 14 bright colors, avoiding black/gray/silver\n- ✅ Ensured color consistency between badges and progress bars with no duplicates\n- Implemented PostgreSQL database with full persistence and connection pooling\n- Fixed all import/export functionality with robust Excel processing\n- Enhanced file processor to handle Portuguese column names and data validation\n- Improved error handling and database connection stability\n- Created comprehensive system documentation (DOCUMENTACAO_SISTEMA.md)\n- Validated import functionality with 100+ real case data from user upload\n- All security requirements maintained: 100% internal processing, no external AI dependencies\n\n**Database Status:**\n- PostgreSQL database fully operational with 200+ cases stored\n- Enhanced connection pooling with better timeout and pool size management\n- Automatic fallback to SQLite (os_assistant.db) if PostgreSQL connectivity issues occur\n- Full CRUD operations implemented and tested\n- Fixed database connection issues that caused worker crashes during import\n- New AnalysisFeedback table created for comprehensive feedback tracking\n\n**Import Functionality:**\n- Fixed \"Internal Server Error\" during file imports\n- Enhanced error handling to prevent application crashes\n- Improved batch processing for large Excel files\n- Added progress logging for import operations\n- Handles Portuguese column names correctly (Problema, Solução, Sistema)\n- Validates data quality and skips invalid entries\n\n**Local Deployment Ready:**\n- Created robust SQLite fallback for local deployment\n- Added run_local.py script for easy local execution\n- Enhanced database connection resilience with retry logic\n- Created complete setup documentation (setup_local.md)\n- System now automatically uses SQLite when PostgreSQL unavailable\n- Ready for deployment on user's local machine with zero external dependencies\n\n**Advanced ML Learning System (August 2025):**\n- Implemented comprehensive feedback storage in PostgreSQL database\n- Created AnalysisFeedback model to store detailed feedback on AI analysis\n- **MAJOR UPGRADE**: Advanced intelligent learning from \"useful\" and \"not useful\" feedback ratings\n- Real-time solution effectiveness scoring based on user feedback patterns\n- Smart suggestion ranking that prioritizes solutions with higher success rates\n- Automatic pattern recognition that learns from successful problem-solution combinations\n- Intelligent retraining every 5 feedback submissions (increased frequency for faster learning)\n- Enhanced system detection accuracy tracking with performance analytics\n- Solution effectiveness weights automatically adjust based on feedback history\n- New /ml-learning-info route provides comprehensive learning analytics and insights\n- Machine Learning Learning Version 2.0: Fully adaptive system that truly learns from every feedback","size_bytes":9912},"routes.py":{"content":"from flask import render_template, request, jsonify, redirect, url_for, flash\nfrom werkzeug.utils import secure_filename\nfrom app import app\nfrom models import Case, SolutionSuggestion\nfrom ml_service import MLService\nfrom case_service import CaseService\nfrom file_processor import FileProcessor\nimport logging\nimport os\nimport tempfile\nfrom datetime import datetime, timedelta\n\n# Initialize services\nml_service = MLService()\ncase_service = CaseService()\nfile_processor = FileProcessor()\n\n@app.route('/')\ndef index():\n    \"\"\"Main page with problem input form\"\"\"\n    try:\n        recent_cases = case_service.get_recent_cases(limit=6)\n        return render_template('index.html', recent_cases=recent_cases)\n    except Exception as e:\n        logging.error(f\"Error loading recent cases: {str(e)}\")\n        return render_template('index.html', recent_cases=[])\n\n@app.route('/analyze', methods=['POST'])\ndef analyze_problem():\n    \"\"\"Analyze problem and provide AI suggestions\"\"\"\n    try:\n        problem_description = request.form.get('problem_description', '').strip()\n        \n        if not problem_description:\n            flash('Please enter a problem description.', 'error')\n            return redirect(url_for('index'))\n        \n        # Find similar cases first\n        similar_cases = case_service.find_similar_cases(problem_description, limit=5)\n        \n        # Get ML analysis and suggestions with similar cases priority\n        suggestion = ml_service.analyze_problem(problem_description, similar_cases)\n        suggestion.similar_cases = similar_cases\n        \n        # Get recent cases for reference\n        recent_cases = case_service.get_recent_cases(limit=6)\n        \n        return render_template('index.html', \n                             suggestion=suggestion, \n                             problem_description=problem_description,\n                             recent_cases=recent_cases)\n        \n    except Exception as e:\n        logging.error(f\"Error analyzing problem: {str(e)}\")\n        flash(f'Error analyzing problem: {str(e)}', 'error')\n        return redirect(url_for('index'))\n\n@app.route('/dashboard')\ndef dashboard():\n    \"\"\"Dashboard showing analytics and system overview\"\"\"\n    try:\n        stats = case_service.get_statistics()\n        return render_template('dashboard.html', stats=stats)\n        \n    except Exception as e:\n        logging.error(f\"Error loading dashboard: {str(e)}\")\n        flash(f'Error loading dashboard: {str(e)}', 'error')\n        return render_template('dashboard.html', stats={})\n\n@app.route('/recent-cases')\ndef recent_cases():\n    \"\"\"Page dedicated to recent cases with search and pagination\"\"\"\n    search_query = request.args.get('search', '').strip()\n    system_filter = request.args.get('system', '')\n    sort_by = request.args.get('sort', 'recent')\n    page = int(request.args.get('page', 1))\n    per_page = 30  # Cases per page\n    \n    try:\n        # Get all cases first\n        if search_query or system_filter:\n            all_cases = case_service.search_cases(search_query, system_filter)\n        else:\n            all_cases = case_service.get_all_cases()\n        \n        # Apply sorting\n        if sort_by == 'oldest':\n            all_cases = sorted(all_cases, key=lambda x: x.created_at or datetime.min)\n        elif sort_by == 'system':\n            all_cases = sorted(all_cases, key=lambda x: x.system_type)\n        else:  # recent (default)\n            all_cases = sorted(all_cases, key=lambda x: x.created_at or datetime.min, reverse=True)\n        \n        # Calculate pagination\n        total_cases = len(all_cases)\n        total_pages = (total_cases + per_page - 1) // per_page if total_cases > 0 else 1\n        start_idx = (page - 1) * per_page\n        end_idx = start_idx + per_page\n        cases = all_cases[start_idx:end_idx]\n        \n        # Pagination info\n        has_prev = page > 1\n        has_next = page < total_pages\n        prev_page = page - 1 if has_prev else None\n        next_page = page + 1 if has_next else None\n        \n        # Get additional stats for the page\n        stats = case_service.get_statistics()\n        systems = case_service.get_unique_systems()\n        \n        # Quick stats for this page\n        today_cases = len([c for c in all_cases if c.created_at and c.created_at.date() == datetime.now().date()]) if all_cases else 0\n        week_cases = len([c for c in all_cases if c.created_at and c.created_at >= datetime.now() - timedelta(days=7)]) if all_cases else 0\n        with_feedback = len([c for c in all_cases if c.effectiveness_score is not None]) if all_cases else 0\n        \n        return render_template('recent_cases.html',\n                             cases=cases,\n                             search_query=search_query,\n                             system_filter=system_filter,\n                             sort_by=sort_by,\n                             systems=systems,\n                             # Pagination\n                             current_page=page,\n                             total_pages=total_pages,\n                             total_cases=total_cases,\n                             has_prev=has_prev,\n                             has_next=has_next,\n                             prev_page=prev_page,\n                             next_page=next_page,\n                             # Quick stats\n                             today_cases=today_cases,\n                             week_cases=week_cases,\n                             with_feedback=with_feedback)\n        \n    except Exception as e:\n        logging.error(f\"Error loading recent cases: {str(e)}\")\n        flash(f'Error loading cases: {str(e)}', 'error')\n        return render_template('recent_cases.html', cases=[], systems=[], total_cases=0, total_pages=1, current_page=1, has_prev=False, has_next=False)\n\n@app.route('/cases')\ndef list_cases():\n    \"\"\"List all cases with search functionality\"\"\"\n    search_query = request.args.get('search', '').strip()\n    system_filter = request.args.get('system', '')\n    \n    try:\n        if search_query or system_filter:\n            cases = case_service.search_cases(search_query, system_filter)\n        else:\n            cases = case_service.get_all_cases()\n        \n        systems = case_service.get_unique_systems()\n        \n        return render_template('dashboard.html', \n                             cases=cases, \n                             search_query=search_query,\n                             system_filter=system_filter,\n                             systems=systems)\n        \n    except Exception as e:\n        logging.error(f\"Error listing cases: {str(e)}\")\n        flash(f'Error loading cases: {str(e)}', 'error')\n        return render_template('dashboard.html', cases=[], systems=[])\n\n@app.route('/cases/<int:case_id>')\ndef view_case(case_id):\n    \"\"\"Show detailed view of a specific case\"\"\"\n    try:\n        case = case_service.get_case_by_id(case_id)\n        if not case:\n            flash('Case not found.', 'error')\n            return redirect(url_for('dashboard'))\n        \n        return render_template('case_detail.html', case=case)\n        \n    except Exception as e:\n        logging.error(f\"Error loading case {case_id}: {str(e)}\")\n        flash(f'Error loading case: {str(e)}', 'error')\n        return redirect(url_for('dashboard'))\n\n@app.route('/add_case')\ndef add_case_form():\n    \"\"\"Show form to add a new case manually\"\"\"\n    return render_template('add_case.html')\n\n@app.route('/add_case', methods=['POST'])\ndef add_case():\n    \"\"\"Add a new case to the knowledge base\"\"\"\n    try:\n        problem_description = request.form.get('problem_description', '').strip()\n        solution = request.form.get('solution', '').strip()\n        system_type = request.form.get('system_type', 'Desconhecido').strip()\n        custom_system = request.form.get('custom_system', '').strip()\n        \n        # Se selecionou \"Outros\", usar o sistema customizado\n        if system_type == 'Outros' and custom_system:\n            system_type = custom_system\n        \n        if not problem_description or not solution:\n            flash('Descrição do problema e solução são obrigatórias.', 'error')\n            return render_template('add_case.html')\n        \n        case = case_service.add_case(problem_description, solution, system_type)\n        \n        # Retrain ML models with new case\n        all_cases = case_service.get_all_cases()\n        if len(all_cases) >= 5:  # Only retrain if we have enough cases\n            ml_service.train_models(all_cases)\n        \n        flash(f'Case #{case.id} added successfully!', 'success')\n        \n        return redirect(url_for('view_case', case_id=case.id))\n        \n    except Exception as e:\n        logging.error(f\"Error adding case: {str(e)}\")\n        flash(f'Error adding case: {str(e)}', 'error')\n        return render_template('add_case.html')\n\n@app.route('/cases/<int:case_id>/feedback')\ndef case_feedback_form(case_id):\n    \"\"\"Show detailed feedback form for a specific case\"\"\"\n    try:\n        case = case_service.get_case_by_id(case_id)\n        if not case:\n            flash('Caso não encontrado.', 'error')\n            return redirect(url_for('dashboard'))\n        \n        return render_template('case_feedback.html', case=case)\n        \n    except Exception as e:\n        logging.error(f\"Error loading feedback form for case {case_id}: {str(e)}\")\n        flash(f'Erro ao carregar formulário de feedback: {str(e)}', 'error')\n        return redirect(url_for('dashboard'))\n\n@app.route('/cases/<int:case_id>/feedback', methods=['POST'])\ndef add_case_feedback(case_id):\n    \"\"\"Add detailed feedback to a case\"\"\"\n    try:\n        effectiveness_score = request.form.get('effectiveness_score', type=int)\n        resolution_method = request.form.get('resolution_method', '').strip()\n        custom_solution = request.form.get('custom_solution', '').strip()\n        \n        if not effectiveness_score or effectiveness_score < 1 or effectiveness_score > 5:\n            flash('Avaliação deve ser entre 1 e 5 estrelas.', 'error')\n            return redirect(url_for('case_feedback_form', case_id=case_id))\n        \n        if not resolution_method:\n            flash('Selecione como o problema foi resolvido.', 'error')\n            return redirect(url_for('case_feedback_form', case_id=case_id))\n        \n        success = case_service.add_case_feedback(case_id, effectiveness_score, resolution_method, custom_solution)\n        \n        if success:\n            flash('Feedback adicionado com sucesso!', 'success')\n            return redirect(url_for('view_case', case_id=case_id))\n        else:\n            flash('Caso não encontrado.', 'error')\n            return redirect(url_for('dashboard'))\n            \n    except Exception as e:\n        logging.error(f\"Error adding feedback to case {case_id}: {str(e)}\")\n        flash(f'Erro ao adicionar feedback: {str(e)}', 'error')\n        return redirect(url_for('case_feedback_form', case_id=case_id))\n\n@app.route('/submit-case-feedback', methods=['POST'])\ndef submit_case_feedback():\n    \"\"\"Submit feedback on solution effectiveness\"\"\"\n    try:\n        case_id = request.form.get('case_id', type=int)\n        effectiveness = request.form.get('effectiveness', type=int)\n        \n        if not case_id or effectiveness is None:\n            return jsonify({'error': 'Case ID e effectiveness são obrigatórios'}), 400\n        \n        if effectiveness < 1 or effectiveness > 5:\n            return jsonify({'error': 'Effectiveness must be between 1 and 5'}), 400\n        \n        success = case_service.add_feedback(case_id, effectiveness)\n        \n        if success:\n            return jsonify({'message': 'Feedback submitted successfully'})\n        else:\n            return jsonify({'error': 'Case not found'}), 404\n            \n    except Exception as e:\n        logging.error(f\"Error submitting feedback: {str(e)}\")\n        return jsonify({'error': str(e)}), 500\n\n@app.route('/api/stats')\ndef api_stats():\n    \"\"\"API endpoint for dashboard statistics\"\"\"\n    try:\n        stats = case_service.get_statistics()\n        return jsonify(stats)\n    except Exception as e:\n        logging.error(f\"Error getting stats: {str(e)}\")\n        return jsonify({'error': str(e)}), 500\n\n@app.route('/convert-to-case', methods=['POST'])\ndef convert_suggestion_to_case():\n    \"\"\"Convert an ML suggestion to a permanent case\"\"\"\n    try:\n        problem_description = request.form.get('problem_description', '').strip()\n        solution = request.form.get('solution', '').strip()\n        system_type = request.form.get('system_type', 'Unknown').strip()\n        \n        if not problem_description or not solution:\n            flash('Descrição do problema e solução são obrigatórias.', 'error')\n            return redirect(url_for('index'))\n        \n        # Add the case\n        case = case_service.add_case(problem_description, solution, system_type)\n        \n        # Retrain ML models with new case\n        all_cases = case_service.get_all_cases()\n        if len(all_cases) >= 5:\n            ml_service.train_models(all_cases)\n        \n        flash(f'✅ Caso #{case.id} criado com sucesso! Obrigado por contribuir para a base de conhecimento.', 'success')\n        return redirect(url_for('view_case', case_id=case.id))\n        \n    except Exception as e:\n        logging.error(f\"Error converting suggestion to case: {str(e)}\")\n        flash(f'Erro ao criar caso: {str(e)}', 'error')\n        return redirect(url_for('index'))\n\n@app.route('/api/ml-info')\ndef api_ml_info():\n    \"\"\"API endpoint for ML model information\"\"\"\n    try:\n        ml_info = ml_service.get_model_info()\n        return jsonify(ml_info)\n    except Exception as e:\n        logging.error(f\"Error getting ML info: {str(e)}\")\n        return jsonify({'error': str(e)}), 500\n\n@app.route('/cases/<int:case_id>/edit')\ndef edit_case_form(case_id):\n    \"\"\"Show form to edit an existing case\"\"\"\n    try:\n        case = case_service.get_case_by_id(case_id)\n        if not case:\n            flash('Caso não encontrado.', 'error')\n            return redirect(url_for('dashboard'))\n        \n        return render_template('edit_case.html', case=case)\n        \n    except Exception as e:\n        logging.error(f\"Error loading edit form for case {case_id}: {str(e)}\")\n        flash(f'Erro ao carregar formulário de edição: {str(e)}', 'error')\n        return redirect(url_for('dashboard'))\n\n@app.route('/cases/<int:case_id>/edit', methods=['POST'])\ndef edit_case(case_id):\n    \"\"\"Update an existing case\"\"\"\n    try:\n        problem_description = request.form.get('problem_description', '').strip()\n        solution = request.form.get('solution', '').strip()\n        system_type = request.form.get('system_type', 'Unknown').strip()\n        \n        if not problem_description or not solution:\n            flash('Descrição do problema e solução são obrigatórios.', 'error')\n            return redirect(url_for('edit_case_form', case_id=case_id))\n        \n        success = case_service.update_case(case_id, problem_description, solution, system_type)\n        \n        if success:\n            # Retrain ML models with updated cases\n            all_cases = case_service.get_all_cases()\n            if len(all_cases) >= 5:\n                ml_service.train_models(all_cases)\n            \n            flash(f'Caso #{case_id} atualizado com sucesso!', 'success')\n            return redirect(url_for('view_case', case_id=case_id))\n        else:\n            flash('Caso não encontrado.', 'error')\n            return redirect(url_for('dashboard'))\n        \n    except Exception as e:\n        logging.error(f\"Error updating case {case_id}: {str(e)}\")\n        flash(f'Erro ao atualizar caso: {str(e)}', 'error')\n        return redirect(url_for('edit_case_form', case_id=case_id))\n\n@app.route('/cases/<int:case_id>/delete', methods=['POST'])\ndef delete_case(case_id):\n    \"\"\"Delete a case\"\"\"\n    try:\n        success = case_service.delete_case(case_id)\n        \n        if success:\n            # Retrain ML models after deletion\n            all_cases = case_service.get_all_cases()\n            if len(all_cases) >= 5:\n                ml_service.train_models(all_cases)\n            \n            flash(f'Caso #{case_id} excluído com sucesso!', 'success')\n        else:\n            flash('Caso não encontrado.', 'error')\n        \n        return redirect(url_for('dashboard'))\n        \n    except Exception as e:\n        logging.error(f\"Error deleting case {case_id}: {str(e)}\")\n        flash(f'Erro ao excluir caso: {str(e)}', 'error')\n        return redirect(url_for('dashboard'))\n\n@app.route('/cases/delete-all', methods=['POST'])\ndef delete_all_cases():\n    \"\"\"Delete ALL cases with double confirmation\"\"\"\n    try:\n        # Check for confirmation parameter\n        confirm = request.form.get('confirm_delete_all')\n        if confirm != 'yes':\n            flash('Operação cancelada: confirmação não recebida.', 'error')\n            return redirect(url_for('dashboard'))\n        \n        # Get current case count for logging\n        current_cases = case_service.get_all_cases()\n        case_count = len(current_cases)\n        \n        if case_count == 0:\n            flash('Nenhum caso encontrado para remover.', 'info')\n            return redirect(url_for('dashboard'))\n        \n        # Delete all cases\n        success_count = case_service.delete_all_cases()\n        \n        if success_count > 0:\n            flash(f'✅ Sucesso: {success_count} casos foram removidos permanentemente do sistema.', 'success')\n            logging.warning(f\"BULK DELETE: {success_count} cases deleted by user\")\n            \n            # Clear ML models since all training data is gone\n            try:\n                ml_service.is_trained = False\n                logging.info(\"ML models reset after bulk delete\")\n            except:\n                pass\n        else:\n            flash('Erro: Nenhum caso foi removido. Tente novamente.', 'error')\n            \n    except Exception as e:\n        logging.error(f\"Error in bulk delete operation: {str(e)}\")\n        flash('Erro crítico durante remoção em massa. Contate o administrador.', 'error')\n    \n    return redirect(url_for('dashboard'))\n\n@app.route('/train-models', methods=['POST'])\ndef train_models():\n    \"\"\"Manually trigger ML model training\"\"\"\n    try:\n        all_cases = case_service.get_all_cases()\n        if len(all_cases) < 5:\n            flash('Necessário pelo menos 5 casos para treinar os modelos ML.', 'warning')\n        else:\n            success = ml_service.train_models(all_cases)\n            if success:\n                flash('Modelos ML treinados com sucesso!', 'success')\n            else:\n                flash('Falha ao treinar modelos ML. Verifique os logs para detalhes.', 'error')\n        \n        return redirect(url_for('dashboard'))\n        \n    except Exception as e:\n        logging.error(f\"Error training models: {str(e)}\")\n        flash(f'Erro ao treinar modelos: {str(e)}', 'error')\n        return redirect(url_for('dashboard'))\n\n@app.route('/ml-learning-info')\ndef ml_learning_info():\n    \"\"\"Show ML learning insights and effectiveness analysis\"\"\"\n    try:\n        # Get comprehensive model information\n        model_info = ml_service.get_model_info()\n        \n        # Get learning insights\n        learning_insights = ml_service.get_learning_insights()\n        \n        return render_template('ml_learning_info.html', \n                             model_info=model_info,\n                             learning_insights=learning_insights)\n        \n    except Exception as e:\n        logging.error(f\"Error getting ML learning info: {str(e)}\")\n        flash(f'Erro ao carregar informações de aprendizado: {str(e)}', 'error')\n        return redirect(url_for('dashboard'))\n\n@app.route('/populate-sample-data', methods=['POST'])\ndef populate_sample_data():\n    \"\"\"Add sample cases for demonstration\"\"\"\n    try:\n        sample_cases = [\n            {\n                'problem': 'Sistema Tasy apresentando erro de conexão com banco de dados Oracle. Usuários não conseguem acessar módulo de prontuário eletrônico. Erro: ORA-12154 TNS could not resolve the connect identifier.',\n                'solution': '1. Verificar conectividade de rede com servidor Oracle\\n2. Validar configurações do tnsnames.ora\\n3. Testar conexão usando sqlplus\\n4. Reiniciar listener do Oracle se necessário\\n5. Verificar logs do Tasy para detalhes adicionais\\n6. Se problema persistir, abrir chamado para Nexdow',\n                'system': 'Tasy'\n            },\n            {\n                'problem': 'SGU não consegue processar admissões. Erro \"Timeout na comunicação com base de dados\" aparece ao tentar registrar novos pacientes. Módulo de gestão hospitalar indisponível.',\n                'solution': '1. Verificar status dos serviços SGU no servidor\\n2. Testar conectividade com banco de dados SGU\\n3. Analisar logs de erro do SGU\\n4. Verificar configurações de timeout\\n5. Reiniciar serviços SGU se necessário\\n6. Caso não resolva, escalar para Nexdow',\n                'system': 'SGU'\n            },\n            {\n                'problem': 'SGU Card não imprime carteirinhas de pacientes. Impressora conectada mas recebe dados corrompidos. Erro \"Falha na geração de layout\" no módulo de cartões.',\n                'solution': '1. Verificar driver da impressora de cartões\\n2. Testar impressão manual de arquivo teste\\n3. Validar template de layout no SGU Card\\n4. Verificar dados do paciente no sistema\\n5. Limpar cache do módulo Card\\n6. Se necessário, abrir chamado Nexdow para revisão do layout',\n                'system': 'SGU Card'\n            },\n            {\n                'problem': 'Autorizador não processa guias de consulta. Fila com 500+ autorizações pendentes. Erro \"Falha na comunicação com operadora\" em todas as tentativas.',\n                'solution': '1. Verificar conectividade com APIs das operadoras\\n2. Validar certificados digitais expirados\\n3. Testar manualmente autorização de uma guia\\n4. Verificar configurações de proxy/firewall\\n5. Processar fila manualmente se urgente\\n6. Contatar Nexdow para problemas de integração com operadoras',\n                'system': 'Autorizador'\n            },\n            {\n                'problem': 'Tasy módulo farmácia lento para dispensar medicamentos. Consulta de estoque demora mais de 2 minutos. Pacientes aguardando na fila da farmácia.',\n                'solution': '1. Analisar performance de queries no módulo farmácia\\n2. Verificar índices das tabelas de estoque\\n3. Executar reorganização de índices\\n4. Limpar dados antigos da tabela de logs\\n5. Considerar aumento de memória do servidor\\n6. Se problema persistir, solicitar análise Nexdow',\n                'system': 'Tasy'\n            },\n            {\n                'problem': 'Rede hospitalar com perda de pacotes na VLAN dos equipamentos médicos. Monitores cardíacos perdendo conexão intermitentemente. Setor UTI afetado.',\n                'solution': '1. Verificar cabos de rede na UTI\\n2. Analisar logs dos switches da VLAN médica\\n3. Testar largura de banda disponível\\n4. Verificar configurações QoS para tráfego médico\\n5. Substituir cabos defeituosos se identificados\\n6. Priorizar tráfego crítico nos switches',\n                'system': 'Network'\n            }\n        ]\n        \n        added_count = 0\n        for sample in sample_cases:\n            case = case_service.add_case(\n                problem_description=sample['problem'],\n                solution=sample['solution'],\n                system_type=sample['system']\n            )\n            added_count += 1\n        \n        # Train ML models with new cases\n        all_cases = case_service.get_all_cases()\n        ml_service.train_models(all_cases)\n        \n        flash(f'{added_count} casos de exemplo adicionados e modelos ML treinados!', 'success')\n        return redirect(url_for('dashboard'))\n        \n    except Exception as e:\n        logging.error(f\"Error adding sample data: {str(e)}\")\n        flash(f'Erro ao adicionar dados de exemplo: {str(e)}', 'error')\n        return redirect(url_for('dashboard'))\n\n@app.route('/upload-cases')\ndef upload_cases_form():\n    \"\"\"Show form to upload cases from files\"\"\"\n    return render_template('upload_cases.html')\n\n@app.route('/upload-cases', methods=['POST'])\ndef upload_cases():\n    \"\"\"Process uploaded file with cases\"\"\"\n    try:\n        if 'file' not in request.files:\n            flash('Nenhum arquivo selecionado.', 'error')\n            return redirect(url_for('upload_cases_form'))\n        \n        file = request.files['file']\n        file_type = request.form.get('file_type')\n        \n        if file.filename == '':\n            flash('Nenhum arquivo selecionado.', 'error')\n            return redirect(url_for('upload_cases_form'))\n        \n        # Import required libraries\n        import pandas as pd\n        import PyPDF2\n        import io\n        from flask import current_app\n        \n        cases_added = 0\n        \n        if file_type == 'excel':\n            # Process Excel/CSV file\n            try:\n                if file.filename and file.filename.endswith('.csv'):\n                    df = pd.read_csv(io.BytesIO(file.read()), encoding='utf-8')\n                else:\n                    df = pd.read_excel(io.BytesIO(file.read()))\n                \n                problem_col = request.form.get('problem_column', 'Problema')\n                solution_col = request.form.get('solution_column', 'Solução')\n                system_col = request.form.get('system_column', 'Sistema')\n                \n                for _, row in df.iterrows():\n                    problem_val = row.get(problem_col)\n                    solution_val = row.get(solution_col)\n                    if (problem_val is not None and pd.notna(problem_val) and \n                        solution_val is not None and pd.notna(solution_val)):\n                        case = case_service.add_case(\n                            problem_description=str(problem_val),\n                            solution=str(solution_val),\n                            system_type=str(row.get(system_col, 'Unknown'))\n                        )\n                        cases_added += 1\n                        \n            except Exception as e:\n                flash(f'Erro ao processar planilha: {str(e)}', 'error')\n                return redirect(url_for('upload_cases_form'))\n        \n        elif file_type == 'pdf':\n            # Process PDF file\n            try:\n                pdf_reader = PyPDF2.PdfReader(io.BytesIO(file.read()))\n                text = \"\"\n                for page in pdf_reader.pages:\n                    text += page.extract_text()\n                \n                # Simple text processing for PDF (basic implementation)\n                lines = text.split('\\n')\n                current_problem = \"\"\n                current_solution = \"\"\n                \n                for line in lines:\n                    line = line.strip()\n                    if not line:\n                        continue\n                    \n                    # Simple heuristics to identify problem/solution pairs\n                    if any(word in line.lower() for word in ['problema:', 'erro:', 'issue:', 'falha:']):\n                        if current_problem and current_solution:\n                            case = case_service.add_case(\n                                problem_description=current_problem,\n                                solution=current_solution,\n                                system_type='Unknown'\n                            )\n                            cases_added += 1\n                        current_problem = line\n                        current_solution = \"\"\n                    elif any(word in line.lower() for word in ['solução:', 'resolução:', 'fix:', 'correção:']):\n                        current_solution = line\n                    elif current_solution and line:\n                        current_solution += \" \" + line\n                \n                # Add last case\n                if current_problem and current_solution:\n                    case = case_service.add_case(\n                        problem_description=current_problem,\n                        solution=current_solution,\n                        system_type='Unknown'\n                    )\n                    cases_added += 1\n                    \n            except Exception as e:\n                flash(f'Erro ao processar PDF: {str(e)}', 'error')\n                return redirect(url_for('upload_cases_form'))\n        \n        if cases_added > 0:\n            # Retrain ML models with new cases\n            all_cases = case_service.get_all_cases()\n            if len(all_cases) >= 5:\n                ml_service.train_models(all_cases)\n            \n            flash(f'{cases_added} casos adicionados com sucesso!', 'success')\n        else:\n            flash('Nenhum caso válido encontrado no arquivo.', 'warning')\n        \n        return redirect(url_for('dashboard'))\n        \n    except Exception as e:\n        logging.error(f\"Error uploading cases: {str(e)}\")\n        flash(f'Erro ao processar arquivo: {str(e)}', 'error')\n        return redirect(url_for('upload_cases_form'))\n\n@app.route('/download-template')\ndef download_template():\n    \"\"\"Download Excel template for case upload\"\"\"\n    try:\n        import pandas as pd\n        import io\n        \n        # Create sample data\n        sample_data = {\n            'Problema': [\n                'Sistema Tasy apresentando lentidão extrema',\n                'SGU não consegue processar admissões',\n                'Autorizador rejeitando guias válidas'\n            ],\n            'Solução': [\n                'Reiniciar serviço do Tasy e limpar cache',\n                'Verificar conectividade com banco SGU',\n                'Atualizar certificados digitais'\n            ],\n            'Sistema': ['Tasy', 'SGU', 'Autorizador']\n        }\n        \n        df = pd.DataFrame(sample_data)\n        \n        # Create Excel file in memory\n        output = io.BytesIO()\n        with pd.ExcelWriter(output, engine='openpyxl') as writer:\n            df.to_excel(writer, sheet_name='Casos', index=False)\n        \n        output.seek(0)\n        \n        from flask import send_file\n        return send_file(\n            output,\n            as_attachment=True,\n            download_name='template_casos.xlsx',\n            mimetype='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'\n        )\n        \n    except Exception as e:\n        logging.error(f\"Error creating template: {str(e)}\")\n        flash(f'Erro ao gerar template: {str(e)}', 'error')\n        return redirect(url_for('upload_cases_form'))\n\n@app.route('/systems')\ndef manage_systems():\n    \"\"\"Manage system types\"\"\"\n    try:\n        # Get system usage statistics\n        all_cases = case_service.get_all_cases()\n        system_stats = {}\n        \n        for case in all_cases:\n            system = case.system_type\n            if system not in system_stats:\n                system_stats[system] = {\n                    'name': system,\n                    'category': 'Healthcare' if system in ['Tasy', 'SGU', 'SGU Card', 'Autorizador'] else 'Other',\n                    'case_count': 0,\n                    'last_used': None\n                }\n            system_stats[system]['case_count'] += 1\n            if not system_stats[system]['last_used'] or case.created_at > system_stats[system]['last_used']:\n                system_stats[system]['last_used'] = case.created_at\n        \n        # Get custom systems from config\n        from flask import current_app\n        custom_systems = current_app.config.get('CUSTOM_SYSTEMS', [])\n        \n        # Merge with usage stats\n        all_systems = []\n        for system_name, stats in system_stats.items():\n            all_systems.append(stats)\n        \n        # Add custom systems that haven't been used\n        for custom in custom_systems:\n            if custom['name'] not in system_stats:\n                custom['case_count'] = 0\n                custom['last_used'] = None\n                all_systems.append(custom)\n        \n        return render_template('manage_systems.html', systems=all_systems)\n        \n    except Exception as e:\n        logging.error(f\"Error loading systems: {str(e)}\")\n        flash(f'Erro ao carregar sistemas: {str(e)}', 'error')\n        return render_template('manage_systems.html', systems=[])\n\n@app.route('/systems/add', methods=['POST'])\ndef add_system():\n    \"\"\"Add new system type\"\"\"\n    try:\n        system_name = request.form.get('system_name', '').strip()\n        system_category = request.form.get('system_category', 'Other')\n        system_description = request.form.get('system_description', '').strip()\n        \n        if not system_name:\n            flash('Nome do sistema é obrigatório.', 'error')\n            return redirect(url_for('manage_systems'))\n        \n        # Get current custom systems\n        from flask import current_app\n        custom_systems = current_app.config.get('CUSTOM_SYSTEMS', [])\n        \n        # Check if system already exists\n        if any(s['name'].lower() == system_name.lower() for s in custom_systems):\n            flash('Sistema já cadastrado.', 'error')\n            return redirect(url_for('manage_systems'))\n        \n        # Add new system\n        new_system = {\n            'name': system_name,\n            'category': system_category,\n            'description': system_description\n        }\n        custom_systems.append(new_system)\n        current_app.config['CUSTOM_SYSTEMS'] = custom_systems\n        \n        flash(f'Sistema \"{system_name}\" adicionado com sucesso!', 'success')\n        return redirect(url_for('manage_systems'))\n        \n    except Exception as e:\n        logging.error(f\"Error adding system: {str(e)}\")\n        flash(f'Erro ao adicionar sistema: {str(e)}', 'error')\n        return redirect(url_for('manage_systems'))\n\n@app.route('/tutorial')\ndef tutorial():\n    \"\"\"Show tutorial and documentation\"\"\"\n    return render_template('tutorial.html')\n\n@app.route('/import-cases', methods=['POST'])\ndef import_cases():\n    \"\"\"Import cases from file using new AI-powered system\"\"\"\n    try:\n        if 'file' not in request.files:\n            flash('Nenhum arquivo selecionado.', 'error')\n            return redirect(url_for('add_case_form'))\n        \n        file = request.files['file']\n        format_type = request.form.get('format_type', 'structured')\n        \n        if file.filename == '':\n            flash('Nenhum arquivo selecionado.', 'error')\n            return redirect(url_for('upload_cases_form'))\n        \n        # Save file temporarily\n        filename = secure_filename(file.filename or \"upload.txt\")\n        temp_dir = tempfile.gettempdir()\n        temp_path = os.path.join(temp_dir, filename)\n        \n        file.save(temp_path)\n        \n        # Process file using FileProcessor\n        logging.info(f\"Processing file: {temp_path} with format: {format_type}\")\n        cases = file_processor.process_file(temp_path, format_type)\n        logging.info(f\"Processed {len(cases)} cases from file\")\n        \n        cases_added = 0\n        cases_failed = 0\n        \n        for i, case_data in enumerate(cases):\n            try:\n                case = case_service.add_case(\n                    problem_description=case_data['problem_description'],\n                    solution=case_data['solution'],\n                    system_type=case_data['system_type']\n                )\n                cases_added += 1\n                if cases_added % 10 == 0:  # Log progress every 10 cases\n                    logging.info(f\"Added {cases_added} cases so far...\")\n            except Exception as e:\n                cases_failed += 1\n                logging.error(f\"Failed to add case {i+1}: {str(e)}\")\n                # Continue with other cases\n                continue\n        \n        # Clean up temporary file\n        if temp_path and os.path.exists(temp_path):\n            os.unlink(temp_path)\n        \n        if cases_added > 0:\n            # Retrain ML models with new cases\n            try:\n                all_cases = case_service.get_all_cases()\n                if len(all_cases) >= 5:\n                    ml_service.train_models(all_cases)\n                    logging.info(\"ML models retrained successfully\")\n            except Exception as e:\n                logging.warning(f\"Failed to retrain ML models: {str(e)}\")\n            \n            success_msg = f'{cases_added} casos importados com sucesso!'\n            if cases_failed > 0:\n                success_msg += f' ({cases_failed} casos falharam)'\n            flash(success_msg, 'success')\n        else:\n            flash('Nenhum caso válido encontrado no arquivo.', 'warning')\n        \n        return redirect(url_for('dashboard'))\n            \n    except Exception as e:\n        # Clean up temporary file on error\n        if 'temp_path' in locals() and temp_path and os.path.exists(temp_path):\n            try:\n                os.unlink(temp_path)\n            except:\n                pass\n        \n        logging.error(f\"Error importing cases: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        flash(f'Erro ao importar casos: {str(e)}', 'error')\n        return redirect(url_for('upload_cases_form'))\n\n@app.route('/feedback', methods=['POST'])\ndef feedback():\n    \"\"\"Process detailed feedback from users\"\"\"\n    try:\n        from datetime import datetime\n        import json\n        \n        # Log received data for debugging\n        logging.info(f\"Feedback form data: {dict(request.form)}\")\n        \n        # Get form data\n        score = request.form.get('score', type=int)\n        problem_description = request.form.get('problem_description', '')\n        comments = request.form.get('comments', '')\n        good_aspects = request.form.get('good_aspects', '[]')\n        improvements = request.form.get('improvements', '[]')\n        suggestion_ratings = request.form.get('suggestion_ratings', '{}')\n        \n        # Validate required data\n        if score is None:\n            return jsonify({\n                'success': False,\n                'message': 'Score é obrigatório'\n            }), 400\n        \n        # Parse JSON strings\n        try:\n            good_aspects_list = json.loads(good_aspects)\n            improvements_list = json.loads(improvements)\n            suggestion_ratings_dict = json.loads(suggestion_ratings)\n        except json.JSONDecodeError:\n            good_aspects_list = []\n            improvements_list = []\n            suggestion_ratings_dict = {}\n        \n        # Log feedback for analysis (in a real system, this would go to a database)\n        feedback_data = {\n            'timestamp': datetime.now().isoformat(),\n            'score': score,\n            'problem_description': problem_description[:200],  # Truncate for privacy\n            'good_aspects': good_aspects_list,\n            'improvements': improvements_list,\n            'suggestion_ratings': suggestion_ratings_dict,\n            'comments': comments,\n            'user_agent': request.headers.get('User-Agent', '')\n        }\n        \n        # Save feedback to database for ML learning\n        try:\n            from models import AnalysisFeedback\n            import json\n            \n            analysis_feedback = AnalysisFeedback()\n            analysis_feedback.problem_description = problem_description\n            analysis_feedback.overall_score = score\n            analysis_feedback.suggestion_ratings = json.dumps(suggestion_ratings_dict)\n            analysis_feedback.good_aspects = json.dumps(good_aspects_list)\n            analysis_feedback.improvements = json.dumps(improvements_list)\n            analysis_feedback.comments = comments\n            \n            db.session.add(analysis_feedback)\n            db.session.commit()\n            \n            logging.info(f\"Saved analysis feedback to database: score={score}\")\n            \n            # Trigger ML model improvement based on feedback\n            ml_service.process_analysis_feedback(analysis_feedback)\n            \n        except Exception as e:\n            logging.error(f\"Error saving analysis feedback: {str(e)}\")\n        \n        # Log the feedback for immediate debugging\n        logging.info(f\"User Feedback Received: {feedback_data}\")\n        \n        return jsonify({\n            'success': True,\n            'message': 'Feedback processado com sucesso!'\n        })\n        \n    except Exception as e:\n        logging.error(f\"Error processing feedback: {str(e)}\")\n        return jsonify({\n            'success': False,\n            'message': 'Erro ao processar feedback'\n        }), 500\n\n@app.route('/admin/feedbacks')\ndef view_feedbacks():\n    \"\"\"View all feedback data for system improvement\"\"\"\n    try:\n        from models import AnalysisFeedback, CaseFeedback\n        \n        # Get analysis feedbacks (from AI suggestions)\n        analysis_feedbacks = AnalysisFeedback.query.order_by(AnalysisFeedback.created_at.desc()).limit(50).all()\n        \n        # Get case feedbacks (from individual cases)\n        case_feedbacks = db.session.query(CaseFeedback, Case).join(Case).order_by(CaseFeedback.created_at.desc()).limit(50).all()\n        \n        # Calculate feedback statistics\n        total_analysis_feedbacks = AnalysisFeedback.query.count()\n        avg_analysis_score = db.session.query(db.func.avg(AnalysisFeedback.overall_score)).scalar() or 0\n        \n        total_case_feedbacks = CaseFeedback.query.count()\n        avg_case_score = db.session.query(db.func.avg(CaseFeedback.effectiveness_score)).scalar() or 0\n        \n        feedback_stats = {\n            'total_analysis_feedbacks': total_analysis_feedbacks,\n            'avg_analysis_score': round(avg_analysis_score, 1),\n            'total_case_feedbacks': total_case_feedbacks,\n            'avg_case_score': round(avg_case_score, 1)\n        }\n        \n        return render_template('admin_feedbacks.html', \n                             analysis_feedbacks=analysis_feedbacks,\n                             case_feedbacks=case_feedbacks,\n                             feedback_stats=feedback_stats)\n        \n    except Exception as e:\n        logging.error(f\"Error viewing feedbacks: {str(e)}\")\n        flash(f'Erro ao carregar feedbacks: {str(e)}', 'error')\n        return redirect(url_for('dashboard'))\n\n\n","size_bytes":42433},"run_local.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nOS Assistant - Local Development Runner\n\nThis script sets up and runs the OS Assistant application locally with SQLite database.\nPerfect for running on your local machine without external dependencies.\n\"\"\"\n\nimport os\nimport sys\nimport logging\nfrom pathlib import Path\n\n# Set environment variables for local development\nos.environ[\"DATABASE_URL\"] = \"\"  # Forces SQLite usage\nos.environ[\"SESSION_SECRET\"] = \"local-dev-secret-key-change-for-production\"\n\n# Ensure we can import from the current directory\nsys.path.insert(0, str(Path(__file__).parent))\n\n# Set up logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\nprint(\"=\"*60)\nprint(\"OS ASSISTANT - Sistema de Suporte Técnico Inteligente\")\nprint(\"=\"*60)\nprint(\"Configuração: SQLite (Banco Local)\")\nprint(\"Porta: 5000\")\nprint(\"URL: http://localhost:5000\")\nprint(\"Pasta do projeto:\", Path(__file__).parent)\nprint(\"=\"*60)\n\ntry:\n    from app import app, db\n    \n    # Create database tables if they don't exist\n    with app.app_context():\n        db.create_all()\n        print(\"✅ Banco de dados SQLite inicializado com sucesso\")\n        print(f\"📁 Arquivo do banco: {os.path.join(os.getcwd(), 'os_assistant.db')}\")\n        \n        # Check if we have any existing cases\n        from models import Case\n        case_count = Case.query.count()\n        print(f\"📊 Casos existentes no banco: {case_count}\")\n    \n    print(\"\\n🚀 Iniciando servidor Flask...\")\n    print(\"💡 Pressione Ctrl+C para parar o servidor\")\n    print(\"=\"*60)\n    \n    # Run the application\n    app.run(\n        host='0.0.0.0',\n        port=5000,\n        debug=True,\n        use_reloader=True\n    )\n\nexcept ImportError as e:\n    print(f\"❌ Erro de importação: {e}\")\n    print(\"\\n📦 Instale as dependências necessárias:\")\n    print(\"pip install flask flask-sqlalchemy pandas openpyxl scikit-learn\")\n    sys.exit(1)\nexcept Exception as e:\n    print(f\"❌ Erro ao iniciar aplicação: {e}\")\n    sys.exit(1)","size_bytes":2030},"run_production.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nOS Assistant - Production Server\n\nPara uso com múltiplos usuários simultâneos em rede.\nUse este script quando várias pessoas acessarem ao mesmo tempo.\n\"\"\"\n\nimport os\nimport sys\nimport logging\nfrom pathlib import Path\n\n# Set environment variables for production\nos.environ[\"DATABASE_URL\"] = \"\"  # Forces SQLite usage\nos.environ[\"SESSION_SECRET\"] = \"production-secret-key-change-this\"\nos.environ[\"FLASK_ENV\"] = \"production\"\n\n# Ensure we can import from the current directory\nsys.path.insert(0, str(Path(__file__).parent))\n\n# Set up logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\nprint(\"=\"*60)\nprint(\"OS ASSISTANT - SERVIDOR PRODUÇÃO (Multi-usuário)\")\nprint(\"=\"*60)\nprint(\"Configuração: SQLite (Compartilhado)\")\nprint(\"Porta: 5000\")\nprint(\"Acesso em rede: Habilitado\")\nprint(\"Usuários simultâneos: Suportado\")\nprint(\"=\"*60)\n\ntry:\n    from app import app, db\n    \n    # Create database tables if they don't exist\n    with app.app_context():\n        db.create_all()\n        print(\"✅ Banco de dados SQLite inicializado\")\n        print(f\"📁 Arquivo do banco: {os.path.join(os.getcwd(), 'os_assistant.db')}\")\n        \n        # Check if we have any existing cases\n        from models import Case\n        case_count = Case.query.count()\n        print(f\"📊 Casos existentes: {case_count}\")\n    \n    print(\"\\n🚀 Iniciando servidor de produção...\")\n    print(\"🌐 Acesso em rede habilitado para múltiplos usuários\")\n    print(\"💡 Pressione Ctrl+C para parar\")\n    print(\"=\"*60)\n    \n    # Run with Gunicorn-like settings for better performance\n    app.run(\n        host='0.0.0.0',\n        port=5000,\n        debug=False,  # Disabled for production\n        threaded=True,  # Enable threading for multiple users\n        use_reloader=False\n    )\n\nexcept ImportError as e:\n    print(f\"❌ Erro de importação: {e}\")\n    print(\"\\n📦 Instale as dependências:\")\n    print(\"pip install -r requirements_local.txt\")\n    sys.exit(1)\nexcept Exception as e:\n    print(f\"❌ Erro ao iniciar: {e}\")\n    sys.exit(1)","size_bytes":2119},"setup_local.md":{"content":"# OS Assistant - Instalação e Configuração Local\n\n## Como Rodar na Sua Máquina\n\n### Pré-requisitos\n- Python 3.8 ou superior\n- pip (gerenciador de pacotes Python)\n\n### Instalação Rápida\n\n1. **Baixe todos os arquivos do projeto** para uma pasta no seu computador\n\n2. **Abra o terminal/prompt na pasta do projeto**\n\n3. **Instale as dependências:**\n```bash\npip install flask flask-sqlalchemy pandas openpyxl scikit-learn gunicorn werkzeug numpy PyPDF2 email-validator psycopg2-binary\n```\n\n4. **Execute o aplicativo:**\n```bash\npython run_local.py\n```\n\n5. **Acesse no navegador:**\n```\nhttp://localhost:5000\n```\n\n### Estrutura de Arquivos Necessários\n\nCertifique-se de ter todos estes arquivos na pasta:\n\n```\nOS-Assistant/\n├── run_local.py           # ← Script principal para executar\n├── app.py                 # Configuração do Flask\n├── main.py                # Ponto de entrada alternativo\n├── models.py              # Modelos do banco de dados\n├── routes.py              # Rotas da aplicação\n├── case_service.py        # Serviço de gerenciamento de casos\n├── ml_service.py          # Serviço de machine learning\n├── file_processor.py      # Processamento de arquivos\n├── static/\n│   ├── style.css          # Estilos CSS\n│   └── script.js          # JavaScript\n├── templates/             # Templates HTML\n│   ├── base.html\n│   ├── index.html\n│   ├── dashboard.html\n│   ├── add_case.html\n│   ├── upload_cases.html\n│   └── ... (outros templates)\n└── ml_models/             # Modelos de ML (criados automaticamente)\n```\n\n### Banco de Dados Local\n\n- **Tipo:** SQLite (arquivo local)\n- **Localização:** `os_assistant.db` na pasta do projeto\n- **Backup:** Simplesmente copie o arquivo `os_assistant.db`\n- **Reset:** Delete o arquivo para começar do zero\n\n### Importação de Dados\n\n1. Acesse \"Upload de Casos\" no menu\n2. Selecione seu arquivo Excel com colunas:\n   - **Problema**: Descrição do problema\n   - **Solução**: Solução aplicada\n   - **Sistema**: Tipo de sistema (opcional)\n3. Clique em \"Importar\"\n\n### Funcionalidades Principais\n\n- ✅ **Análise de Problemas**: IA analisa e sugere soluções\n- ✅ **Importação Excel**: Carregue casos em lote\n- ✅ **Dashboard**: Estatísticas e casos recentes\n- ✅ **CRUD Completo**: Criar, editar, deletar casos\n- ✅ **Busca Inteligente**: Encontre casos similares\n- ✅ **100% Offline**: Sem dependências externas\n\n### Solução de Problemas\n\n#### Erro: \"ModuleNotFoundError\"\n```bash\npip install --upgrade pip\npip install flask flask-sqlalchemy pandas openpyxl scikit-learn\n```\n\n#### Erro: \"Port already in use\"\n```bash\n# Use outra porta editando run_local.py, linha:\napp.run(port=5001)  # Mude de 5000 para 5001\n```\n\n#### Erro: \"Permission denied\" no banco\n```bash\n# Verifique permissões da pasta\nchmod 755 .\n```\n\n#### Importação falha\n- Verifique se as colunas estão nomeadas: \"Problema\", \"Solução\", \"Sistema\"\n- Arquivo deve ser .xlsx ou .csv\n- Máximo 5MB recomendado\n\n### Performance\n\n- **Casos suportados:** Até 10.000 casos\n- **Importação:** Até 1.000 casos por vez\n- **Memória:** ~100MB RAM\n- **Espaço:** ~50MB disco\n\n### Backup e Migração\n\n#### Backup Completo\n```bash\n# Copie estes arquivos:\ncp os_assistant.db backup/\ncp -r ml_models/ backup/\n```\n\n#### Restaurar Backup\n```bash\ncp backup/os_assistant.db .\ncp -r backup/ml_models/ .\n```\n\n### Customização\n\n#### Mudar Porta\nEdite `run_local.py`, linha 57:\n```python\napp.run(port=8080)  # Sua porta preferida\n```\n\n#### Ativar Debug SQL\nEdite `app.py`, linha 49:\n```python\n\"echo\": True  # Mostra queries SQL no console\n```\n\n#### Adicionar Sistemas\nAcesse \"Gerenciar Sistemas\" no menu da aplicação\n\n### Suporte\n\n- **Documentação completa:** `DOCUMENTACAO_SISTEMA.md`\n- **Logs de erro:** Aparecem no terminal onde executou\n- **Banco de dados:** SQLite Browser para visualizar dados","size_bytes":3958},"static/script.js":{"content":"// OS Assistant - Custom JavaScript functionality\n\n// Global variables\nlet searchTimeout = null;\nlet currentFeedbackCaseId = null;\n\n// Initialize when DOM is loaded\ndocument.addEventListener('DOMContentLoaded', function() {\n    initializeComponents();\n    setupEventListeners();\n    loadUserPreferences();\n    createScrollToTopButton();\n    setupScrollToTop();\n});\n\n// Initialize various components\nfunction initializeComponents() {\n    // Initialize tooltips if Bootstrap tooltips are available\n    if (typeof bootstrap !== 'undefined' && bootstrap.Tooltip) {\n        const tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle=\"tooltip\"]'));\n        tooltipTriggerList.map(function (tooltipTriggerEl) {\n            return new bootstrap.Tooltip(tooltipTriggerEl);\n        });\n    }\n    \n    // Auto-resize textareas\n    autoResizeTextareas();\n    \n    // Initialize search functionality\n    setupSearchFunctionality();\n}\n\n// Setup event listeners\nfunction setupEventListeners() {\n    // Form validation\n    const forms = document.querySelectorAll('form');\n    forms.forEach(form => {\n        form.addEventListener('submit', handleFormSubmission);\n    });\n    \n    // Keyboard shortcuts\n    document.addEventListener('keydown', handleKeyboardShortcuts);\n    \n    // Auto-save functionality for forms\n    setupAutoSave();\n    \n    // Handle back button navigation\n    window.addEventListener('popstate', handleBackNavigation);\n}\n\n// System color mapping function\nfunction getSystemColor(systemType) {\n    const systemColors = {\n        'Sistema SGU': 'primary',\n        'SGU-CRM': 'info', \n        'SGU-Card': 'success',\n        'SGU-Portais': 'warning',\n        'SGU GPL': 'secondary',\n        'Autorizador/AutSC': 'danger',\n        'Aplicativo Unimed Criciúma': 'dark',\n        'Tasy': 'purple',\n        'Syngoo': 'cyan',\n        'Pep RS': 'orange',\n        'Database': 'pink'\n    };\n    return systemColors[systemType] || 'secondary';\n}\n\n// Create scroll to top button\nfunction createScrollToTopButton() {\n    // Only create if it doesn't exist\n    if (document.getElementById('scrollToTop')) {\n        return;\n    }\n    \n    const scrollBtn = document.createElement('button');\n    scrollBtn.id = 'scrollToTop';\n    scrollBtn.innerHTML = '<i data-feather=\"arrow-up\"></i>';\n    scrollBtn.className = 'btn btn-primary scroll-to-top-btn';\n    scrollBtn.style.cssText = `\n        position: fixed;\n        bottom: 30px;\n        right: 30px;\n        width: 50px;\n        height: 50px;\n        border-radius: 50%;\n        display: none;\n        z-index: 1000;\n        border: none;\n        box-shadow: 0 4px 12px rgba(0,0,0,0.3);\n        transition: all 0.3s ease;\n    `;\n    \n    scrollBtn.addEventListener('click', function() {\n        window.scrollTo({\n            top: 0,\n            behavior: 'smooth'\n        });\n    });\n    \n    document.body.appendChild(scrollBtn);\n    \n    // Initialize feather icons for the new button\n    if (typeof feather !== 'undefined') {\n        feather.replace();\n    }\n}\n\n// Setup scroll to top functionality\nfunction setupScrollToTop() {\n    window.addEventListener('scroll', function() {\n        const scrollBtn = document.getElementById('scrollToTop');\n        if (scrollBtn) {\n            if (window.pageYOffset > 300) {\n                scrollBtn.style.display = 'block';\n            } else {\n                scrollBtn.style.display = 'none';\n            }\n        }\n    });\n}\n\n// Handle Enter key submission for textarea\nfunction handleEnterSubmit(event) {\n    // Check if Enter key is pressed without Shift (Shift+Enter for new line)\n    if (event.key === 'Enter' && !event.shiftKey) {\n        event.preventDefault(); // Prevent new line\n        \n        // Find the form and submit it\n        const form = event.target.closest('form');\n        if (form) {\n            // Check if textarea has content\n            const textarea = event.target;\n            if (textarea.value.trim().length > 0) {\n                form.submit();\n            }\n        }\n    }\n}\n\n// Handle form submissions with loading states\nfunction handleFormSubmission(event) {\n    const form = event.target;\n    const submitButton = form.querySelector('button[type=\"submit\"]');\n    \n    if (submitButton) {\n        // Show loading state\n        const originalText = submitButton.innerHTML;\n        submitButton.innerHTML = '<i data-feather=\"loader\" class=\"me-1\"></i>Processing...';\n        submitButton.disabled = true;\n        \n        // Re-initialize feather icons\n        if (typeof feather !== 'undefined') {\n            feather.replace();\n        }\n        \n        // Reset button after 10 seconds (fallback)\n        setTimeout(() => {\n            submitButton.innerHTML = originalText;\n            submitButton.disabled = false;\n            if (typeof feather !== 'undefined') {\n                feather.replace();\n            }\n        }, 10000);\n    }\n}\n\n// Keyboard shortcuts\nfunction handleKeyboardShortcuts(event) {\n    // Ctrl+Enter to submit forms\n    if (event.ctrlKey && event.key === 'Enter') {\n        const activeForm = document.querySelector('form:focus-within');\n        if (activeForm) {\n            activeForm.submit();\n        }\n    }\n    \n    // Escape to close modals\n    if (event.key === 'Escape') {\n        const openModal = document.querySelector('.modal.show');\n        if (openModal && typeof bootstrap !== 'undefined') {\n            const modal = bootstrap.Modal.getInstance(openModal);\n            if (modal) {\n                modal.hide();\n            }\n        }\n    }\n}\n\n// Auto-resize textareas\nfunction autoResizeTextareas() {\n    const textareas = document.querySelectorAll('textarea');\n    textareas.forEach(textarea => {\n        textarea.addEventListener('input', function() {\n            this.style.height = 'auto';\n            this.style.height = Math.min(this.scrollHeight, 400) + 'px';\n        });\n        \n        // Initial resize\n        textarea.dispatchEvent(new Event('input'));\n    });\n}\n\n// Setup search functionality\nfunction setupSearchFunctionality() {\n    const searchInputs = document.querySelectorAll('input[name=\"search\"]');\n    searchInputs.forEach(input => {\n        input.addEventListener('input', function() {\n            // Debounce search\n            clearTimeout(searchTimeout);\n            searchTimeout = setTimeout(() => {\n                performInstantSearch(this.value);\n            }, 300);\n        });\n    });\n}\n\n// Perform instant search (for future enhancement)\nfunction performInstantSearch(query) {\n    // This could be enhanced to perform real-time search\n    console.log('Searching for:', query);\n}\n\n// Auto-save functionality\nfunction setupAutoSave() {\n    const autoSaveInputs = document.querySelectorAll('textarea[name=\"problem_description\"], textarea[name=\"solution\"]');\n    autoSaveInputs.forEach(input => {\n        input.addEventListener('input', debounce(saveFormData, 2000));\n    });\n}\n\n// Debounce function\nfunction debounce(func, wait) {\n    let timeout;\n    return function executedFunction(...args) {\n        const later = () => {\n            clearTimeout(timeout);\n            func(...args);\n        };\n        clearTimeout(timeout);\n        timeout = setTimeout(later, wait);\n    };\n}\n\n// Save form data to localStorage\nfunction saveFormData() {\n    const forms = document.querySelectorAll('form');\n    forms.forEach(form => {\n        const formData = new FormData(form);\n        const data = {};\n        \n        for (let [key, value] of formData.entries()) {\n            data[key] = value;\n        }\n        \n        if (Object.keys(data).length > 0) {\n            localStorage.setItem(`form_${form.action}`, JSON.stringify(data));\n        }\n    });\n}\n\n// Load form data from localStorage\nfunction loadFormData() {\n    const forms = document.querySelectorAll('form');\n    forms.forEach(form => {\n        const saved = localStorage.getItem(`form_${form.action}`);\n        if (saved) {\n            try {\n                const data = JSON.parse(saved);\n                Object.keys(data).forEach(key => {\n                    const input = form.querySelector(`[name=\"${key}\"]`);\n                    if (input && input.type !== 'file') {\n                        input.value = data[key];\n                    }\n                });\n            } catch (e) {\n                console.error('Error loading saved form data:', e);\n            }\n        }\n    });\n}\n\n// Handle back button navigation\nfunction handleBackNavigation(event) {\n    // Clean up any unsaved data warnings if needed\n    console.log('Navigating back');\n}\n\n// Load user preferences\nfunction loadUserPreferences() {\n    const prefs = localStorage.getItem('userPreferences');\n    if (prefs) {\n        try {\n            const preferences = JSON.parse(prefs);\n            applyPreferences(preferences);\n        } catch (e) {\n            console.error('Error loading user preferences:', e);\n        }\n    }\n}\n\n// Apply user preferences\nfunction applyPreferences(preferences) {\n    // Apply theme preferences, font size, etc.\n    if (preferences.theme) {\n        document.documentElement.setAttribute('data-bs-theme', preferences.theme);\n    }\n}\n\n// Utility functions\nconst Utils = {\n    // Show notification toast\n    showToast: function(message, type = 'info', duration = 5000) {\n        const toastId = 'toast-' + Date.now();\n        const toastHtml = `\n            <div id=\"${toastId}\" class=\"toast align-items-center text-bg-${type} border-0\" role=\"alert\" \n                 style=\"position: fixed; top: 20px; right: 20px; z-index: 1050;\">\n                <div class=\"d-flex\">\n                    <div class=\"toast-body\">${message}</div>\n                    <button type=\"button\" class=\"btn-close btn-close-white me-2 m-auto\" data-bs-dismiss=\"toast\"></button>\n                </div>\n            </div>\n        `;\n        \n        document.body.insertAdjacentHTML('beforeend', toastHtml);\n        \n        if (typeof bootstrap !== 'undefined') {\n            const toastElement = document.getElementById(toastId);\n            const toast = new bootstrap.Toast(toastElement, { delay: duration });\n            toast.show();\n            \n            // Remove toast element after it's hidden\n            toastElement.addEventListener('hidden.bs.toast', function() {\n                toastElement.remove();\n            });\n        }\n    },\n    \n    // Copy text to clipboard\n    copyToClipboard: function(text) {\n        if (navigator.clipboard && window.isSecureContext) {\n            return navigator.clipboard.writeText(text).then(() => {\n                this.showToast('Copied to clipboard!', 'success');\n            }).catch(err => {\n                console.error('Failed to copy:', err);\n                this.fallbackCopyTextToClipboard(text);\n            });\n        } else {\n            this.fallbackCopyTextToClipboard(text);\n        }\n    },\n    \n    // Fallback copy method\n    fallbackCopyTextToClipboard: function(text) {\n        const textArea = document.createElement('textarea');\n        textArea.value = text;\n        textArea.style.top = '0';\n        textArea.style.left = '0';\n        textArea.style.position = 'fixed';\n        textArea.style.opacity = '0';\n        \n        document.body.appendChild(textArea);\n        textArea.focus();\n        textArea.select();\n        \n        try {\n            const successful = document.execCommand('copy');\n            if (successful) {\n                this.showToast('Copied to clipboard!', 'success');\n            } else {\n                this.showToast('Failed to copy to clipboard', 'danger');\n            }\n        } catch (err) {\n            console.error('Fallback copy failed:', err);\n            this.showToast('Failed to copy to clipboard', 'danger');\n        }\n        \n        document.body.removeChild(textArea);\n    },\n    \n    // Format date for display\n    formatDate: function(dateString) {\n        const date = new Date(dateString);\n        const now = new Date();\n        const diffTime = Math.abs(now - date);\n        const diffDays = Math.ceil(diffTime / (1000 * 60 * 60 * 24));\n        \n        if (diffDays === 1) {\n            return 'Yesterday';\n        } else if (diffDays < 7) {\n            return `${diffDays} days ago`;\n        } else {\n            return date.toLocaleDateString();\n        }\n    },\n    \n    // Validate form fields\n    validateForm: function(form) {\n        const errors = [];\n        const requiredFields = form.querySelectorAll('[required]');\n        \n        requiredFields.forEach(field => {\n            if (!field.value.trim()) {\n                errors.push(`${field.labels[0]?.textContent || field.name} is required`);\n                field.classList.add('is-invalid');\n            } else {\n                field.classList.remove('is-invalid');\n            }\n        });\n        \n        return {\n            isValid: errors.length === 0,\n            errors: errors\n        };\n    },\n    \n    // Highlight search terms\n    highlightText: function(text, searchTerm) {\n        if (!searchTerm) return text;\n        \n        const regex = new RegExp(`(${searchTerm})`, 'gi');\n        return text.replace(regex, '<span class=\"search-highlight\">$1</span>');\n    }\n};\n\n// Export utility functions to global scope\nwindow.OSAssistant = {\n    Utils: Utils,\n    showToast: Utils.showToast,\n    copyToClipboard: Utils.copyToClipboard\n};\n\n// Performance monitoring\nwindow.addEventListener('load', function() {\n    // Log performance metrics\n    if (window.performance) {\n        const loadTime = window.performance.timing.loadEventEnd - window.performance.timing.navigationStart;\n        console.log(`Page loaded in ${loadTime}ms`);\n    }\n});\n\n// Error handling\nwindow.addEventListener('error', function(event) {\n    console.error('JavaScript error:', event.error);\n    // Could send error reports to server in production\n});\n\n// Handle offline/online status\nwindow.addEventListener('offline', function() {\n    Utils.showToast('You are now offline. Some features may not work.', 'warning');\n});\n\nwindow.addEventListener('online', function() {\n    Utils.showToast('You are back online!', 'success');\n});\n","size_bytes":14083},"static/style.css":{"content":"/* Custom styles for OS Assistant */\n\n/* Override some Bootstrap defaults for better technical interface */\n:root {\n    --custom-code-bg: #1a1a1a;\n    --custom-border-radius: 8px;\n    --glow-color: #0dcaf0;\n    --glow-secondary: rgba(13, 202, 240, 0.3);\n}\n\n/* Navigation glow effects */\n.navbar-brand-glow {\n    text-shadow: 0 0 10px var(--glow-secondary);\n    transition: text-shadow 0.3s ease;\n    cursor: default !important;\n    pointer-events: none !important;\n}\n\n.navbar-brand {\n    cursor: default !important;\n    pointer-events: none !important;\n    text-decoration: none !important;\n}\n\n.nav-link.active {\n    color: var(--glow-color) !important;\n    text-shadow: 0 0 8px var(--glow-secondary);\n    font-weight: 500;\n    position: relative;\n}\n\n.nav-link.active::after {\n    content: '';\n    position: absolute;\n    bottom: -2px;\n    left: 50%;\n    transform: translateX(-50%);\n    width: 80%;\n    height: 2px;\n    background: linear-gradient(90deg, transparent, var(--glow-color), transparent);\n    border-radius: 2px;\n    box-shadow: 0 0 5px var(--glow-secondary);\n}\n\n.nav-link {\n    transition: all 0.3s ease;\n    border-radius: 6px;\n    padding: 0.5rem 1rem !important;\n}\n\n.nav-link:hover {\n    background-color: rgba(13, 202, 240, 0.1);\n    color: var(--glow-color) !important;\n}\n\n/* Navbar perfect centering - Fixed */\n.navbar {\n    position: relative;\n}\n\n.navbar-brand {\n    position: absolute;\n    left: 2rem;\n    z-index: 10;\n}\n\n.navbar-collapse {\n    position: static;\n    width: 100%;\n    display: flex !important;\n    justify-content: center !important;\n}\n\n.navbar-nav {\n    display: flex;\n    justify-content: center;\n    flex-wrap: wrap;\n    margin: 0 auto;\n}\n\n/* Custom Badge Colors - Enhanced */\n.badge.bg-secondary {\n    background-color: #6c757d !important;\n}\n\n.badge.bg-dark {\n    background-color: #212529 !important;\n    color: #ffffff !important;\n}\n\n.badge.bg-primary {\n    background-color: #0d6efd !important;\n}\n\n.badge.bg-info {\n    background-color: #0dcaf0 !important;\n}\n\n.badge.bg-success {\n    background-color: #198754 !important;\n}\n\n.badge.bg-warning {\n    background-color: #ffc107 !important;\n    color: #000000 !important;\n}\n\n.badge.bg-danger {\n    background-color: #dc3545 !important;\n}\n\n/* Remove system-specific overrides - let dynamic assignment handle it */\n\n/* Force badge visibility and proper styling */\n.badge {\n    display: inline-block !important;\n    padding: 0.375rem 0.75rem !important;\n    font-size: 0.75em !important;\n    font-weight: 600 !important;\n    line-height: 1 !important;\n    color: #fff !important;\n    text-align: center !important;\n    white-space: nowrap !important;\n    vertical-align: baseline !important;\n    border-radius: 0.375rem !important;\n}\n\n/* Extended bright color palette - no black/gray/silver */\n.bg-purple {\n    background-color: #6f42c1 !important;\n}\n\n.bg-cyan {\n    background-color: #17a2b8 !important;\n}\n\n.bg-orange {\n    background-color: #fd7e14 !important;\n}\n\n.bg-pink {\n    background-color: #e83e8c !important;\n}\n\n.bg-indigo {\n    background-color: #6610f2 !important;\n}\n\n.bg-teal {\n    background-color: #20c997 !important;\n}\n\n.bg-lime {\n    background-color: #32cd32 !important;\n}\n\n.bg-violet {\n    background-color: #8b00ff !important;\n}\n\n.bg-emerald {\n    background-color: #50c878 !important;\n}\n\n/* Progress bar consistency */\n.progress-bar {\n    color: #fff !important;\n    font-weight: 600 !important;\n}\n\n.progress-bar.bg-warning {\n    color: #000 !important;\n}\n\n.navbar-toggler {\n    position: absolute;\n    right: 2rem;\n    z-index: 10;\n}\n\n/* Desktop spacing */\n@media (min-width: 992px) {\n    .navbar-nav {\n        gap: 2rem;\n    }\n    \n    .navbar-brand {\n        left: 2rem;\n    }\n    \n    .navbar-toggler {\n        right: 2rem;\n    }\n}\n\n/* Mobile adjustments */\n@media (max-width: 991.98px) {\n    .navbar-brand {\n        position: static;\n    }\n    \n    .navbar-toggler {\n        position: static;\n    }\n    \n    .navbar-collapse {\n        position: static;\n        margin-top: 1rem;\n    }\n    \n    .navbar-nav {\n        flex-direction: column;\n        gap: 0.5rem;\n    }\n}\n\n/* Code and pre styling */\npre {\n    background-color: var(--custom-code-bg) !important;\n    border: 1px solid var(--bs-border-color);\n    border-radius: 6px;\n    color: var(--bs-body-color);\n    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n    font-size: 1rem;\n    line-height: 1.6;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    padding: 1rem;\n    margin: 0;\n}\n\n/* Card styling improvements */\n.card {\n    border-radius: var(--custom-border-radius);\n    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);\n    margin-bottom: 1rem;\n}\n\n.card-header {\n    background-color: var(--bs-dark);\n    border-bottom: 1px solid var(--bs-border-color);\n    border-radius: var(--custom-border-radius) var(--custom-border-radius) 0 0 !important;\n}\n\n/* Form improvements */\n.form-control, .form-select {\n    background-color: #2d3748 !important;\n    border: 1px solid #4a5568 !important;\n    color: #e2e8f0 !important;\n    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif !important;\n    font-size: 1rem;\n    border-radius: 6px !important;\n    transition: all 0.2s ease !important;\n}\n\n.form-control:focus, .form-select:focus {\n    border-color: #63b3ed !important;\n    box-shadow: 0 0 0 0.2rem rgba(99, 179, 237, 0.25) !important;\n    background-color: #2d3748 !important;\n    color: #e2e8f0 !important;\n    outline: none !important;\n}\n\n.form-control::placeholder {\n    color: #9ca3af !important;\n    font-style: italic;\n}\n\ntextarea.form-control {\n    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n    font-size: 1rem;\n    line-height: 1.6;\n    background-color: #2d3748 !important;\n    color: #e2e8f0 !important;\n    min-height: 120px;\n    resize: vertical;\n}\n\n/* Textarea específico da tela inicial - volta ao padrão simples */\n#problem_description {\n    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif !important;\n    font-size: 1rem !important;\n    line-height: 1.6 !important;\n    background-color: #2d3748 !important;\n    border: 1px solid #4a5568 !important;\n    color: #e2e8f0 !important;\n    border-radius: 6px !important;\n    padding: 0.75rem !important;\n}\n\n#problem_description:focus {\n    background-color: #2d3748 !important;\n    border-color: #63b3ed !important;\n    box-shadow: 0 0 0 0.2rem rgba(99, 179, 237, 0.25) !important;\n}\n\n/* Textareas de feedback e detalhes - melhorados mas simples */\n#custom_solution_text {\n    font-family: 'Consolas', 'Monaco', 'Courier New', monospace !important;\n    font-size: 0.95rem !important;\n    line-height: 1.7 !important;\n    background-color: #374151 !important;\n    border: 1px solid #6b7280 !important;\n    color: #f3f4f6 !important;\n    border-radius: 6px !important;\n    padding: 1rem !important;\n    min-height: 150px !important;\n}\n\n#custom_solution_text:focus {\n    background-color: #374151 !important;\n    border-color: #3b82f6 !important;\n    box-shadow: 0 0 0 0.2rem rgba(59, 130, 246, 0.25) !important;\n}\n\n/* Radio and checkbox visibility fixes */\n.form-check-input {\n    background-color: #2d3748 !important;\n    border-color: #4a5568 !important;\n    margin-top: 0.25rem !important;\n}\n\n.form-check-input:checked {\n    background-color: #3182ce !important;\n    border-color: #3182ce !important;\n}\n\n.form-check-input:focus {\n    border-color: #63b3ed !important;\n    box-shadow: 0 0 0 0.2rem rgba(99, 179, 237, 0.25) !important;\n}\n\n/* Radio button specific fixes for better visibility */\n.form-check-input[type=\"radio\"] {\n    background-color: #374151 !important;\n    border: 2px solid #6b7280 !important;\n    width: 1.3em !important;\n    height: 1.3em !important;\n    margin-top: 0.15rem !important;\n    transition: all 0.2s ease !important;\n}\n\n.form-check-input[type=\"radio\"]:checked {\n    background-color: #3b82f6 !important;\n    border-color: #3b82f6 !important;\n    background-image: url(\"data:image/svg+xml,%3csvg xmlns='http://www.w3.org/2000/svg' viewBox='-4 -4 8 8'%3e%3ccircle r='2.5' fill='%23ffffff'/%3e%3c/svg%3e\") !important;\n    transform: scale(1.05);\n}\n\n.form-check-input[type=\"radio\"]:focus {\n    border-color: #60a5fa !important;\n    outline: 0 !important;\n    box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.25) !important;\n}\n\n/* Colorful radio buttons for feedback form */\n.form-check-input[type=\"radio\"]#first_suggestion:checked {\n    background-color: #10b981 !important;\n    border-color: #10b981 !important;\n}\n\n.form-check-input[type=\"radio\"]#custom_solution:checked {\n    background-color: #f59e0b !important;\n    border-color: #f59e0b !important;\n}\n\n.form-check-input[type=\"radio\"]#not_resolved:checked {\n    background-color: #ef4444 !important;\n    border-color: #ef4444 !important;\n}\n\n/* Score radio buttons with gradient colors */\n.form-check-input[type=\"radio\"]#score1:checked {\n    background: linear-gradient(45deg, #dc2626, #ef4444) !important;\n    border-color: #dc2626 !important;\n}\n\n.form-check-input[type=\"radio\"]#score2:checked {\n    background: linear-gradient(45deg, #ea580c, #f97316) !important;\n    border-color: #ea580c !important;\n}\n\n.form-check-input[type=\"radio\"]#score3:checked {\n    background: linear-gradient(45deg, #d97706, #f59e0b) !important;\n    border-color: #d97706 !important;\n}\n\n.form-check-input[type=\"radio\"]#score4:checked {\n    background: linear-gradient(45deg, #059669, #10b981) !important;\n    border-color: #059669 !important;\n}\n\n.form-check-input[type=\"radio\"]#score5:checked {\n    background: linear-gradient(45deg, #0d9488, #14b8a6) !important;\n    border-color: #0d9488 !important;\n    box-shadow: 0 0 15px rgba(20, 184, 166, 0.4) !important;\n}\n\n/* Form labels and text in dark theme */\n.form-check-label {\n    color: #e5e7eb !important;\n    font-weight: 500;\n    cursor: pointer;\n    font-size: 1rem;\n    line-height: 1.6;\n    padding-left: 0.5rem;\n    transition: color 0.2s ease;\n}\n\n.form-check-label:hover {\n    color: #f3f4f6 !important;\n}\n\n.form-label {\n    color: #f3f4f6 !important;\n    font-weight: 600;\n    margin-bottom: 0.75rem;\n    font-size: 1.1rem;\n}\n\n/* Specific label colors for feedback options */\n.form-check-label[for=\"first_suggestion\"] {\n    color: #6ee7b7 !important;\n    font-weight: 600;\n}\n\n.form-check-label[for=\"custom_solution\"] {\n    color: #fcd34d !important;\n    font-weight: 600;\n}\n\n.form-check-label[for=\"not_resolved\"] {\n    color: #fca5a5 !important;\n    font-weight: 600;\n}\n\n/* Score labels with color coding */\n.form-check-label[for=\"score1\"] {\n    color: #fca5a5 !important;\n}\n\n.form-check-label[for=\"score2\"] {\n    color: #fed7aa !important;\n}\n\n.form-check-label[for=\"score3\"] {\n    color: #fde68a !important;\n}\n\n.form-check-label[for=\"score4\"] {\n    color: #a7f3d0 !important;\n}\n\n.form-check-label[for=\"score5\"] {\n    color: #5eead4 !important;\n    font-weight: 700;\n}\n\n/* Modal specific form styling */\n.modal .form-control {\n    background-color: #343a40 !important;\n    border: 1px solid #495057 !important;\n    color: #fff !important;\n}\n\n.modal .form-control:focus {\n    background-color: #343a40 !important;\n    border-color: #86b7fe !important;\n    color: #fff !important;\n    box-shadow: 0 0 0 0.2rem rgba(13, 110, 253, 0.25) !important;\n}\n\n.modal .form-check-input {\n    background-color: #343a40 !important;\n    border: 1px solid #495057 !important;\n}\n\n.modal .form-check-input:checked {\n    background-color: #0d6efd !important;\n    border-color: #0d6efd !important;\n}\n\n/* Button improvements */\n.btn {\n    border-radius: var(--custom-border-radius);\n    font-weight: 500;\n}\n\n.btn-group .btn {\n    border-radius: 0;\n}\n\n.btn-group .btn:first-child {\n    border-radius: var(--custom-border-radius) 0 0 var(--custom-border-radius);\n}\n\n.btn-group .btn:last-child {\n    border-radius: 0 var(--custom-border-radius) var(--custom-border-radius) 0;\n}\n\n/* Table improvements */\n.table-responsive {\n    border-radius: var(--custom-border-radius);\n}\n\n.table th {\n    border-top: none;\n    font-weight: 600;\n    font-size: 0.875rem;\n    text-transform: uppercase;\n    letter-spacing: 0.5px;\n}\n\n.table td {\n    vertical-align: middle;\n    border-color: var(--bs-border-color);\n}\n\n/* Progress bar styling */\n.progress {\n    border-radius: var(--custom-border-radius);\n    background-color: var(--bs-secondary-bg);\n}\n\n.progress-bar {\n    border-radius: var(--custom-border-radius);\n}\n\n/* Badge improvements */\n.badge {\n    border-radius: var(--custom-border-radius);\n    font-weight: 500;\n    font-size: 0.75rem;\n}\n\n/* Alert styling */\n.alert {\n    border-radius: var(--custom-border-radius);\n    border: none;\n}\n\n/* Navigation improvements */\n.navbar-brand {\n    font-weight: 700;\n    font-size: 1.25rem;\n}\n\n.nav-link {\n    font-weight: 500;\n}\n\n/* Footer styling */\nfooter {\n    margin-top: auto;\n}\n\n/* Modal improvements */\n.modal-content {\n    border-radius: var(--custom-border-radius);\n    border: none;\n}\n\n.modal-header {\n    border-bottom: 1px solid var(--bs-border-color);\n}\n\n/* Responsive improvements */\n@media (max-width: 768px) {\n    .container {\n        padding-left: 15px;\n        padding-right: 15px;\n    }\n    \n    .card-body {\n        padding: 1rem;\n    }\n    \n    .btn {\n        font-size: 0.875rem;\n    }\n    \n    .table-responsive {\n        font-size: 0.875rem;\n    }\n}\n\n/* Utility classes */\n.text-wrap {\n    white-space: pre-wrap;\n    word-wrap: break-word;\n}\n\n.cursor-pointer {\n    cursor: pointer;\n}\n\n/* Loading states */\n.loading {\n    opacity: 0.6;\n    pointer-events: none;\n}\n\n.loading::after {\n    content: \"\";\n    position: absolute;\n    top: 50%;\n    left: 50%;\n    margin: -12px 0 0 -12px;\n    width: 24px;\n    height: 24px;\n    border: 2px solid var(--bs-primary);\n    border-radius: 50%;\n    border-top-color: transparent;\n    animation: spin 1s ease-in-out infinite;\n}\n\n@keyframes spin {\n    to {\n        transform: rotate(360deg);\n    }\n}\n\n/* Toast positioning */\n.toast-container {\n    position: fixed;\n    top: 20px;\n    right: 20px;\n    z-index: 1050;\n}\n\n/* Highlight search results */\n.search-highlight {\n    background-color: rgba(var(--bs-warning-rgb), 0.3);\n    padding: 2px 4px;\n    border-radius: 3px;\n}\n\n/* Custom scrollbar for webkit browsers */\n::-webkit-scrollbar {\n    width: 8px;\n}\n\n::-webkit-scrollbar-track {\n    background: var(--bs-dark);\n}\n\n::-webkit-scrollbar-thumb {\n    background: var(--bs-secondary);\n    border-radius: 4px;\n}\n\n::-webkit-scrollbar-thumb:hover {\n    background: var(--bs-light);\n}\n\n/* Print styles */\n@media print {\n    .navbar,\n    .btn,\n    footer {\n        display: none !important;\n    }\n    \n    .card {\n        border: 1px solid #000 !important;\n        box-shadow: none !important;\n    }\n    \n    .card-body {\n        padding: 1rem !important;\n    }\n    \n    pre {\n        background-color: #f8f9fa !important;\n        border: 1px solid #000 !important;\n        color: #000 !important;\n    }\n}\n\n/* Custom system color classes */\n.bg-purple { background-color: #6f42c1 !important; color: white !important; }\n.bg-cyan { background-color: #0dcaf0 !important; color: white !important; }\n.bg-orange { background-color: #fd7e14 !important; color: white !important; }\n.bg-pink { background-color: #d63384 !important; color: white !important; }\n\n.progress-bar.bg-purple { background-color: #6f42c1 !important; }\n.progress-bar.bg-cyan { background-color: #0dcaf0 !important; }\n.progress-bar.bg-orange { background-color: #fd7e14 !important; }\n.progress-bar.bg-pink { background-color: #d63384 !important; }\n\n/* Force system badge colors - critical fixes */\n.badge.system-badge {\n    color: white !important;\n    font-weight: 600 !important;\n    border: none !important;\n}\n\n.badge.bg-dark,\n.badge[data-system*=\"Aplicativo Unimed\"],\n.badge[data-system*=\"aplicativo unimed\"] {\n    background-color: #212529 !important;\n    color: white !important;\n}\n\n.badge.bg-secondary,\n.badge[data-system*=\"SGU GPL\"],\n.badge[data-system*=\"sgu gpl\"] {\n    background-color: #6c757d !important;\n    color: white !important;\n}\n\n/* Scroll to top button styling */\n.scroll-to-top-btn:hover {\n    transform: translateY(-2px);\n    box-shadow: 0 6px 16px rgba(0,0,0,0.4) !important;\n}\n\n/* System color utility classes for cases */\n.system-badge-primary { background-color: #0d6efd !important; }\n.system-badge-info { background-color: #0dcaf0 !important; }\n.system-badge-success { background-color: #198754 !important; }\n.system-badge-warning { background-color: #ffc107 !important; }\n.system-badge-secondary { background-color: #6c757d !important; }\n.system-badge-danger { background-color: #dc3545 !important; }\n.system-badge-dark { background-color: #212529 !important; }\n.system-badge-purple { background-color: #6f42c1 !important; }\n.system-badge-cyan { background-color: #0dcaf0 !important; }\n.system-badge-orange { background-color: #fd7e14 !important; }\n.system-badge-pink { background-color: #d63384 !important; }\n","size_bytes":16919},".local/state/replit/agent/progress_tracker.md":{"content":"[x] 1. Install the required packages\n[x] 2. Restart the workflow to see if the project is working\n[x] 3. Verify the project is working using the feedback tool\n[x] 4. Inform user the import is completed and they can start building, mark the import as completed using the complete_project_import tool","size_bytes":298}}}